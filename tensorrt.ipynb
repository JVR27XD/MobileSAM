{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5NqXA8uvTlvAJgswS7zJh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVR27XD/MobileSAM/blob/main/tensorrt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_xhz3KVpON5",
        "outputId": "aaad3476-9d45-4620-e514-a3247c1b64a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ItayElam/SegmentAnything-TensorRT.git\n",
        "%cd SegmentAnything-TensorRT\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chi93VTVtV4O",
        "outputId": "9a823383-b3dc-4d50-da2a-9e540c868a0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SegmentAnything-TensorRT'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 42 (delta 7), reused 41 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (42/42), 280.67 KiB | 5.73 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/SegmentAnything-TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/SAM_TENSOR/sam_vit_h_4b8939.pth\" checkpoints/sam_vit_h.pth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UNzDoPWu3FQ",
        "outputId": "3e194f26-bb63-4e49-f8e0-e523f611625a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Instalar dependencias\n",
        "!pip install onnx onnxruntime onnxruntime-gpu nvidia-pyindex nvidia-tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mERdFY68wNx2",
        "outputId": "11556aa4-64ab-4934-973d-a43e38065873"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-10.12.0.36.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Collecting tensorrt_cu12==10.12.0.36 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12-10.12.0.36.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_libs==10.12.0.36 (from tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.12.0.36.tar.gz (709 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.12.0.36 (from tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.12.0.36-cp311-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.12.0.36->tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt) (12.5.82)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.12.0.36-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex, tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=3c776aaaafc4b997d5ebb9ac2eac578c8603382957539ad2431f291eafe879df\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/d0/7d/b68b3665d16ee20355e65fb7ef48b7ca26533217d9f09924fe\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.12.0.36-py2.py3-none-any.whl size=46638 sha256=45642e4fb1cd24a0289e8d0db0d9c34593b01b6321184562573dc418616bbaea\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/7e/1d/fa229fa908a941f493812047b942b726d18e66f30fe2ac3854\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.12.0.36-py2.py3-none-any.whl size=17480 sha256=34c90fbcefc85ca7d9b49f366eb96ff0bd68d1190542109e480d8da2c00938aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/b2/d6/1629763d3e056546381842f6216f736bf45390fc25cf204091\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.12.0.36-py2.py3-none-manylinux_2_28_x86_64.whl size=3095483544 sha256=3910039e1d49de0edfdc8bf273e40ad4b85a9d57c7c383fe0e22f75417df9610\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/57/d0/c32fb4b4873adbbadcf505f348d120a5b5c3aaab46617e52ac\n",
            "Successfully built nvidia-pyindex tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, nvidia-pyindex, tensorrt_cu12_libs, onnx, humanfriendly, tensorrt_cu12, coloredlogs, tensorrt, onnxruntime-gpu, onnxruntime, nvidia-tensorrt\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-pyindex-1.0.9 nvidia-tensorrt-99.0.0 onnx-1.18.0 onnxruntime-1.22.0 onnxruntime-gpu-1.22.0 tensorrt-10.12.0.36 tensorrt_cu12-10.12.0.36 tensorrt_cu12_bindings-10.12.0.36 tensorrt_cu12_libs-10.12.0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Clonar Segment Anything oficial y renombrar\n",
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/segment-anything.git\n",
        "!mv segment-anything segment_anything"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUhEauiBwRGl",
        "outputId": "06f9c615-3a36-40fc-aa4a-6087c193711f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'segment-anything'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 304 (delta 2), reused 1 (delta 1), pack-reused 299 (from 2)\u001b[K\n",
            "Receiving objects: 100% (304/304), 18.31 MiB | 44.64 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Instalar SAM como paquete Python local\n",
        "%cd /content/segment_anything\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC1GqQPHwiRd",
        "outputId": "4ec7ce69-a4e5-4565-cf03-7c345cb710af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/segment_anything\n",
            "Obtaining file:///content/segment_anything\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: segment_anything\n",
            "  Running setup.py develop for segment_anything\n",
            "Successfully installed segment_anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6: Volver al proyecto principal\n",
        "%cd /content/SegmentAnything-TensorRT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuuJZTmlwq0W",
        "outputId": "1158d9e1-72af-406f-b84f-3731474813fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SegmentAnything-TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6.5: Instalar PyCUDA\n",
        "!pip install pycuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSUA9p-xi32",
        "outputId": "5b9e57d6-0b86-4be3-c875-984fad399cf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.14.0)\n",
            "Downloading pytools-2025.1.6-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1.1-cp311-cp311-linux_x86_64.whl size=660712 sha256=1c24184f00c2f150b56b6bc67ece7adc5b1cbe54c25e73d31b868e517c986de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/0a/64/6530a5fde64f984ebb4992e38744fdfd2a61f510377b3a24d9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1.1 pytools-2025.1.6 siphash24-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 7: Exportar a ONNX y TensorRT\n",
        "!python main.py export \\\n",
        "  --model_path checkpoints/sam_vit_h.pth \\\n",
        "  --model_precision fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9upl1eWRv1F9",
        "outputId": "d0da02df-fb98-4e68-d6bb-08f17265a61e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "  %/blocks.15/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/mlp/act/Div\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.15/mlp/act/Erf\"](%/blocks.15/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/act/Add\"](%/blocks.15/mlp/act/Erf_output_0, %/blocks.15/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.15/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul_1\"](%/blocks.15/mlp/act/Mul_output_0, %/blocks.15/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin2/MatMul\"](%/blocks.15/mlp/act/Mul_1_output_0, %onnx::MatMul_6086), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin2/Add\"](%blocks.15.mlp.lin2.bias, %/blocks.15/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %intermediate_output : Float(*, *, *, *, strides=[5242880, 64, 1, 4096], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add_1\"](%/blocks.15/Add_output_0, %/blocks.15/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  return (%intermediate_output)\n",
            "\n",
            "Exported graph: graph(%intermediate_input : Float(1, 64, 64, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu),\n",
            "      %blocks.0.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.rel_pos_h : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.rel_pos_w : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.rel_pos_h : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.rel_pos_w : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %neck.0.weight : Float(256, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %neck.2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
            "      %onnx::MatMul_5612 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5621 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5634 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5635 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5650 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5659 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5670 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5671 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5686 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5695 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5706 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5707 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5722 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5731 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5742 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5743 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5758 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5767 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5778 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5779 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5794 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5803 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5814 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5815 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5830 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5839 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5850 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5851 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5852 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5861 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5862 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5863 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5878 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5887 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5898 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5899 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5914 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5923 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5934 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5935 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5950 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5959 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5970 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5971 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5986 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5995 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6006 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6007 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6022 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6031 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6042 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6043 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6058 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6067 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6078 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6079 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6094 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6103 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6114 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6115 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6116 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6125 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6126 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6127 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::Mul_6129 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Add_6131 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Mul_6133 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Add_6135 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu)):\n",
            "  %/blocks.0/norm1/LayerNormalization_output_0 : Float(1, 64, 64, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.0/norm1/LayerNormalization\"](%intermediate_input, %blocks.0.norm1.weight, %blocks.0.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.0/Constant_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod\"](%/blocks.0/Constant_output_0, %/blocks.0/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub\"](%/blocks.0/Constant_2_output_0, %/blocks.0/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_1\"](%/blocks.0/Sub_output_0, %/blocks.0/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_2\"](%/blocks.0/Constant_4_output_0, %/blocks.0/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub_1\"](%/blocks.0/Constant_6_output_0, %/blocks.0/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_3\"](%/blocks.0/Sub_1_output_0, %/blocks.0/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze\"](%/blocks.0/Mod_3_output_0, %onnx::Unsqueeze_261), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_1\"](%/blocks.0/Mod_1_output_0, %onnx::Unsqueeze_265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat\"](%/blocks.0/Constant_8_output_0, %/blocks.0/Constant_9_output_0, %/blocks.0/Constant_10_output_0, %/blocks.0/Unsqueeze_output_0, %/blocks.0/Constant_11_output_0, %/blocks.0/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_2\"](%/blocks.0/Mod_3_output_0, %onnx::Unsqueeze_274), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_3\"](%/blocks.0/Mod_1_output_0, %onnx::Unsqueeze_278), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_1\"](%/blocks.0/Constant_12_output_0, %/blocks.0/Constant_13_output_0, %/blocks.0/Constant_14_output_0, %/blocks.0/Unsqueeze_2_output_0, %/blocks.0/Constant_15_output_0, %/blocks.0/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %onnx::Pad_281 : NoneType = prim::Constant(), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Shape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/Shape\"](%/blocks.0/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Gather_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/Gather\"](%/blocks.0/Shape_output_0, %/blocks.0/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_17_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.0/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub_2\"](%/blocks.0/Constant_17_output_0, %/blocks.0/Gather_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast\"](%/blocks.0/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.0/ConstantOfShape\"](%/blocks.0/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_2\"](%/blocks.0/Cast_output_0, %/blocks.0/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.0/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape\"](%/blocks.0/Concat_2_output_0, %/blocks.0/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.0/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice\"](%/blocks.0/Reshape_output_0, %/blocks.0/Constant_20_output_0, %/blocks.0/Constant_21_output_0, %/blocks.0/Constant_19_output_0, %/blocks.0/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.0/Transpose\"](%/blocks.0/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_1\"](%/blocks.0/Transpose_output_0, %/blocks.0/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_1\"](%/blocks.0/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.0/Pad\"](%/blocks.0/norm1/LayerNormalization_output_0, %/blocks.0/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add\"](%/blocks.0/Constant_24_output_0, %/blocks.0/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Constant_25_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_1\"](%/blocks.0/Constant_25_output_0, %/blocks.0/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div\"](%/blocks.0/Add_output_0, %/blocks.0/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_2\"](%/blocks.0/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_3\"](%/blocks.0/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_1\"](%/blocks.0/Add_1_output_0, %/blocks.0/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_4\"](%/blocks.0/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_5\"](%/blocks.0/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_4\"](%/blocks.0/Cast_3_output_0, %onnx::Unsqueeze_318), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_5\"](%/blocks.0/Cast_5_output_0, %onnx::Unsqueeze_322), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1280}, onnx_name=\"/blocks.0/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_3\"](%/blocks.0/Constant_28_output_0, %/blocks.0/Unsqueeze_4_output_0, %/blocks.0/Constant_29_output_0, %/blocks.0/Unsqueeze_5_output_0, %/blocks.0/Constant_30_output_0, %/blocks.0/Constant_31_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.0/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_2\"](%/blocks.0/Pad_output_0, %/blocks.0/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.0/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.0/Transpose_1\"](%/blocks.0/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/Constant_32_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   -1    14    14  1280 [ CPULongType{4} ], onnx_name=\"/blocks.0/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_3\"](%/blocks.0/Transpose_1_output_0, %/blocks.0/Constant_32_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather\"](%/blocks.0/attn/Shape_output_0, %/blocks.0/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_1\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_1\"](%/blocks.0/attn/Shape_1_output_0, %/blocks.0/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_2\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_2\"](%/blocks.0/attn/Shape_2_output_0, %/blocks.0/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/qkv/MatMul\"](%/blocks.0/Reshape_3_output_0, %onnx::MatMul_5612), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/qkv/Add\"](%blocks.0.attn.qkv.bias, %/blocks.0/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul\"](%/blocks.0/attn/Gather_1_output_0, %/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_356 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_356), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_1\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_358), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat\"](%/blocks.0/attn/Unsqueeze_output_0, %/blocks.0/attn/Unsqueeze_1_output_0, %/blocks.0/attn/Constant_3_output_0, %/blocks.0/attn/Constant_4_output_0, %/blocks.0/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape\"](%/blocks.0/attn/qkv/Add_output_0, %/blocks.0/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.0/attn/Transpose\"](%/blocks.0/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_1\"](%/blocks.0/attn/Gather_output_0, %/blocks.0/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_2\"](%/blocks.0/attn/Mul_1_output_0, %onnx::Unsqueeze_373), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_3\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_375), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_1\"](%/blocks.0/attn/Constant_7_output_0, %/blocks.0/attn/Unsqueeze_2_output_0, %/blocks.0/attn/Unsqueeze_3_output_0, %/blocks.0/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_1\"](%/blocks.0/attn/Transpose_output_0, %/blocks.0/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.0/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.0/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.0/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.0/attn/Split\"](%/blocks.0/attn/Reshape_1_output_0, %/blocks.0/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze\"](%/blocks.0/attn/Split_output_0, %/blocks.0/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze_1\"](%/blocks.0/attn/Split_output_1, %/blocks.0/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze_2\"](%/blocks.0/attn/Split_output_2, %/blocks.0/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.0/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_2\"](%/blocks.0/attn/Squeeze_output_0, %/blocks.0/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.0/attn/Transpose_1\"](%/blocks.0/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/MatMul\"](%/blocks.0/attn/Mul_2_output_0, %/blocks.0/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.0/attn/Range\"](%/blocks.0/attn/Constant_14_output_0, %/blocks.0/attn/Cast_output_0, %/blocks.0/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_4\"](%/blocks.0/attn/Range_output_0, %/blocks.0/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_1\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_2\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/attn/Div\"](%/blocks.0/attn/Cast_1_output_0, %/blocks.0/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_3\"](%/blocks.0/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_3\"](%/blocks.0/attn/Cast_3_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_5\"](%/blocks.0/attn/Range_output_0, %/blocks.0/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_4\"](%/blocks.0/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_4\"](%/blocks.0/attn/Cast_4_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub\"](%/blocks.0/attn/Mul_3_output_0, %/blocks.0/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_1\"](%/blocks.0/attn/Gather_1_output_0, %/blocks.0/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_5\"](%/blocks.0/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_5\"](%/blocks.0/attn/Cast_5_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add\"](%/blocks.0/attn/Sub_output_0, %/blocks.0/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_6\"](%/blocks.0/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_3\"](%blocks.0.attn.rel_pos_h, %/blocks.0/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_7\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.0/attn/Range_1\"](%/blocks.0/attn/Constant_19_output_0, %/blocks.0/attn/Cast_7_output_0, %/blocks.0/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_6\"](%/blocks.0/attn/Range_1_output_0, %/blocks.0/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_8\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_9\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/attn/Div_1\"](%/blocks.0/attn/Cast_8_output_0, %/blocks.0/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_10\"](%/blocks.0/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_6\"](%/blocks.0/attn/Cast_10_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_7\"](%/blocks.0/attn/Range_1_output_0, %/blocks.0/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_11\"](%/blocks.0/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_7\"](%/blocks.0/attn/Cast_11_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_2\"](%/blocks.0/attn/Mul_6_output_0, %/blocks.0/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_3\"](%/blocks.0/attn/Gather_2_output_0, %/blocks.0/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_12\"](%/blocks.0/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_8\"](%/blocks.0/attn/Cast_12_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_1\"](%/blocks.0/attn/Sub_2_output_0, %/blocks.0/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_13\"](%/blocks.0/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_4\"](%blocks.0.attn.rel_pos_w, %/blocks.0/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_3\"](%/blocks.0/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_5\"](%/blocks.0/attn/Shape_3_output_0, %/blocks.0/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_4\"](%/blocks.0/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_6\"](%/blocks.0/attn/Shape_4_output_0, %/blocks.0/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_8\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_447), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_449 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_9\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_449), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_10\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_451), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_11\"](%/blocks.0/attn/Gather_6_output_0, %onnx::Unsqueeze_453), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_2\"](%/blocks.0/attn/Unsqueeze_8_output_0, %/blocks.0/attn/Unsqueeze_9_output_0, %/blocks.0/attn/Unsqueeze_10_output_0, %/blocks.0/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.0/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_2\"](%/blocks.0/attn/Squeeze_output_0, %/blocks.0/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.0/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.0/attn/Einsum\"](%/blocks.0/attn/Reshape_2_output_0, %/blocks.0/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.0/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.0/attn/Einsum_1\"](%/blocks.0/attn/Reshape_2_output_0, %/blocks.0/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_12\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_459), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_13\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_461), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_14\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_463), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_15\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_465), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_467 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_16\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_467), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_3\"](%/blocks.0/attn/Unsqueeze_12_output_0, %/blocks.0/attn/Unsqueeze_13_output_0, %/blocks.0/attn/Unsqueeze_14_output_0, %/blocks.0/attn/Unsqueeze_15_output_0, %/blocks.0/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_3\"](%/blocks.0/attn/MatMul_output_0, %/blocks.0/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.0/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_17\"](%/blocks.0/attn/Einsum_output_0, %/blocks.0/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_2\"](%/blocks.0/attn/Reshape_3_output_0, %/blocks.0/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_18\"](%/blocks.0/attn/Einsum_1_output_0, %/blocks.0/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_3\"](%/blocks.0/attn/Add_2_output_0, %/blocks.0/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_19\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_477), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_20\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_479), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_481 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_21\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_481), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_4\"](%/blocks.0/attn/Unsqueeze_19_output_0, %/blocks.0/attn/Unsqueeze_20_output_0, %/blocks.0/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.0/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_4\"](%/blocks.0/attn/Add_3_output_0, %/blocks.0/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.0/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.0/attn/Softmax\"](%/blocks.0/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.0/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/MatMul_1\"](%/blocks.0/attn/Softmax_output_0, %/blocks.0/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_22\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_487), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_23\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_24\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_5\"](%/blocks.0/attn/Unsqueeze_22_output_0, %/blocks.0/attn/Constant_28_output_0, %/blocks.0/attn/Unsqueeze_23_output_0, %/blocks.0/attn/Unsqueeze_24_output_0, %/blocks.0/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_5\"](%/blocks.0/attn/MatMul_1_output_0, %/blocks.0/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.0/attn/Transpose_2\"](%/blocks.0/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_25\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_500), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_26\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_502), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_27\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_504), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_6\"](%/blocks.0/attn/Unsqueeze_25_output_0, %/blocks.0/attn/Unsqueeze_26_output_0, %/blocks.0/attn/Unsqueeze_27_output_0, %/blocks.0/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_6\"](%/blocks.0/attn/Transpose_2_output_0, %/blocks.0/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/proj/MatMul\"](%/blocks.0/attn/Reshape_6_output_0, %onnx::MatMul_5621), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/proj/Add\"](%blocks.0.attn.proj.bias, %/blocks.0/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/Shape_1\"](%/blocks.0/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/Gather_1\"](%/blocks.0/Shape_1_output_0, %/blocks.0/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/Mul\"](%/blocks.0/Add_output_0, %/blocks.0/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_2\"](%/blocks.0/Mul_output_0, %/blocks.0/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_6\"](%/blocks.0/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_7\"](%/blocks.0/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_3\"](%/blocks.0/Cast_7_output_0, %/blocks.0/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_8\"](%/blocks.0/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_9\"](%/blocks.0/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_4\"](%/blocks.0/Gather_1_output_0, %/blocks.0/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_10\"](%/blocks.0/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_11\"](%/blocks.0/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_6\"](%/blocks.0/Cast_11_output_0, %onnx::Unsqueeze_528), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_7\"](%/blocks.0/Cast_3_output_0, %onnx::Unsqueeze_530), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_8\"](%/blocks.0/Cast_5_output_0, %onnx::Unsqueeze_532), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_4\"](%/blocks.0/Unsqueeze_6_output_0, %/blocks.0/Unsqueeze_7_output_0, %/blocks.0/Unsqueeze_8_output_0, %/blocks.0/Constant_36_output_0, %/blocks.0/Constant_37_output_0, %/blocks.0/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.0/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_4\"](%/blocks.0/attn/proj/Add_output_0, %/blocks.0/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.0/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.0/Transpose_2\"](%/blocks.0/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_543 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_9\"](%/blocks.0/Cast_11_output_0, %onnx::Unsqueeze_543), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_545 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_10\"](%/blocks.0/Add_output_0, %onnx::Unsqueeze_545), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_11\"](%/blocks.0/Add_1_output_0, %onnx::Unsqueeze_547), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_5\"](%/blocks.0/Unsqueeze_9_output_0, %/blocks.0/Unsqueeze_10_output_0, %/blocks.0/Unsqueeze_11_output_0, %/blocks.0/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.0/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_5\"](%/blocks.0/Transpose_2_output_0, %/blocks.0/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.0/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice_1\"](%/blocks.0/Reshape_5_output_0, %/blocks.0/Constant_41_output_0, %/blocks.0/Constant_42_output_0, %/blocks.0/Constant_40_output_0, %/blocks.0/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice_2\"](%/blocks.0/Slice_1_output_0, %/blocks.0/Constant_45_output_0, %/blocks.0/Constant_46_output_0, %/blocks.0/Constant_44_output_0, %/blocks.0/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_2\"](%intermediate_input, %/blocks.0/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.0/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.0/norm2/LayerNormalization\"](%/blocks.0/Add_2_output_0, %blocks.0.norm2.weight, %blocks.0.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.0/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/mlp/lin1/MatMul\"](%/blocks.0/norm2/LayerNormalization_output_0, %onnx::MatMul_5634), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/lin1/Add\"](%blocks.0.mlp.lin1.bias, %/blocks.0/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.0/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/mlp/act/Div\"](%/blocks.0/mlp/lin1/Add_output_0, %/blocks.0/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.0/mlp/act/Erf\"](%/blocks.0/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/act/Add\"](%/blocks.0/mlp/act/Erf_output_0, %/blocks.0/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/mlp/act/Mul\"](%/blocks.0/mlp/lin1/Add_output_0, %/blocks.0/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.0/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/mlp/act/Mul_1\"](%/blocks.0/mlp/act/Mul_output_0, %/blocks.0/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/mlp/lin2/MatMul\"](%/blocks.0/mlp/act/Mul_1_output_0, %onnx::MatMul_5635), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/lin2/Add\"](%blocks.0.mlp.lin2.bias, %/blocks.0/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_3\"](%/blocks.0/Add_2_output_0, %/blocks.0/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.1/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.1/norm1/LayerNormalization\"](%/blocks.0/Add_3_output_0, %blocks.1.norm1.weight, %blocks.1.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather\"](%/blocks.1/Shape_output_0, %/blocks.1/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_1\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_1\"](%/blocks.1/Shape_1_output_0, %/blocks.1/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_2\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_2\"](%/blocks.1/Shape_2_output_0, %/blocks.1/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_3\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_3\"](%/blocks.1/Shape_3_output_0, %/blocks.1/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod\"](%/blocks.1/Gather_output_0, %/blocks.1/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub\"](%/blocks.1/Constant_5_output_0, %/blocks.1/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_1\"](%/blocks.1/Sub_output_0, %/blocks.1/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_2\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub_1\"](%/blocks.1/Constant_8_output_0, %/blocks.1/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_3\"](%/blocks.1/Sub_1_output_0, %/blocks.1/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_619 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze\"](%/blocks.1/Mod_3_output_0, %onnx::Unsqueeze_619), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_623 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_1\"](%/blocks.1/Mod_1_output_0, %onnx::Unsqueeze_623), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat\"](%/blocks.1/Constant_10_output_0, %/blocks.1/Constant_11_output_0, %/blocks.1/Constant_12_output_0, %/blocks.1/Unsqueeze_output_0, %/blocks.1/Constant_13_output_0, %/blocks.1/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_2\"](%/blocks.1/Mod_3_output_0, %onnx::Unsqueeze_632), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_636 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_3\"](%/blocks.1/Mod_1_output_0, %onnx::Unsqueeze_636), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_1\"](%/blocks.1/Constant_14_output_0, %/blocks.1/Constant_15_output_0, %/blocks.1/Constant_16_output_0, %/blocks.1/Unsqueeze_2_output_0, %/blocks.1/Constant_17_output_0, %/blocks.1/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_4\"](%/blocks.1/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_4\"](%/blocks.1/Shape_4_output_0, %/blocks.1/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.1/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub_2\"](%/blocks.1/Constant_19_output_0, %/blocks.1/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast\"](%/blocks.1/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.1/ConstantOfShape\"](%/blocks.1/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_2\"](%/blocks.1/Cast_output_0, %/blocks.1/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.1/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape\"](%/blocks.1/Concat_2_output_0, %/blocks.1/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.1/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice\"](%/blocks.1/Reshape_output_0, %/blocks.1/Constant_22_output_0, %/blocks.1/Constant_23_output_0, %/blocks.1/Constant_21_output_0, %/blocks.1/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.1/Transpose\"](%/blocks.1/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_1\"](%/blocks.1/Transpose_output_0, %/blocks.1/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_1\"](%/blocks.1/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.1/Pad\"](%/blocks.1/norm1/LayerNormalization_output_0, %/blocks.1/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add\"](%/blocks.1/Gather_output_0, %/blocks.1/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.1/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_1\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.1/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div\"](%/blocks.1/Add_output_0, %/blocks.1/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_2\"](%/blocks.1/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_3\"](%/blocks.1/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_1\"](%/blocks.1/Add_1_output_0, %/blocks.1/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_4\"](%/blocks.1/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_5\"](%/blocks.1/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_4\"](%/blocks.1/Gather_2_output_0, %onnx::Unsqueeze_671), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_5\"](%/blocks.1/Cast_3_output_0, %onnx::Unsqueeze_673), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_677 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_6\"](%/blocks.1/Cast_5_output_0, %onnx::Unsqueeze_677), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_681 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_7\"](%/blocks.1/Gather_3_output_0, %onnx::Unsqueeze_681), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_3\"](%/blocks.1/Unsqueeze_4_output_0, %/blocks.1/Unsqueeze_5_output_0, %/blocks.1/Constant_28_output_0, %/blocks.1/Unsqueeze_6_output_0, %/blocks.1/Constant_29_output_0, %/blocks.1/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.1/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_2\"](%/blocks.1/Pad_output_0, %/blocks.1/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.1/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.1/Transpose_1\"](%/blocks.1/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_8\"](%/blocks.1/Gather_3_output_0, %onnx::Unsqueeze_692), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_4\"](%/blocks.1/Constant_30_output_0, %/blocks.1/Constant_31_output_0, %/blocks.1/Constant_32_output_0, %/blocks.1/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_3\"](%/blocks.1/Transpose_1_output_0, %/blocks.1/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather\"](%/blocks.1/attn/Shape_output_0, %/blocks.1/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_1\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_1\"](%/blocks.1/attn/Shape_1_output_0, %/blocks.1/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_2\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_2\"](%/blocks.1/attn/Shape_2_output_0, %/blocks.1/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/qkv/MatMul\"](%/blocks.1/Reshape_3_output_0, %onnx::MatMul_5650), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/qkv/Add\"](%blocks.1.attn.qkv.bias, %/blocks.1/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul\"](%/blocks.1/attn/Gather_1_output_0, %/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_709 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_709), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_1\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_711), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat\"](%/blocks.1/attn/Unsqueeze_output_0, %/blocks.1/attn/Unsqueeze_1_output_0, %/blocks.1/attn/Constant_3_output_0, %/blocks.1/attn/Constant_4_output_0, %/blocks.1/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape\"](%/blocks.1/attn/qkv/Add_output_0, %/blocks.1/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.1/attn/Transpose\"](%/blocks.1/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_1\"](%/blocks.1/attn/Gather_output_0, %/blocks.1/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_726 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_2\"](%/blocks.1/attn/Mul_1_output_0, %onnx::Unsqueeze_726), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_728 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_3\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_728), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_1\"](%/blocks.1/attn/Constant_7_output_0, %/blocks.1/attn/Unsqueeze_2_output_0, %/blocks.1/attn/Unsqueeze_3_output_0, %/blocks.1/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_1\"](%/blocks.1/attn/Transpose_output_0, %/blocks.1/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.1/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.1/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.1/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.1/attn/Split\"](%/blocks.1/attn/Reshape_1_output_0, %/blocks.1/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze\"](%/blocks.1/attn/Split_output_0, %/blocks.1/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze_1\"](%/blocks.1/attn/Split_output_1, %/blocks.1/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze_2\"](%/blocks.1/attn/Split_output_2, %/blocks.1/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.1/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_2\"](%/blocks.1/attn/Squeeze_output_0, %/blocks.1/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.1/attn/Transpose_1\"](%/blocks.1/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/MatMul\"](%/blocks.1/attn/Mul_2_output_0, %/blocks.1/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.1/attn/Range\"](%/blocks.1/attn/Constant_14_output_0, %/blocks.1/attn/Cast_output_0, %/blocks.1/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_4\"](%/blocks.1/attn/Range_output_0, %/blocks.1/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_1\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_2\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/attn/Div\"](%/blocks.1/attn/Cast_1_output_0, %/blocks.1/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_3\"](%/blocks.1/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_3\"](%/blocks.1/attn/Cast_3_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_5\"](%/blocks.1/attn/Range_output_0, %/blocks.1/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_4\"](%/blocks.1/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_4\"](%/blocks.1/attn/Cast_4_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub\"](%/blocks.1/attn/Mul_3_output_0, %/blocks.1/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_1\"](%/blocks.1/attn/Gather_1_output_0, %/blocks.1/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_5\"](%/blocks.1/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_5\"](%/blocks.1/attn/Cast_5_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add\"](%/blocks.1/attn/Sub_output_0, %/blocks.1/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_6\"](%/blocks.1/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_3\"](%blocks.1.attn.rel_pos_h, %/blocks.1/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_7\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.1/attn/Range_1\"](%/blocks.1/attn/Constant_19_output_0, %/blocks.1/attn/Cast_7_output_0, %/blocks.1/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_6\"](%/blocks.1/attn/Range_1_output_0, %/blocks.1/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_8\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_9\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/attn/Div_1\"](%/blocks.1/attn/Cast_8_output_0, %/blocks.1/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_10\"](%/blocks.1/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_6\"](%/blocks.1/attn/Cast_10_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_7\"](%/blocks.1/attn/Range_1_output_0, %/blocks.1/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_11\"](%/blocks.1/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_7\"](%/blocks.1/attn/Cast_11_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_2\"](%/blocks.1/attn/Mul_6_output_0, %/blocks.1/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_3\"](%/blocks.1/attn/Gather_2_output_0, %/blocks.1/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_12\"](%/blocks.1/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_8\"](%/blocks.1/attn/Cast_12_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_1\"](%/blocks.1/attn/Sub_2_output_0, %/blocks.1/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_13\"](%/blocks.1/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_4\"](%blocks.1.attn.rel_pos_w, %/blocks.1/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_3\"](%/blocks.1/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_5\"](%/blocks.1/attn/Shape_3_output_0, %/blocks.1/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_4\"](%/blocks.1/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_6\"](%/blocks.1/attn/Shape_4_output_0, %/blocks.1/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_800 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_8\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_800), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_802 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_9\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_802), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_804 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_10\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_804), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_806 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_11\"](%/blocks.1/attn/Gather_6_output_0, %onnx::Unsqueeze_806), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_2\"](%/blocks.1/attn/Unsqueeze_8_output_0, %/blocks.1/attn/Unsqueeze_9_output_0, %/blocks.1/attn/Unsqueeze_10_output_0, %/blocks.1/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.1/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_2\"](%/blocks.1/attn/Squeeze_output_0, %/blocks.1/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.1/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.1/attn/Einsum\"](%/blocks.1/attn/Reshape_2_output_0, %/blocks.1/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.1/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.1/attn/Einsum_1\"](%/blocks.1/attn/Reshape_2_output_0, %/blocks.1/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_12\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_812), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_13\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_14\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_816), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_15\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_818), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_16\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_820), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_3\"](%/blocks.1/attn/Unsqueeze_12_output_0, %/blocks.1/attn/Unsqueeze_13_output_0, %/blocks.1/attn/Unsqueeze_14_output_0, %/blocks.1/attn/Unsqueeze_15_output_0, %/blocks.1/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_3\"](%/blocks.1/attn/MatMul_output_0, %/blocks.1/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.1/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_17\"](%/blocks.1/attn/Einsum_output_0, %/blocks.1/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_2\"](%/blocks.1/attn/Reshape_3_output_0, %/blocks.1/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_18\"](%/blocks.1/attn/Einsum_1_output_0, %/blocks.1/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_3\"](%/blocks.1/attn/Add_2_output_0, %/blocks.1/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_19\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_20\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_832), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_21\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_834), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_4\"](%/blocks.1/attn/Unsqueeze_19_output_0, %/blocks.1/attn/Unsqueeze_20_output_0, %/blocks.1/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.1/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_4\"](%/blocks.1/attn/Add_3_output_0, %/blocks.1/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.1/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.1/attn/Softmax\"](%/blocks.1/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.1/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/MatMul_1\"](%/blocks.1/attn/Softmax_output_0, %/blocks.1/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_840 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_22\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_840), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_844 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_23\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_844), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_24\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_846), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_5\"](%/blocks.1/attn/Unsqueeze_22_output_0, %/blocks.1/attn/Constant_28_output_0, %/blocks.1/attn/Unsqueeze_23_output_0, %/blocks.1/attn/Unsqueeze_24_output_0, %/blocks.1/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_5\"](%/blocks.1/attn/MatMul_1_output_0, %/blocks.1/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.1/attn/Transpose_2\"](%/blocks.1/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_25\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_853), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_26\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_855), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_27\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_857), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_6\"](%/blocks.1/attn/Unsqueeze_25_output_0, %/blocks.1/attn/Unsqueeze_26_output_0, %/blocks.1/attn/Unsqueeze_27_output_0, %/blocks.1/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_6\"](%/blocks.1/attn/Transpose_2_output_0, %/blocks.1/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/proj/MatMul\"](%/blocks.1/attn/Reshape_6_output_0, %onnx::MatMul_5659), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/proj/Add\"](%blocks.1.attn.proj.bias, %/blocks.1/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_5\"](%/blocks.1/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_5\"](%/blocks.1/Shape_5_output_0, %/blocks.1/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/Mul\"](%/blocks.1/Add_output_0, %/blocks.1/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_2\"](%/blocks.1/Mul_output_0, %/blocks.1/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_6\"](%/blocks.1/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_7\"](%/blocks.1/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_3\"](%/blocks.1/Cast_7_output_0, %/blocks.1/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_8\"](%/blocks.1/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_9\"](%/blocks.1/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_4\"](%/blocks.1/Gather_5_output_0, %/blocks.1/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_10\"](%/blocks.1/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_11\"](%/blocks.1/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_881 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_9\"](%/blocks.1/Cast_11_output_0, %onnx::Unsqueeze_881), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_10\"](%/blocks.1/Cast_3_output_0, %onnx::Unsqueeze_883), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_11\"](%/blocks.1/Cast_5_output_0, %onnx::Unsqueeze_885), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_5\"](%/blocks.1/Unsqueeze_9_output_0, %/blocks.1/Unsqueeze_10_output_0, %/blocks.1/Unsqueeze_11_output_0, %/blocks.1/Constant_36_output_0, %/blocks.1/Constant_37_output_0, %/blocks.1/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.1/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_4\"](%/blocks.1/attn/proj/Add_output_0, %/blocks.1/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.1/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.1/Transpose_2\"](%/blocks.1/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_12\"](%/blocks.1/Cast_11_output_0, %onnx::Unsqueeze_896), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_13\"](%/blocks.1/Add_output_0, %onnx::Unsqueeze_898), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_900 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_14\"](%/blocks.1/Add_1_output_0, %onnx::Unsqueeze_900), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_6\"](%/blocks.1/Unsqueeze_12_output_0, %/blocks.1/Unsqueeze_13_output_0, %/blocks.1/Unsqueeze_14_output_0, %/blocks.1/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.1/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_5\"](%/blocks.1/Transpose_2_output_0, %/blocks.1/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.1/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_15\"](%/blocks.1/Gather_output_0, %/blocks.1/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice_1\"](%/blocks.1/Reshape_5_output_0, %/blocks.1/Constant_41_output_0, %/blocks.1/Unsqueeze_15_output_0, %/blocks.1/Constant_40_output_0, %/blocks.1/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_16\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice_2\"](%/blocks.1/Slice_1_output_0, %/blocks.1/Constant_45_output_0, %/blocks.1/Unsqueeze_16_output_0, %/blocks.1/Constant_44_output_0, %/blocks.1/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_2\"](%/blocks.0/Add_3_output_0, %/blocks.1/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.1/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.1/norm2/LayerNormalization\"](%/blocks.1/Add_2_output_0, %blocks.1.norm2.weight, %blocks.1.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.1/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/mlp/lin1/MatMul\"](%/blocks.1/norm2/LayerNormalization_output_0, %onnx::MatMul_5670), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/lin1/Add\"](%blocks.1.mlp.lin1.bias, %/blocks.1/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.1/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/mlp/act/Div\"](%/blocks.1/mlp/lin1/Add_output_0, %/blocks.1/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.1/mlp/act/Erf\"](%/blocks.1/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/act/Add\"](%/blocks.1/mlp/act/Erf_output_0, %/blocks.1/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/mlp/act/Mul\"](%/blocks.1/mlp/lin1/Add_output_0, %/blocks.1/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.1/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/mlp/act/Mul_1\"](%/blocks.1/mlp/act/Mul_output_0, %/blocks.1/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/mlp/lin2/MatMul\"](%/blocks.1/mlp/act/Mul_1_output_0, %onnx::MatMul_5671), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/lin2/Add\"](%blocks.1.mlp.lin2.bias, %/blocks.1/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_3\"](%/blocks.1/Add_2_output_0, %/blocks.1/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.2/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.2/norm1/LayerNormalization\"](%/blocks.1/Add_3_output_0, %blocks.2.norm1.weight, %blocks.2.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.2/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather\"](%/blocks.2/Shape_output_0, %/blocks.2/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_1\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_1\"](%/blocks.2/Shape_1_output_0, %/blocks.2/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_2\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_2\"](%/blocks.2/Shape_2_output_0, %/blocks.2/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_3\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_3\"](%/blocks.2/Shape_3_output_0, %/blocks.2/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod\"](%/blocks.2/Gather_output_0, %/blocks.2/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub\"](%/blocks.2/Constant_5_output_0, %/blocks.2/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_1\"](%/blocks.2/Sub_output_0, %/blocks.2/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_2\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub_1\"](%/blocks.2/Constant_8_output_0, %/blocks.2/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_3\"](%/blocks.2/Sub_1_output_0, %/blocks.2/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze\"](%/blocks.2/Mod_3_output_0, %onnx::Unsqueeze_972), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_1\"](%/blocks.2/Mod_1_output_0, %onnx::Unsqueeze_976), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat\"](%/blocks.2/Constant_10_output_0, %/blocks.2/Constant_11_output_0, %/blocks.2/Constant_12_output_0, %/blocks.2/Unsqueeze_output_0, %/blocks.2/Constant_13_output_0, %/blocks.2/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_2\"](%/blocks.2/Mod_3_output_0, %onnx::Unsqueeze_985), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_989 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_3\"](%/blocks.2/Mod_1_output_0, %onnx::Unsqueeze_989), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_1\"](%/blocks.2/Constant_14_output_0, %/blocks.2/Constant_15_output_0, %/blocks.2/Constant_16_output_0, %/blocks.2/Unsqueeze_2_output_0, %/blocks.2/Constant_17_output_0, %/blocks.2/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_4\"](%/blocks.2/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_4\"](%/blocks.2/Shape_4_output_0, %/blocks.2/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.2/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub_2\"](%/blocks.2/Constant_19_output_0, %/blocks.2/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast\"](%/blocks.2/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.2/ConstantOfShape\"](%/blocks.2/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_2\"](%/blocks.2/Cast_output_0, %/blocks.2/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.2/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape\"](%/blocks.2/Concat_2_output_0, %/blocks.2/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.2/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice\"](%/blocks.2/Reshape_output_0, %/blocks.2/Constant_22_output_0, %/blocks.2/Constant_23_output_0, %/blocks.2/Constant_21_output_0, %/blocks.2/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.2/Transpose\"](%/blocks.2/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_1\"](%/blocks.2/Transpose_output_0, %/blocks.2/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_1\"](%/blocks.2/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.2/Pad\"](%/blocks.2/norm1/LayerNormalization_output_0, %/blocks.2/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add\"](%/blocks.2/Gather_output_0, %/blocks.2/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.2/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_1\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.2/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div\"](%/blocks.2/Add_output_0, %/blocks.2/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_2\"](%/blocks.2/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_3\"](%/blocks.2/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_1\"](%/blocks.2/Add_1_output_0, %/blocks.2/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_4\"](%/blocks.2/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_5\"](%/blocks.2/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_4\"](%/blocks.2/Gather_2_output_0, %onnx::Unsqueeze_1024), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1026 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_5\"](%/blocks.2/Cast_3_output_0, %onnx::Unsqueeze_1026), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1030 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_6\"](%/blocks.2/Cast_5_output_0, %onnx::Unsqueeze_1030), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1034 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_7\"](%/blocks.2/Gather_3_output_0, %onnx::Unsqueeze_1034), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_3\"](%/blocks.2/Unsqueeze_4_output_0, %/blocks.2/Unsqueeze_5_output_0, %/blocks.2/Constant_28_output_0, %/blocks.2/Unsqueeze_6_output_0, %/blocks.2/Constant_29_output_0, %/blocks.2/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.2/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_2\"](%/blocks.2/Pad_output_0, %/blocks.2/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.2/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.2/Transpose_1\"](%/blocks.2/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1045 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_8\"](%/blocks.2/Gather_3_output_0, %onnx::Unsqueeze_1045), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_4\"](%/blocks.2/Constant_30_output_0, %/blocks.2/Constant_31_output_0, %/blocks.2/Constant_32_output_0, %/blocks.2/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_3\"](%/blocks.2/Transpose_1_output_0, %/blocks.2/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather\"](%/blocks.2/attn/Shape_output_0, %/blocks.2/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_1\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_1\"](%/blocks.2/attn/Shape_1_output_0, %/blocks.2/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_2\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_2\"](%/blocks.2/attn/Shape_2_output_0, %/blocks.2/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/qkv/MatMul\"](%/blocks.2/Reshape_3_output_0, %onnx::MatMul_5686), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/qkv/Add\"](%blocks.2.attn.qkv.bias, %/blocks.2/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul\"](%/blocks.2/attn/Gather_1_output_0, %/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1062 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1062), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1064 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_1\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1064), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat\"](%/blocks.2/attn/Unsqueeze_output_0, %/blocks.2/attn/Unsqueeze_1_output_0, %/blocks.2/attn/Constant_3_output_0, %/blocks.2/attn/Constant_4_output_0, %/blocks.2/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape\"](%/blocks.2/attn/qkv/Add_output_0, %/blocks.2/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.2/attn/Transpose\"](%/blocks.2/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_1\"](%/blocks.2/attn/Gather_output_0, %/blocks.2/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1079 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_2\"](%/blocks.2/attn/Mul_1_output_0, %onnx::Unsqueeze_1079), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1081 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_3\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1081), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_1\"](%/blocks.2/attn/Constant_7_output_0, %/blocks.2/attn/Unsqueeze_2_output_0, %/blocks.2/attn/Unsqueeze_3_output_0, %/blocks.2/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_1\"](%/blocks.2/attn/Transpose_output_0, %/blocks.2/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.2/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.2/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.2/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.2/attn/Split\"](%/blocks.2/attn/Reshape_1_output_0, %/blocks.2/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze\"](%/blocks.2/attn/Split_output_0, %/blocks.2/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze_1\"](%/blocks.2/attn/Split_output_1, %/blocks.2/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze_2\"](%/blocks.2/attn/Split_output_2, %/blocks.2/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.2/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_2\"](%/blocks.2/attn/Squeeze_output_0, %/blocks.2/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.2/attn/Transpose_1\"](%/blocks.2/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/MatMul\"](%/blocks.2/attn/Mul_2_output_0, %/blocks.2/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.2/attn/Range\"](%/blocks.2/attn/Constant_14_output_0, %/blocks.2/attn/Cast_output_0, %/blocks.2/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_4\"](%/blocks.2/attn/Range_output_0, %/blocks.2/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_1\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_2\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/attn/Div\"](%/blocks.2/attn/Cast_1_output_0, %/blocks.2/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_3\"](%/blocks.2/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_3\"](%/blocks.2/attn/Cast_3_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_5\"](%/blocks.2/attn/Range_output_0, %/blocks.2/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_4\"](%/blocks.2/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_4\"](%/blocks.2/attn/Cast_4_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub\"](%/blocks.2/attn/Mul_3_output_0, %/blocks.2/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_1\"](%/blocks.2/attn/Gather_1_output_0, %/blocks.2/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_5\"](%/blocks.2/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_5\"](%/blocks.2/attn/Cast_5_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add\"](%/blocks.2/attn/Sub_output_0, %/blocks.2/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_6\"](%/blocks.2/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_3\"](%blocks.2.attn.rel_pos_h, %/blocks.2/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_7\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.2/attn/Range_1\"](%/blocks.2/attn/Constant_19_output_0, %/blocks.2/attn/Cast_7_output_0, %/blocks.2/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_6\"](%/blocks.2/attn/Range_1_output_0, %/blocks.2/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_8\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_9\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/attn/Div_1\"](%/blocks.2/attn/Cast_8_output_0, %/blocks.2/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_10\"](%/blocks.2/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_6\"](%/blocks.2/attn/Cast_10_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_7\"](%/blocks.2/attn/Range_1_output_0, %/blocks.2/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_11\"](%/blocks.2/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_7\"](%/blocks.2/attn/Cast_11_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_2\"](%/blocks.2/attn/Mul_6_output_0, %/blocks.2/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_3\"](%/blocks.2/attn/Gather_2_output_0, %/blocks.2/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_12\"](%/blocks.2/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_8\"](%/blocks.2/attn/Cast_12_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_1\"](%/blocks.2/attn/Sub_2_output_0, %/blocks.2/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_13\"](%/blocks.2/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_4\"](%blocks.2.attn.rel_pos_w, %/blocks.2/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_3\"](%/blocks.2/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_5\"](%/blocks.2/attn/Shape_3_output_0, %/blocks.2/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_4\"](%/blocks.2/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_6\"](%/blocks.2/attn/Shape_4_output_0, %/blocks.2/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_8\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1153), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_9\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1155), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_10\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1157), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_11\"](%/blocks.2/attn/Gather_6_output_0, %onnx::Unsqueeze_1159), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_2\"](%/blocks.2/attn/Unsqueeze_8_output_0, %/blocks.2/attn/Unsqueeze_9_output_0, %/blocks.2/attn/Unsqueeze_10_output_0, %/blocks.2/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.2/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_2\"](%/blocks.2/attn/Squeeze_output_0, %/blocks.2/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.2/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.2/attn/Einsum\"](%/blocks.2/attn/Reshape_2_output_0, %/blocks.2/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.2/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.2/attn/Einsum_1\"](%/blocks.2/attn/Reshape_2_output_0, %/blocks.2/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_12\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1165), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_13\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1167), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1169 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_14\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1169), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1171 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_15\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1171), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1173 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_16\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1173), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_3\"](%/blocks.2/attn/Unsqueeze_12_output_0, %/blocks.2/attn/Unsqueeze_13_output_0, %/blocks.2/attn/Unsqueeze_14_output_0, %/blocks.2/attn/Unsqueeze_15_output_0, %/blocks.2/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_3\"](%/blocks.2/attn/MatMul_output_0, %/blocks.2/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.2/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_17\"](%/blocks.2/attn/Einsum_output_0, %/blocks.2/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_2\"](%/blocks.2/attn/Reshape_3_output_0, %/blocks.2/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_18\"](%/blocks.2/attn/Einsum_1_output_0, %/blocks.2/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_3\"](%/blocks.2/attn/Add_2_output_0, %/blocks.2/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_19\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1183), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_20\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1185), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_21\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1187), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_4\"](%/blocks.2/attn/Unsqueeze_19_output_0, %/blocks.2/attn/Unsqueeze_20_output_0, %/blocks.2/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.2/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_4\"](%/blocks.2/attn/Add_3_output_0, %/blocks.2/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.2/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.2/attn/Softmax\"](%/blocks.2/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.2/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/MatMul_1\"](%/blocks.2/attn/Softmax_output_0, %/blocks.2/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_22\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1193), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_23\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1197), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_24\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1199), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_5\"](%/blocks.2/attn/Unsqueeze_22_output_0, %/blocks.2/attn/Constant_28_output_0, %/blocks.2/attn/Unsqueeze_23_output_0, %/blocks.2/attn/Unsqueeze_24_output_0, %/blocks.2/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_5\"](%/blocks.2/attn/MatMul_1_output_0, %/blocks.2/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.2/attn/Transpose_2\"](%/blocks.2/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_25\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1206), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1208 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_26\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1208), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1210 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_27\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1210), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_6\"](%/blocks.2/attn/Unsqueeze_25_output_0, %/blocks.2/attn/Unsqueeze_26_output_0, %/blocks.2/attn/Unsqueeze_27_output_0, %/blocks.2/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_6\"](%/blocks.2/attn/Transpose_2_output_0, %/blocks.2/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/proj/MatMul\"](%/blocks.2/attn/Reshape_6_output_0, %onnx::MatMul_5695), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/proj/Add\"](%blocks.2.attn.proj.bias, %/blocks.2/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_5\"](%/blocks.2/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_5\"](%/blocks.2/Shape_5_output_0, %/blocks.2/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/Mul\"](%/blocks.2/Add_output_0, %/blocks.2/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_2\"](%/blocks.2/Mul_output_0, %/blocks.2/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_6\"](%/blocks.2/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_7\"](%/blocks.2/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_3\"](%/blocks.2/Cast_7_output_0, %/blocks.2/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_8\"](%/blocks.2/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_9\"](%/blocks.2/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_4\"](%/blocks.2/Gather_5_output_0, %/blocks.2/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_10\"](%/blocks.2/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_11\"](%/blocks.2/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_9\"](%/blocks.2/Cast_11_output_0, %onnx::Unsqueeze_1234), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_10\"](%/blocks.2/Cast_3_output_0, %onnx::Unsqueeze_1236), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_11\"](%/blocks.2/Cast_5_output_0, %onnx::Unsqueeze_1238), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_5\"](%/blocks.2/Unsqueeze_9_output_0, %/blocks.2/Unsqueeze_10_output_0, %/blocks.2/Unsqueeze_11_output_0, %/blocks.2/Constant_36_output_0, %/blocks.2/Constant_37_output_0, %/blocks.2/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.2/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_4\"](%/blocks.2/attn/proj/Add_output_0, %/blocks.2/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.2/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.2/Transpose_2\"](%/blocks.2/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_12\"](%/blocks.2/Cast_11_output_0, %onnx::Unsqueeze_1249), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_13\"](%/blocks.2/Add_output_0, %onnx::Unsqueeze_1251), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_14\"](%/blocks.2/Add_1_output_0, %onnx::Unsqueeze_1253), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_6\"](%/blocks.2/Unsqueeze_12_output_0, %/blocks.2/Unsqueeze_13_output_0, %/blocks.2/Unsqueeze_14_output_0, %/blocks.2/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.2/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_5\"](%/blocks.2/Transpose_2_output_0, %/blocks.2/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.2/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_15\"](%/blocks.2/Gather_output_0, %/blocks.2/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice_1\"](%/blocks.2/Reshape_5_output_0, %/blocks.2/Constant_41_output_0, %/blocks.2/Unsqueeze_15_output_0, %/blocks.2/Constant_40_output_0, %/blocks.2/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_16\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice_2\"](%/blocks.2/Slice_1_output_0, %/blocks.2/Constant_45_output_0, %/blocks.2/Unsqueeze_16_output_0, %/blocks.2/Constant_44_output_0, %/blocks.2/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_2\"](%/blocks.1/Add_3_output_0, %/blocks.2/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.2/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.2/norm2/LayerNormalization\"](%/blocks.2/Add_2_output_0, %blocks.2.norm2.weight, %blocks.2.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.2/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/mlp/lin1/MatMul\"](%/blocks.2/norm2/LayerNormalization_output_0, %onnx::MatMul_5706), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/lin1/Add\"](%blocks.2.mlp.lin1.bias, %/blocks.2/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.2/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/mlp/act/Div\"](%/blocks.2/mlp/lin1/Add_output_0, %/blocks.2/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.2/mlp/act/Erf\"](%/blocks.2/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/act/Add\"](%/blocks.2/mlp/act/Erf_output_0, %/blocks.2/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/mlp/act/Mul\"](%/blocks.2/mlp/lin1/Add_output_0, %/blocks.2/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.2/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/mlp/act/Mul_1\"](%/blocks.2/mlp/act/Mul_output_0, %/blocks.2/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/mlp/lin2/MatMul\"](%/blocks.2/mlp/act/Mul_1_output_0, %onnx::MatMul_5707), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/lin2/Add\"](%blocks.2.mlp.lin2.bias, %/blocks.2/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_3\"](%/blocks.2/Add_2_output_0, %/blocks.2/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.3/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.3/norm1/LayerNormalization\"](%/blocks.2/Add_3_output_0, %blocks.3.norm1.weight, %blocks.3.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.3/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather\"](%/blocks.3/Shape_output_0, %/blocks.3/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_1\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_1\"](%/blocks.3/Shape_1_output_0, %/blocks.3/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_2\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_2\"](%/blocks.3/Shape_2_output_0, %/blocks.3/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_3\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_3\"](%/blocks.3/Shape_3_output_0, %/blocks.3/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod\"](%/blocks.3/Gather_output_0, %/blocks.3/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub\"](%/blocks.3/Constant_5_output_0, %/blocks.3/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_1\"](%/blocks.3/Sub_output_0, %/blocks.3/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_2\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub_1\"](%/blocks.3/Constant_8_output_0, %/blocks.3/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_3\"](%/blocks.3/Sub_1_output_0, %/blocks.3/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1325 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze\"](%/blocks.3/Mod_3_output_0, %onnx::Unsqueeze_1325), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_1\"](%/blocks.3/Mod_1_output_0, %onnx::Unsqueeze_1329), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat\"](%/blocks.3/Constant_10_output_0, %/blocks.3/Constant_11_output_0, %/blocks.3/Constant_12_output_0, %/blocks.3/Unsqueeze_output_0, %/blocks.3/Constant_13_output_0, %/blocks.3/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1338 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_2\"](%/blocks.3/Mod_3_output_0, %onnx::Unsqueeze_1338), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_3\"](%/blocks.3/Mod_1_output_0, %onnx::Unsqueeze_1342), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_1\"](%/blocks.3/Constant_14_output_0, %/blocks.3/Constant_15_output_0, %/blocks.3/Constant_16_output_0, %/blocks.3/Unsqueeze_2_output_0, %/blocks.3/Constant_17_output_0, %/blocks.3/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_4\"](%/blocks.3/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_4\"](%/blocks.3/Shape_4_output_0, %/blocks.3/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.3/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub_2\"](%/blocks.3/Constant_19_output_0, %/blocks.3/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast\"](%/blocks.3/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.3/ConstantOfShape\"](%/blocks.3/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_2\"](%/blocks.3/Cast_output_0, %/blocks.3/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.3/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape\"](%/blocks.3/Concat_2_output_0, %/blocks.3/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.3/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice\"](%/blocks.3/Reshape_output_0, %/blocks.3/Constant_22_output_0, %/blocks.3/Constant_23_output_0, %/blocks.3/Constant_21_output_0, %/blocks.3/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.3/Transpose\"](%/blocks.3/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_1\"](%/blocks.3/Transpose_output_0, %/blocks.3/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_1\"](%/blocks.3/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.3/Pad\"](%/blocks.3/norm1/LayerNormalization_output_0, %/blocks.3/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add\"](%/blocks.3/Gather_output_0, %/blocks.3/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.3/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_1\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.3/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div\"](%/blocks.3/Add_output_0, %/blocks.3/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_2\"](%/blocks.3/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_3\"](%/blocks.3/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_1\"](%/blocks.3/Add_1_output_0, %/blocks.3/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_4\"](%/blocks.3/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_5\"](%/blocks.3/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1377 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_4\"](%/blocks.3/Gather_2_output_0, %onnx::Unsqueeze_1377), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_5\"](%/blocks.3/Cast_3_output_0, %onnx::Unsqueeze_1379), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1383 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_6\"](%/blocks.3/Cast_5_output_0, %onnx::Unsqueeze_1383), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_7\"](%/blocks.3/Gather_3_output_0, %onnx::Unsqueeze_1387), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_3\"](%/blocks.3/Unsqueeze_4_output_0, %/blocks.3/Unsqueeze_5_output_0, %/blocks.3/Constant_28_output_0, %/blocks.3/Unsqueeze_6_output_0, %/blocks.3/Constant_29_output_0, %/blocks.3/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.3/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_2\"](%/blocks.3/Pad_output_0, %/blocks.3/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.3/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.3/Transpose_1\"](%/blocks.3/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1398 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_8\"](%/blocks.3/Gather_3_output_0, %onnx::Unsqueeze_1398), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_4\"](%/blocks.3/Constant_30_output_0, %/blocks.3/Constant_31_output_0, %/blocks.3/Constant_32_output_0, %/blocks.3/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_3\"](%/blocks.3/Transpose_1_output_0, %/blocks.3/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather\"](%/blocks.3/attn/Shape_output_0, %/blocks.3/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_1\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_1\"](%/blocks.3/attn/Shape_1_output_0, %/blocks.3/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_2\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_2\"](%/blocks.3/attn/Shape_2_output_0, %/blocks.3/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/qkv/MatMul\"](%/blocks.3/Reshape_3_output_0, %onnx::MatMul_5722), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/qkv/Add\"](%blocks.3.attn.qkv.bias, %/blocks.3/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul\"](%/blocks.3/attn/Gather_1_output_0, %/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1415 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1415), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1417 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_1\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1417), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat\"](%/blocks.3/attn/Unsqueeze_output_0, %/blocks.3/attn/Unsqueeze_1_output_0, %/blocks.3/attn/Constant_3_output_0, %/blocks.3/attn/Constant_4_output_0, %/blocks.3/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape\"](%/blocks.3/attn/qkv/Add_output_0, %/blocks.3/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.3/attn/Transpose\"](%/blocks.3/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_1\"](%/blocks.3/attn/Gather_output_0, %/blocks.3/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1432 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_2\"](%/blocks.3/attn/Mul_1_output_0, %onnx::Unsqueeze_1432), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1434 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_3\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1434), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_1\"](%/blocks.3/attn/Constant_7_output_0, %/blocks.3/attn/Unsqueeze_2_output_0, %/blocks.3/attn/Unsqueeze_3_output_0, %/blocks.3/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_1\"](%/blocks.3/attn/Transpose_output_0, %/blocks.3/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.3/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.3/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.3/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.3/attn/Split\"](%/blocks.3/attn/Reshape_1_output_0, %/blocks.3/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze\"](%/blocks.3/attn/Split_output_0, %/blocks.3/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze_1\"](%/blocks.3/attn/Split_output_1, %/blocks.3/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze_2\"](%/blocks.3/attn/Split_output_2, %/blocks.3/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.3/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_2\"](%/blocks.3/attn/Squeeze_output_0, %/blocks.3/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.3/attn/Transpose_1\"](%/blocks.3/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/MatMul\"](%/blocks.3/attn/Mul_2_output_0, %/blocks.3/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.3/attn/Range\"](%/blocks.3/attn/Constant_14_output_0, %/blocks.3/attn/Cast_output_0, %/blocks.3/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_4\"](%/blocks.3/attn/Range_output_0, %/blocks.3/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_1\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_2\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/attn/Div\"](%/blocks.3/attn/Cast_1_output_0, %/blocks.3/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_3\"](%/blocks.3/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_3\"](%/blocks.3/attn/Cast_3_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_5\"](%/blocks.3/attn/Range_output_0, %/blocks.3/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_4\"](%/blocks.3/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_4\"](%/blocks.3/attn/Cast_4_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub\"](%/blocks.3/attn/Mul_3_output_0, %/blocks.3/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_1\"](%/blocks.3/attn/Gather_1_output_0, %/blocks.3/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_5\"](%/blocks.3/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_5\"](%/blocks.3/attn/Cast_5_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add\"](%/blocks.3/attn/Sub_output_0, %/blocks.3/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_6\"](%/blocks.3/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_3\"](%blocks.3.attn.rel_pos_h, %/blocks.3/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_7\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.3/attn/Range_1\"](%/blocks.3/attn/Constant_19_output_0, %/blocks.3/attn/Cast_7_output_0, %/blocks.3/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_6\"](%/blocks.3/attn/Range_1_output_0, %/blocks.3/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_8\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_9\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/attn/Div_1\"](%/blocks.3/attn/Cast_8_output_0, %/blocks.3/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_10\"](%/blocks.3/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_6\"](%/blocks.3/attn/Cast_10_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_7\"](%/blocks.3/attn/Range_1_output_0, %/blocks.3/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_11\"](%/blocks.3/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_7\"](%/blocks.3/attn/Cast_11_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_2\"](%/blocks.3/attn/Mul_6_output_0, %/blocks.3/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_3\"](%/blocks.3/attn/Gather_2_output_0, %/blocks.3/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_12\"](%/blocks.3/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_8\"](%/blocks.3/attn/Cast_12_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_1\"](%/blocks.3/attn/Sub_2_output_0, %/blocks.3/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_13\"](%/blocks.3/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_4\"](%blocks.3.attn.rel_pos_w, %/blocks.3/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_3\"](%/blocks.3/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_5\"](%/blocks.3/attn/Shape_3_output_0, %/blocks.3/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_4\"](%/blocks.3/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_6\"](%/blocks.3/attn/Shape_4_output_0, %/blocks.3/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1506 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_8\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1506), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1508 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_9\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1508), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1510 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_10\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1510), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_11\"](%/blocks.3/attn/Gather_6_output_0, %onnx::Unsqueeze_1512), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_2\"](%/blocks.3/attn/Unsqueeze_8_output_0, %/blocks.3/attn/Unsqueeze_9_output_0, %/blocks.3/attn/Unsqueeze_10_output_0, %/blocks.3/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.3/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_2\"](%/blocks.3/attn/Squeeze_output_0, %/blocks.3/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.3/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.3/attn/Einsum\"](%/blocks.3/attn/Reshape_2_output_0, %/blocks.3/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.3/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.3/attn/Einsum_1\"](%/blocks.3/attn/Reshape_2_output_0, %/blocks.3/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1518 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_12\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1518), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_13\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1520), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_14\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1522), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1524 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_15\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1524), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1526 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_16\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1526), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_3\"](%/blocks.3/attn/Unsqueeze_12_output_0, %/blocks.3/attn/Unsqueeze_13_output_0, %/blocks.3/attn/Unsqueeze_14_output_0, %/blocks.3/attn/Unsqueeze_15_output_0, %/blocks.3/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_3\"](%/blocks.3/attn/MatMul_output_0, %/blocks.3/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.3/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_17\"](%/blocks.3/attn/Einsum_output_0, %/blocks.3/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_2\"](%/blocks.3/attn/Reshape_3_output_0, %/blocks.3/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_18\"](%/blocks.3/attn/Einsum_1_output_0, %/blocks.3/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_3\"](%/blocks.3/attn/Add_2_output_0, %/blocks.3/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_19\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1536), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_20\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1538), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_21\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1540), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_4\"](%/blocks.3/attn/Unsqueeze_19_output_0, %/blocks.3/attn/Unsqueeze_20_output_0, %/blocks.3/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.3/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_4\"](%/blocks.3/attn/Add_3_output_0, %/blocks.3/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.3/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.3/attn/Softmax\"](%/blocks.3/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.3/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/MatMul_1\"](%/blocks.3/attn/Softmax_output_0, %/blocks.3/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1546 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_22\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1546), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_23\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1550), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_24\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1552), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_5\"](%/blocks.3/attn/Unsqueeze_22_output_0, %/blocks.3/attn/Constant_28_output_0, %/blocks.3/attn/Unsqueeze_23_output_0, %/blocks.3/attn/Unsqueeze_24_output_0, %/blocks.3/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_5\"](%/blocks.3/attn/MatMul_1_output_0, %/blocks.3/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.3/attn/Transpose_2\"](%/blocks.3/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_25\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1559), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_26\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1561), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1563 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_27\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1563), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_6\"](%/blocks.3/attn/Unsqueeze_25_output_0, %/blocks.3/attn/Unsqueeze_26_output_0, %/blocks.3/attn/Unsqueeze_27_output_0, %/blocks.3/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_6\"](%/blocks.3/attn/Transpose_2_output_0, %/blocks.3/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/proj/MatMul\"](%/blocks.3/attn/Reshape_6_output_0, %onnx::MatMul_5731), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/proj/Add\"](%blocks.3.attn.proj.bias, %/blocks.3/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_5\"](%/blocks.3/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_5\"](%/blocks.3/Shape_5_output_0, %/blocks.3/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/Mul\"](%/blocks.3/Add_output_0, %/blocks.3/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_2\"](%/blocks.3/Mul_output_0, %/blocks.3/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_6\"](%/blocks.3/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_7\"](%/blocks.3/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_3\"](%/blocks.3/Cast_7_output_0, %/blocks.3/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_8\"](%/blocks.3/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_9\"](%/blocks.3/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_4\"](%/blocks.3/Gather_5_output_0, %/blocks.3/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_10\"](%/blocks.3/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_11\"](%/blocks.3/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_9\"](%/blocks.3/Cast_11_output_0, %onnx::Unsqueeze_1587), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_10\"](%/blocks.3/Cast_3_output_0, %onnx::Unsqueeze_1589), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_11\"](%/blocks.3/Cast_5_output_0, %onnx::Unsqueeze_1591), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_5\"](%/blocks.3/Unsqueeze_9_output_0, %/blocks.3/Unsqueeze_10_output_0, %/blocks.3/Unsqueeze_11_output_0, %/blocks.3/Constant_36_output_0, %/blocks.3/Constant_37_output_0, %/blocks.3/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.3/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_4\"](%/blocks.3/attn/proj/Add_output_0, %/blocks.3/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.3/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.3/Transpose_2\"](%/blocks.3/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_12\"](%/blocks.3/Cast_11_output_0, %onnx::Unsqueeze_1602), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1604 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_13\"](%/blocks.3/Add_output_0, %onnx::Unsqueeze_1604), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1606 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_14\"](%/blocks.3/Add_1_output_0, %onnx::Unsqueeze_1606), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_6\"](%/blocks.3/Unsqueeze_12_output_0, %/blocks.3/Unsqueeze_13_output_0, %/blocks.3/Unsqueeze_14_output_0, %/blocks.3/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.3/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_5\"](%/blocks.3/Transpose_2_output_0, %/blocks.3/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.3/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_15\"](%/blocks.3/Gather_output_0, %/blocks.3/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice_1\"](%/blocks.3/Reshape_5_output_0, %/blocks.3/Constant_41_output_0, %/blocks.3/Unsqueeze_15_output_0, %/blocks.3/Constant_40_output_0, %/blocks.3/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_16\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice_2\"](%/blocks.3/Slice_1_output_0, %/blocks.3/Constant_45_output_0, %/blocks.3/Unsqueeze_16_output_0, %/blocks.3/Constant_44_output_0, %/blocks.3/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_2\"](%/blocks.2/Add_3_output_0, %/blocks.3/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.3/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.3/norm2/LayerNormalization\"](%/blocks.3/Add_2_output_0, %blocks.3.norm2.weight, %blocks.3.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.3/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/mlp/lin1/MatMul\"](%/blocks.3/norm2/LayerNormalization_output_0, %onnx::MatMul_5742), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/lin1/Add\"](%blocks.3.mlp.lin1.bias, %/blocks.3/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.3/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/mlp/act/Div\"](%/blocks.3/mlp/lin1/Add_output_0, %/blocks.3/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.3/mlp/act/Erf\"](%/blocks.3/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/act/Add\"](%/blocks.3/mlp/act/Erf_output_0, %/blocks.3/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/mlp/act/Mul\"](%/blocks.3/mlp/lin1/Add_output_0, %/blocks.3/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.3/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/mlp/act/Mul_1\"](%/blocks.3/mlp/act/Mul_output_0, %/blocks.3/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/mlp/lin2/MatMul\"](%/blocks.3/mlp/act/Mul_1_output_0, %onnx::MatMul_5743), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/lin2/Add\"](%blocks.3.mlp.lin2.bias, %/blocks.3/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_3\"](%/blocks.3/Add_2_output_0, %/blocks.3/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.4/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.4/norm1/LayerNormalization\"](%/blocks.3/Add_3_output_0, %blocks.4.norm1.weight, %blocks.4.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.4/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather\"](%/blocks.4/Shape_output_0, %/blocks.4/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_1\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_1\"](%/blocks.4/Shape_1_output_0, %/blocks.4/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_2\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_2\"](%/blocks.4/Shape_2_output_0, %/blocks.4/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_3\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_3\"](%/blocks.4/Shape_3_output_0, %/blocks.4/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod\"](%/blocks.4/Gather_output_0, %/blocks.4/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub\"](%/blocks.4/Constant_5_output_0, %/blocks.4/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_1\"](%/blocks.4/Sub_output_0, %/blocks.4/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_2\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub_1\"](%/blocks.4/Constant_8_output_0, %/blocks.4/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_3\"](%/blocks.4/Sub_1_output_0, %/blocks.4/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze\"](%/blocks.4/Mod_3_output_0, %onnx::Unsqueeze_1678), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_1\"](%/blocks.4/Mod_1_output_0, %onnx::Unsqueeze_1682), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat\"](%/blocks.4/Constant_10_output_0, %/blocks.4/Constant_11_output_0, %/blocks.4/Constant_12_output_0, %/blocks.4/Unsqueeze_output_0, %/blocks.4/Constant_13_output_0, %/blocks.4/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1691 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_2\"](%/blocks.4/Mod_3_output_0, %onnx::Unsqueeze_1691), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1695 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_3\"](%/blocks.4/Mod_1_output_0, %onnx::Unsqueeze_1695), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_1\"](%/blocks.4/Constant_14_output_0, %/blocks.4/Constant_15_output_0, %/blocks.4/Constant_16_output_0, %/blocks.4/Unsqueeze_2_output_0, %/blocks.4/Constant_17_output_0, %/blocks.4/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_4\"](%/blocks.4/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_4\"](%/blocks.4/Shape_4_output_0, %/blocks.4/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.4/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub_2\"](%/blocks.4/Constant_19_output_0, %/blocks.4/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast\"](%/blocks.4/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.4/ConstantOfShape\"](%/blocks.4/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_2\"](%/blocks.4/Cast_output_0, %/blocks.4/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.4/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape\"](%/blocks.4/Concat_2_output_0, %/blocks.4/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.4/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice\"](%/blocks.4/Reshape_output_0, %/blocks.4/Constant_22_output_0, %/blocks.4/Constant_23_output_0, %/blocks.4/Constant_21_output_0, %/blocks.4/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.4/Transpose\"](%/blocks.4/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_1\"](%/blocks.4/Transpose_output_0, %/blocks.4/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_1\"](%/blocks.4/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.4/Pad\"](%/blocks.4/norm1/LayerNormalization_output_0, %/blocks.4/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add\"](%/blocks.4/Gather_output_0, %/blocks.4/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.4/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_1\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.4/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div\"](%/blocks.4/Add_output_0, %/blocks.4/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_2\"](%/blocks.4/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_3\"](%/blocks.4/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_1\"](%/blocks.4/Add_1_output_0, %/blocks.4/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_4\"](%/blocks.4/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_5\"](%/blocks.4/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1730 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_4\"](%/blocks.4/Gather_2_output_0, %onnx::Unsqueeze_1730), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_5\"](%/blocks.4/Cast_3_output_0, %onnx::Unsqueeze_1732), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1736 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_6\"](%/blocks.4/Cast_5_output_0, %onnx::Unsqueeze_1736), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_7\"](%/blocks.4/Gather_3_output_0, %onnx::Unsqueeze_1740), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_3\"](%/blocks.4/Unsqueeze_4_output_0, %/blocks.4/Unsqueeze_5_output_0, %/blocks.4/Constant_28_output_0, %/blocks.4/Unsqueeze_6_output_0, %/blocks.4/Constant_29_output_0, %/blocks.4/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.4/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_2\"](%/blocks.4/Pad_output_0, %/blocks.4/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.4/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.4/Transpose_1\"](%/blocks.4/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1751 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_8\"](%/blocks.4/Gather_3_output_0, %onnx::Unsqueeze_1751), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_4\"](%/blocks.4/Constant_30_output_0, %/blocks.4/Constant_31_output_0, %/blocks.4/Constant_32_output_0, %/blocks.4/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_3\"](%/blocks.4/Transpose_1_output_0, %/blocks.4/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather\"](%/blocks.4/attn/Shape_output_0, %/blocks.4/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_1\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_1\"](%/blocks.4/attn/Shape_1_output_0, %/blocks.4/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_2\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_2\"](%/blocks.4/attn/Shape_2_output_0, %/blocks.4/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/qkv/MatMul\"](%/blocks.4/Reshape_3_output_0, %onnx::MatMul_5758), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/qkv/Add\"](%blocks.4.attn.qkv.bias, %/blocks.4/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul\"](%/blocks.4/attn/Gather_1_output_0, %/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1768 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1768), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1770 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_1\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1770), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat\"](%/blocks.4/attn/Unsqueeze_output_0, %/blocks.4/attn/Unsqueeze_1_output_0, %/blocks.4/attn/Constant_3_output_0, %/blocks.4/attn/Constant_4_output_0, %/blocks.4/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape\"](%/blocks.4/attn/qkv/Add_output_0, %/blocks.4/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.4/attn/Transpose\"](%/blocks.4/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_1\"](%/blocks.4/attn/Gather_output_0, %/blocks.4/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1785 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_2\"](%/blocks.4/attn/Mul_1_output_0, %onnx::Unsqueeze_1785), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_3\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1787), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_1\"](%/blocks.4/attn/Constant_7_output_0, %/blocks.4/attn/Unsqueeze_2_output_0, %/blocks.4/attn/Unsqueeze_3_output_0, %/blocks.4/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_1\"](%/blocks.4/attn/Transpose_output_0, %/blocks.4/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.4/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.4/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.4/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.4/attn/Split\"](%/blocks.4/attn/Reshape_1_output_0, %/blocks.4/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze\"](%/blocks.4/attn/Split_output_0, %/blocks.4/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze_1\"](%/blocks.4/attn/Split_output_1, %/blocks.4/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze_2\"](%/blocks.4/attn/Split_output_2, %/blocks.4/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.4/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_2\"](%/blocks.4/attn/Squeeze_output_0, %/blocks.4/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.4/attn/Transpose_1\"](%/blocks.4/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/MatMul\"](%/blocks.4/attn/Mul_2_output_0, %/blocks.4/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.4/attn/Range\"](%/blocks.4/attn/Constant_14_output_0, %/blocks.4/attn/Cast_output_0, %/blocks.4/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_4\"](%/blocks.4/attn/Range_output_0, %/blocks.4/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_1\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_2\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/attn/Div\"](%/blocks.4/attn/Cast_1_output_0, %/blocks.4/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_3\"](%/blocks.4/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_3\"](%/blocks.4/attn/Cast_3_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_5\"](%/blocks.4/attn/Range_output_0, %/blocks.4/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_4\"](%/blocks.4/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_4\"](%/blocks.4/attn/Cast_4_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub\"](%/blocks.4/attn/Mul_3_output_0, %/blocks.4/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_1\"](%/blocks.4/attn/Gather_1_output_0, %/blocks.4/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_5\"](%/blocks.4/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_5\"](%/blocks.4/attn/Cast_5_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add\"](%/blocks.4/attn/Sub_output_0, %/blocks.4/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_6\"](%/blocks.4/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_3\"](%blocks.4.attn.rel_pos_h, %/blocks.4/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_7\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.4/attn/Range_1\"](%/blocks.4/attn/Constant_19_output_0, %/blocks.4/attn/Cast_7_output_0, %/blocks.4/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_6\"](%/blocks.4/attn/Range_1_output_0, %/blocks.4/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_8\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_9\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/attn/Div_1\"](%/blocks.4/attn/Cast_8_output_0, %/blocks.4/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_10\"](%/blocks.4/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_6\"](%/blocks.4/attn/Cast_10_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_7\"](%/blocks.4/attn/Range_1_output_0, %/blocks.4/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_11\"](%/blocks.4/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_7\"](%/blocks.4/attn/Cast_11_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_2\"](%/blocks.4/attn/Mul_6_output_0, %/blocks.4/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_3\"](%/blocks.4/attn/Gather_2_output_0, %/blocks.4/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_12\"](%/blocks.4/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_8\"](%/blocks.4/attn/Cast_12_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_1\"](%/blocks.4/attn/Sub_2_output_0, %/blocks.4/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_13\"](%/blocks.4/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_4\"](%blocks.4.attn.rel_pos_w, %/blocks.4/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_3\"](%/blocks.4/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_5\"](%/blocks.4/attn/Shape_3_output_0, %/blocks.4/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_4\"](%/blocks.4/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_6\"](%/blocks.4/attn/Shape_4_output_0, %/blocks.4/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_8\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1859), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_9\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1861), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_10\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1863), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_11\"](%/blocks.4/attn/Gather_6_output_0, %onnx::Unsqueeze_1865), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_2\"](%/blocks.4/attn/Unsqueeze_8_output_0, %/blocks.4/attn/Unsqueeze_9_output_0, %/blocks.4/attn/Unsqueeze_10_output_0, %/blocks.4/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.4/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_2\"](%/blocks.4/attn/Squeeze_output_0, %/blocks.4/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.4/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.4/attn/Einsum\"](%/blocks.4/attn/Reshape_2_output_0, %/blocks.4/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.4/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.4/attn/Einsum_1\"](%/blocks.4/attn/Reshape_2_output_0, %/blocks.4/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1871 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_12\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1871), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1873 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_13\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1873), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_14\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1875), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_15\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1877), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1879 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_16\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1879), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_3\"](%/blocks.4/attn/Unsqueeze_12_output_0, %/blocks.4/attn/Unsqueeze_13_output_0, %/blocks.4/attn/Unsqueeze_14_output_0, %/blocks.4/attn/Unsqueeze_15_output_0, %/blocks.4/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_3\"](%/blocks.4/attn/MatMul_output_0, %/blocks.4/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.4/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_17\"](%/blocks.4/attn/Einsum_output_0, %/blocks.4/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_2\"](%/blocks.4/attn/Reshape_3_output_0, %/blocks.4/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_18\"](%/blocks.4/attn/Einsum_1_output_0, %/blocks.4/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_3\"](%/blocks.4/attn/Add_2_output_0, %/blocks.4/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_19\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1889), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_20\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1891), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_21\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1893), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_4\"](%/blocks.4/attn/Unsqueeze_19_output_0, %/blocks.4/attn/Unsqueeze_20_output_0, %/blocks.4/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.4/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_4\"](%/blocks.4/attn/Add_3_output_0, %/blocks.4/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.4/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.4/attn/Softmax\"](%/blocks.4/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.4/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/MatMul_1\"](%/blocks.4/attn/Softmax_output_0, %/blocks.4/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_22\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1899), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_23\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1903), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_24\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1905), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_5\"](%/blocks.4/attn/Unsqueeze_22_output_0, %/blocks.4/attn/Constant_28_output_0, %/blocks.4/attn/Unsqueeze_23_output_0, %/blocks.4/attn/Unsqueeze_24_output_0, %/blocks.4/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_5\"](%/blocks.4/attn/MatMul_1_output_0, %/blocks.4/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.4/attn/Transpose_2\"](%/blocks.4/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_25\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1912), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1914 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_26\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1914), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1916 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_27\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1916), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_6\"](%/blocks.4/attn/Unsqueeze_25_output_0, %/blocks.4/attn/Unsqueeze_26_output_0, %/blocks.4/attn/Unsqueeze_27_output_0, %/blocks.4/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_6\"](%/blocks.4/attn/Transpose_2_output_0, %/blocks.4/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/proj/MatMul\"](%/blocks.4/attn/Reshape_6_output_0, %onnx::MatMul_5767), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/proj/Add\"](%blocks.4.attn.proj.bias, %/blocks.4/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_5\"](%/blocks.4/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_5\"](%/blocks.4/Shape_5_output_0, %/blocks.4/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/Mul\"](%/blocks.4/Add_output_0, %/blocks.4/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_2\"](%/blocks.4/Mul_output_0, %/blocks.4/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_6\"](%/blocks.4/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_7\"](%/blocks.4/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_3\"](%/blocks.4/Cast_7_output_0, %/blocks.4/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_8\"](%/blocks.4/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_9\"](%/blocks.4/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_4\"](%/blocks.4/Gather_5_output_0, %/blocks.4/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_10\"](%/blocks.4/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_11\"](%/blocks.4/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_9\"](%/blocks.4/Cast_11_output_0, %onnx::Unsqueeze_1940), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_10\"](%/blocks.4/Cast_3_output_0, %onnx::Unsqueeze_1942), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_11\"](%/blocks.4/Cast_5_output_0, %onnx::Unsqueeze_1944), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_5\"](%/blocks.4/Unsqueeze_9_output_0, %/blocks.4/Unsqueeze_10_output_0, %/blocks.4/Unsqueeze_11_output_0, %/blocks.4/Constant_36_output_0, %/blocks.4/Constant_37_output_0, %/blocks.4/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.4/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_4\"](%/blocks.4/attn/proj/Add_output_0, %/blocks.4/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.4/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.4/Transpose_2\"](%/blocks.4/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1955 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_12\"](%/blocks.4/Cast_11_output_0, %onnx::Unsqueeze_1955), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1957 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_13\"](%/blocks.4/Add_output_0, %onnx::Unsqueeze_1957), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1959 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_14\"](%/blocks.4/Add_1_output_0, %onnx::Unsqueeze_1959), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_6\"](%/blocks.4/Unsqueeze_12_output_0, %/blocks.4/Unsqueeze_13_output_0, %/blocks.4/Unsqueeze_14_output_0, %/blocks.4/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.4/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_5\"](%/blocks.4/Transpose_2_output_0, %/blocks.4/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.4/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_15\"](%/blocks.4/Gather_output_0, %/blocks.4/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice_1\"](%/blocks.4/Reshape_5_output_0, %/blocks.4/Constant_41_output_0, %/blocks.4/Unsqueeze_15_output_0, %/blocks.4/Constant_40_output_0, %/blocks.4/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_16\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice_2\"](%/blocks.4/Slice_1_output_0, %/blocks.4/Constant_45_output_0, %/blocks.4/Unsqueeze_16_output_0, %/blocks.4/Constant_44_output_0, %/blocks.4/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_2\"](%/blocks.3/Add_3_output_0, %/blocks.4/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.4/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.4/norm2/LayerNormalization\"](%/blocks.4/Add_2_output_0, %blocks.4.norm2.weight, %blocks.4.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.4/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/mlp/lin1/MatMul\"](%/blocks.4/norm2/LayerNormalization_output_0, %onnx::MatMul_5778), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/lin1/Add\"](%blocks.4.mlp.lin1.bias, %/blocks.4/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.4/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/mlp/act/Div\"](%/blocks.4/mlp/lin1/Add_output_0, %/blocks.4/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.4/mlp/act/Erf\"](%/blocks.4/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/act/Add\"](%/blocks.4/mlp/act/Erf_output_0, %/blocks.4/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/mlp/act/Mul\"](%/blocks.4/mlp/lin1/Add_output_0, %/blocks.4/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.4/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/mlp/act/Mul_1\"](%/blocks.4/mlp/act/Mul_output_0, %/blocks.4/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/mlp/lin2/MatMul\"](%/blocks.4/mlp/act/Mul_1_output_0, %onnx::MatMul_5779), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/lin2/Add\"](%blocks.4.mlp.lin2.bias, %/blocks.4/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_3\"](%/blocks.4/Add_2_output_0, %/blocks.4/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.5/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.5/norm1/LayerNormalization\"](%/blocks.4/Add_3_output_0, %blocks.5.norm1.weight, %blocks.5.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.5/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather\"](%/blocks.5/Shape_output_0, %/blocks.5/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_1\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_1\"](%/blocks.5/Shape_1_output_0, %/blocks.5/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_2\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_2\"](%/blocks.5/Shape_2_output_0, %/blocks.5/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_3\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_3\"](%/blocks.5/Shape_3_output_0, %/blocks.5/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod\"](%/blocks.5/Gather_output_0, %/blocks.5/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub\"](%/blocks.5/Constant_5_output_0, %/blocks.5/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_1\"](%/blocks.5/Sub_output_0, %/blocks.5/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_2\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub_1\"](%/blocks.5/Constant_8_output_0, %/blocks.5/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_3\"](%/blocks.5/Sub_1_output_0, %/blocks.5/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze\"](%/blocks.5/Mod_3_output_0, %onnx::Unsqueeze_2031), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_1\"](%/blocks.5/Mod_1_output_0, %onnx::Unsqueeze_2035), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat\"](%/blocks.5/Constant_10_output_0, %/blocks.5/Constant_11_output_0, %/blocks.5/Constant_12_output_0, %/blocks.5/Unsqueeze_output_0, %/blocks.5/Constant_13_output_0, %/blocks.5/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2044 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_2\"](%/blocks.5/Mod_3_output_0, %onnx::Unsqueeze_2044), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2048 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_3\"](%/blocks.5/Mod_1_output_0, %onnx::Unsqueeze_2048), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_1\"](%/blocks.5/Constant_14_output_0, %/blocks.5/Constant_15_output_0, %/blocks.5/Constant_16_output_0, %/blocks.5/Unsqueeze_2_output_0, %/blocks.5/Constant_17_output_0, %/blocks.5/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_4\"](%/blocks.5/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_4\"](%/blocks.5/Shape_4_output_0, %/blocks.5/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.5/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub_2\"](%/blocks.5/Constant_19_output_0, %/blocks.5/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast\"](%/blocks.5/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.5/ConstantOfShape\"](%/blocks.5/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_2\"](%/blocks.5/Cast_output_0, %/blocks.5/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.5/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape\"](%/blocks.5/Concat_2_output_0, %/blocks.5/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.5/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice\"](%/blocks.5/Reshape_output_0, %/blocks.5/Constant_22_output_0, %/blocks.5/Constant_23_output_0, %/blocks.5/Constant_21_output_0, %/blocks.5/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.5/Transpose\"](%/blocks.5/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_1\"](%/blocks.5/Transpose_output_0, %/blocks.5/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_1\"](%/blocks.5/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.5/Pad\"](%/blocks.5/norm1/LayerNormalization_output_0, %/blocks.5/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add\"](%/blocks.5/Gather_output_0, %/blocks.5/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.5/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_1\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.5/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div\"](%/blocks.5/Add_output_0, %/blocks.5/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_2\"](%/blocks.5/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_3\"](%/blocks.5/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_1\"](%/blocks.5/Add_1_output_0, %/blocks.5/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_4\"](%/blocks.5/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_5\"](%/blocks.5/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2083 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_4\"](%/blocks.5/Gather_2_output_0, %onnx::Unsqueeze_2083), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2085 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_5\"](%/blocks.5/Cast_3_output_0, %onnx::Unsqueeze_2085), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2089 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_6\"](%/blocks.5/Cast_5_output_0, %onnx::Unsqueeze_2089), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_7\"](%/blocks.5/Gather_3_output_0, %onnx::Unsqueeze_2093), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_3\"](%/blocks.5/Unsqueeze_4_output_0, %/blocks.5/Unsqueeze_5_output_0, %/blocks.5/Constant_28_output_0, %/blocks.5/Unsqueeze_6_output_0, %/blocks.5/Constant_29_output_0, %/blocks.5/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.5/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_2\"](%/blocks.5/Pad_output_0, %/blocks.5/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.5/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.5/Transpose_1\"](%/blocks.5/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2104 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_8\"](%/blocks.5/Gather_3_output_0, %onnx::Unsqueeze_2104), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_4\"](%/blocks.5/Constant_30_output_0, %/blocks.5/Constant_31_output_0, %/blocks.5/Constant_32_output_0, %/blocks.5/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_3\"](%/blocks.5/Transpose_1_output_0, %/blocks.5/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather\"](%/blocks.5/attn/Shape_output_0, %/blocks.5/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_1\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_1\"](%/blocks.5/attn/Shape_1_output_0, %/blocks.5/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_2\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_2\"](%/blocks.5/attn/Shape_2_output_0, %/blocks.5/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/qkv/MatMul\"](%/blocks.5/Reshape_3_output_0, %onnx::MatMul_5794), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/qkv/Add\"](%blocks.5.attn.qkv.bias, %/blocks.5/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul\"](%/blocks.5/attn/Gather_1_output_0, %/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2121 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2121), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2123 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_1\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2123), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat\"](%/blocks.5/attn/Unsqueeze_output_0, %/blocks.5/attn/Unsqueeze_1_output_0, %/blocks.5/attn/Constant_3_output_0, %/blocks.5/attn/Constant_4_output_0, %/blocks.5/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape\"](%/blocks.5/attn/qkv/Add_output_0, %/blocks.5/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.5/attn/Transpose\"](%/blocks.5/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_1\"](%/blocks.5/attn/Gather_output_0, %/blocks.5/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_2\"](%/blocks.5/attn/Mul_1_output_0, %onnx::Unsqueeze_2138), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_3\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2140), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_1\"](%/blocks.5/attn/Constant_7_output_0, %/blocks.5/attn/Unsqueeze_2_output_0, %/blocks.5/attn/Unsqueeze_3_output_0, %/blocks.5/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_1\"](%/blocks.5/attn/Transpose_output_0, %/blocks.5/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.5/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.5/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.5/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.5/attn/Split\"](%/blocks.5/attn/Reshape_1_output_0, %/blocks.5/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze\"](%/blocks.5/attn/Split_output_0, %/blocks.5/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze_1\"](%/blocks.5/attn/Split_output_1, %/blocks.5/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze_2\"](%/blocks.5/attn/Split_output_2, %/blocks.5/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.5/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_2\"](%/blocks.5/attn/Squeeze_output_0, %/blocks.5/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.5/attn/Transpose_1\"](%/blocks.5/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/MatMul\"](%/blocks.5/attn/Mul_2_output_0, %/blocks.5/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.5/attn/Range\"](%/blocks.5/attn/Constant_14_output_0, %/blocks.5/attn/Cast_output_0, %/blocks.5/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_4\"](%/blocks.5/attn/Range_output_0, %/blocks.5/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_1\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_2\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/attn/Div\"](%/blocks.5/attn/Cast_1_output_0, %/blocks.5/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_3\"](%/blocks.5/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_3\"](%/blocks.5/attn/Cast_3_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_5\"](%/blocks.5/attn/Range_output_0, %/blocks.5/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_4\"](%/blocks.5/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_4\"](%/blocks.5/attn/Cast_4_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub\"](%/blocks.5/attn/Mul_3_output_0, %/blocks.5/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_1\"](%/blocks.5/attn/Gather_1_output_0, %/blocks.5/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_5\"](%/blocks.5/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_5\"](%/blocks.5/attn/Cast_5_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add\"](%/blocks.5/attn/Sub_output_0, %/blocks.5/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_6\"](%/blocks.5/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_3\"](%blocks.5.attn.rel_pos_h, %/blocks.5/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_7\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.5/attn/Range_1\"](%/blocks.5/attn/Constant_19_output_0, %/blocks.5/attn/Cast_7_output_0, %/blocks.5/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_6\"](%/blocks.5/attn/Range_1_output_0, %/blocks.5/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_8\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_9\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/attn/Div_1\"](%/blocks.5/attn/Cast_8_output_0, %/blocks.5/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_10\"](%/blocks.5/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_6\"](%/blocks.5/attn/Cast_10_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_7\"](%/blocks.5/attn/Range_1_output_0, %/blocks.5/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_11\"](%/blocks.5/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_7\"](%/blocks.5/attn/Cast_11_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_2\"](%/blocks.5/attn/Mul_6_output_0, %/blocks.5/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_3\"](%/blocks.5/attn/Gather_2_output_0, %/blocks.5/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_12\"](%/blocks.5/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_8\"](%/blocks.5/attn/Cast_12_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_1\"](%/blocks.5/attn/Sub_2_output_0, %/blocks.5/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_13\"](%/blocks.5/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_4\"](%blocks.5.attn.rel_pos_w, %/blocks.5/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_3\"](%/blocks.5/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_5\"](%/blocks.5/attn/Shape_3_output_0, %/blocks.5/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_4\"](%/blocks.5/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_6\"](%/blocks.5/attn/Shape_4_output_0, %/blocks.5/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2212 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_8\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2212), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2214 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_9\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2214), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2216 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_10\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2216), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_11\"](%/blocks.5/attn/Gather_6_output_0, %onnx::Unsqueeze_2218), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_2\"](%/blocks.5/attn/Unsqueeze_8_output_0, %/blocks.5/attn/Unsqueeze_9_output_0, %/blocks.5/attn/Unsqueeze_10_output_0, %/blocks.5/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.5/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_2\"](%/blocks.5/attn/Squeeze_output_0, %/blocks.5/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.5/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.5/attn/Einsum\"](%/blocks.5/attn/Reshape_2_output_0, %/blocks.5/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.5/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.5/attn/Einsum_1\"](%/blocks.5/attn/Reshape_2_output_0, %/blocks.5/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_12\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2224), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_13\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2226), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_14\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2228), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_15\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2230), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_16\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2232), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_3\"](%/blocks.5/attn/Unsqueeze_12_output_0, %/blocks.5/attn/Unsqueeze_13_output_0, %/blocks.5/attn/Unsqueeze_14_output_0, %/blocks.5/attn/Unsqueeze_15_output_0, %/blocks.5/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_3\"](%/blocks.5/attn/MatMul_output_0, %/blocks.5/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.5/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_17\"](%/blocks.5/attn/Einsum_output_0, %/blocks.5/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_2\"](%/blocks.5/attn/Reshape_3_output_0, %/blocks.5/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_18\"](%/blocks.5/attn/Einsum_1_output_0, %/blocks.5/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_3\"](%/blocks.5/attn/Add_2_output_0, %/blocks.5/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_19\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2242), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_20\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2244), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2246 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_21\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2246), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_4\"](%/blocks.5/attn/Unsqueeze_19_output_0, %/blocks.5/attn/Unsqueeze_20_output_0, %/blocks.5/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.5/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_4\"](%/blocks.5/attn/Add_3_output_0, %/blocks.5/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.5/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.5/attn/Softmax\"](%/blocks.5/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.5/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/MatMul_1\"](%/blocks.5/attn/Softmax_output_0, %/blocks.5/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_22\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2252), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_23\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2256), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2258 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_24\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2258), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_5\"](%/blocks.5/attn/Unsqueeze_22_output_0, %/blocks.5/attn/Constant_28_output_0, %/blocks.5/attn/Unsqueeze_23_output_0, %/blocks.5/attn/Unsqueeze_24_output_0, %/blocks.5/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_5\"](%/blocks.5/attn/MatMul_1_output_0, %/blocks.5/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.5/attn/Transpose_2\"](%/blocks.5/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_25\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_26\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2267), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2269 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_27\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2269), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_6\"](%/blocks.5/attn/Unsqueeze_25_output_0, %/blocks.5/attn/Unsqueeze_26_output_0, %/blocks.5/attn/Unsqueeze_27_output_0, %/blocks.5/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_6\"](%/blocks.5/attn/Transpose_2_output_0, %/blocks.5/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/proj/MatMul\"](%/blocks.5/attn/Reshape_6_output_0, %onnx::MatMul_5803), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/proj/Add\"](%blocks.5.attn.proj.bias, %/blocks.5/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_5\"](%/blocks.5/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_5\"](%/blocks.5/Shape_5_output_0, %/blocks.5/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/Mul\"](%/blocks.5/Add_output_0, %/blocks.5/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_2\"](%/blocks.5/Mul_output_0, %/blocks.5/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_6\"](%/blocks.5/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_7\"](%/blocks.5/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_3\"](%/blocks.5/Cast_7_output_0, %/blocks.5/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_8\"](%/blocks.5/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_9\"](%/blocks.5/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_4\"](%/blocks.5/Gather_5_output_0, %/blocks.5/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_10\"](%/blocks.5/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_11\"](%/blocks.5/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_9\"](%/blocks.5/Cast_11_output_0, %onnx::Unsqueeze_2293), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_10\"](%/blocks.5/Cast_3_output_0, %onnx::Unsqueeze_2295), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_11\"](%/blocks.5/Cast_5_output_0, %onnx::Unsqueeze_2297), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_5\"](%/blocks.5/Unsqueeze_9_output_0, %/blocks.5/Unsqueeze_10_output_0, %/blocks.5/Unsqueeze_11_output_0, %/blocks.5/Constant_36_output_0, %/blocks.5/Constant_37_output_0, %/blocks.5/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.5/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_4\"](%/blocks.5/attn/proj/Add_output_0, %/blocks.5/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.5/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.5/Transpose_2\"](%/blocks.5/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_2308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_12\"](%/blocks.5/Cast_11_output_0, %onnx::Unsqueeze_2308), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2310 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_13\"](%/blocks.5/Add_output_0, %onnx::Unsqueeze_2310), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2312 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_14\"](%/blocks.5/Add_1_output_0, %onnx::Unsqueeze_2312), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_6\"](%/blocks.5/Unsqueeze_12_output_0, %/blocks.5/Unsqueeze_13_output_0, %/blocks.5/Unsqueeze_14_output_0, %/blocks.5/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.5/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_5\"](%/blocks.5/Transpose_2_output_0, %/blocks.5/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.5/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_15\"](%/blocks.5/Gather_output_0, %/blocks.5/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice_1\"](%/blocks.5/Reshape_5_output_0, %/blocks.5/Constant_41_output_0, %/blocks.5/Unsqueeze_15_output_0, %/blocks.5/Constant_40_output_0, %/blocks.5/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_16\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice_2\"](%/blocks.5/Slice_1_output_0, %/blocks.5/Constant_45_output_0, %/blocks.5/Unsqueeze_16_output_0, %/blocks.5/Constant_44_output_0, %/blocks.5/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_2\"](%/blocks.4/Add_3_output_0, %/blocks.5/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.5/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.5/norm2/LayerNormalization\"](%/blocks.5/Add_2_output_0, %blocks.5.norm2.weight, %blocks.5.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.5/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/mlp/lin1/MatMul\"](%/blocks.5/norm2/LayerNormalization_output_0, %onnx::MatMul_5814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/lin1/Add\"](%blocks.5.mlp.lin1.bias, %/blocks.5/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.5/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/mlp/act/Div\"](%/blocks.5/mlp/lin1/Add_output_0, %/blocks.5/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.5/mlp/act/Erf\"](%/blocks.5/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/act/Add\"](%/blocks.5/mlp/act/Erf_output_0, %/blocks.5/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/mlp/act/Mul\"](%/blocks.5/mlp/lin1/Add_output_0, %/blocks.5/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.5/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/mlp/act/Mul_1\"](%/blocks.5/mlp/act/Mul_output_0, %/blocks.5/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/mlp/lin2/MatMul\"](%/blocks.5/mlp/act/Mul_1_output_0, %onnx::MatMul_5815), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/lin2/Add\"](%blocks.5.mlp.lin2.bias, %/blocks.5/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_3\"](%/blocks.5/Add_2_output_0, %/blocks.5/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.6/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.6/norm1/LayerNormalization\"](%/blocks.5/Add_3_output_0, %blocks.6.norm1.weight, %blocks.6.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.6/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather\"](%/blocks.6/Shape_output_0, %/blocks.6/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_1\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_1\"](%/blocks.6/Shape_1_output_0, %/blocks.6/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_2\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_2\"](%/blocks.6/Shape_2_output_0, %/blocks.6/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_3\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_3\"](%/blocks.6/Shape_3_output_0, %/blocks.6/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod\"](%/blocks.6/Gather_output_0, %/blocks.6/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub\"](%/blocks.6/Constant_5_output_0, %/blocks.6/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_1\"](%/blocks.6/Sub_output_0, %/blocks.6/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_2\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub_1\"](%/blocks.6/Constant_8_output_0, %/blocks.6/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_3\"](%/blocks.6/Sub_1_output_0, %/blocks.6/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze\"](%/blocks.6/Mod_3_output_0, %onnx::Unsqueeze_2384), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_1\"](%/blocks.6/Mod_1_output_0, %onnx::Unsqueeze_2388), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat\"](%/blocks.6/Constant_10_output_0, %/blocks.6/Constant_11_output_0, %/blocks.6/Constant_12_output_0, %/blocks.6/Unsqueeze_output_0, %/blocks.6/Constant_13_output_0, %/blocks.6/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2397 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_2\"](%/blocks.6/Mod_3_output_0, %onnx::Unsqueeze_2397), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2401 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_3\"](%/blocks.6/Mod_1_output_0, %onnx::Unsqueeze_2401), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_1\"](%/blocks.6/Constant_14_output_0, %/blocks.6/Constant_15_output_0, %/blocks.6/Constant_16_output_0, %/blocks.6/Unsqueeze_2_output_0, %/blocks.6/Constant_17_output_0, %/blocks.6/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_4\"](%/blocks.6/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_4\"](%/blocks.6/Shape_4_output_0, %/blocks.6/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.6/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub_2\"](%/blocks.6/Constant_19_output_0, %/blocks.6/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast\"](%/blocks.6/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.6/ConstantOfShape\"](%/blocks.6/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_2\"](%/blocks.6/Cast_output_0, %/blocks.6/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.6/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape\"](%/blocks.6/Concat_2_output_0, %/blocks.6/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.6/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice\"](%/blocks.6/Reshape_output_0, %/blocks.6/Constant_22_output_0, %/blocks.6/Constant_23_output_0, %/blocks.6/Constant_21_output_0, %/blocks.6/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.6/Transpose\"](%/blocks.6/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_1\"](%/blocks.6/Transpose_output_0, %/blocks.6/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_1\"](%/blocks.6/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.6/Pad\"](%/blocks.6/norm1/LayerNormalization_output_0, %/blocks.6/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add\"](%/blocks.6/Gather_output_0, %/blocks.6/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.6/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_1\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.6/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div\"](%/blocks.6/Add_output_0, %/blocks.6/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_2\"](%/blocks.6/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_3\"](%/blocks.6/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_1\"](%/blocks.6/Add_1_output_0, %/blocks.6/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_4\"](%/blocks.6/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_5\"](%/blocks.6/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2436 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_4\"](%/blocks.6/Gather_2_output_0, %onnx::Unsqueeze_2436), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2438 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_5\"](%/blocks.6/Cast_3_output_0, %onnx::Unsqueeze_2438), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2442 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_6\"](%/blocks.6/Cast_5_output_0, %onnx::Unsqueeze_2442), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_7\"](%/blocks.6/Gather_3_output_0, %onnx::Unsqueeze_2446), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_3\"](%/blocks.6/Unsqueeze_4_output_0, %/blocks.6/Unsqueeze_5_output_0, %/blocks.6/Constant_28_output_0, %/blocks.6/Unsqueeze_6_output_0, %/blocks.6/Constant_29_output_0, %/blocks.6/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.6/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_2\"](%/blocks.6/Pad_output_0, %/blocks.6/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.6/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.6/Transpose_1\"](%/blocks.6/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_8\"](%/blocks.6/Gather_3_output_0, %onnx::Unsqueeze_2457), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_4\"](%/blocks.6/Constant_30_output_0, %/blocks.6/Constant_31_output_0, %/blocks.6/Constant_32_output_0, %/blocks.6/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_3\"](%/blocks.6/Transpose_1_output_0, %/blocks.6/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather\"](%/blocks.6/attn/Shape_output_0, %/blocks.6/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_1\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_1\"](%/blocks.6/attn/Shape_1_output_0, %/blocks.6/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_2\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_2\"](%/blocks.6/attn/Shape_2_output_0, %/blocks.6/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/qkv/MatMul\"](%/blocks.6/Reshape_3_output_0, %onnx::MatMul_5830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/qkv/Add\"](%blocks.6.attn.qkv.bias, %/blocks.6/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul\"](%/blocks.6/attn/Gather_1_output_0, %/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2474 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2474), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_1\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2476), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat\"](%/blocks.6/attn/Unsqueeze_output_0, %/blocks.6/attn/Unsqueeze_1_output_0, %/blocks.6/attn/Constant_3_output_0, %/blocks.6/attn/Constant_4_output_0, %/blocks.6/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape\"](%/blocks.6/attn/qkv/Add_output_0, %/blocks.6/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.6/attn/Transpose\"](%/blocks.6/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_1\"](%/blocks.6/attn/Gather_output_0, %/blocks.6/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_2\"](%/blocks.6/attn/Mul_1_output_0, %onnx::Unsqueeze_2491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_3\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_1\"](%/blocks.6/attn/Constant_7_output_0, %/blocks.6/attn/Unsqueeze_2_output_0, %/blocks.6/attn/Unsqueeze_3_output_0, %/blocks.6/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_1\"](%/blocks.6/attn/Transpose_output_0, %/blocks.6/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.6/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.6/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.6/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.6/attn/Split\"](%/blocks.6/attn/Reshape_1_output_0, %/blocks.6/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze\"](%/blocks.6/attn/Split_output_0, %/blocks.6/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze_1\"](%/blocks.6/attn/Split_output_1, %/blocks.6/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze_2\"](%/blocks.6/attn/Split_output_2, %/blocks.6/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.6/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_2\"](%/blocks.6/attn/Squeeze_output_0, %/blocks.6/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.6/attn/Transpose_1\"](%/blocks.6/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/MatMul\"](%/blocks.6/attn/Mul_2_output_0, %/blocks.6/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.6/attn/Range\"](%/blocks.6/attn/Constant_14_output_0, %/blocks.6/attn/Cast_output_0, %/blocks.6/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_4\"](%/blocks.6/attn/Range_output_0, %/blocks.6/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_1\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_2\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/attn/Div\"](%/blocks.6/attn/Cast_1_output_0, %/blocks.6/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_3\"](%/blocks.6/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_3\"](%/blocks.6/attn/Cast_3_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_5\"](%/blocks.6/attn/Range_output_0, %/blocks.6/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_4\"](%/blocks.6/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_4\"](%/blocks.6/attn/Cast_4_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub\"](%/blocks.6/attn/Mul_3_output_0, %/blocks.6/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_1\"](%/blocks.6/attn/Gather_1_output_0, %/blocks.6/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_5\"](%/blocks.6/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_5\"](%/blocks.6/attn/Cast_5_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add\"](%/blocks.6/attn/Sub_output_0, %/blocks.6/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_6\"](%/blocks.6/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_3\"](%blocks.6.attn.rel_pos_h, %/blocks.6/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_7\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.6/attn/Range_1\"](%/blocks.6/attn/Constant_19_output_0, %/blocks.6/attn/Cast_7_output_0, %/blocks.6/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_6\"](%/blocks.6/attn/Range_1_output_0, %/blocks.6/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_8\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_9\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/attn/Div_1\"](%/blocks.6/attn/Cast_8_output_0, %/blocks.6/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_10\"](%/blocks.6/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_6\"](%/blocks.6/attn/Cast_10_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_7\"](%/blocks.6/attn/Range_1_output_0, %/blocks.6/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_11\"](%/blocks.6/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_7\"](%/blocks.6/attn/Cast_11_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_2\"](%/blocks.6/attn/Mul_6_output_0, %/blocks.6/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_3\"](%/blocks.6/attn/Gather_2_output_0, %/blocks.6/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_12\"](%/blocks.6/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_8\"](%/blocks.6/attn/Cast_12_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_1\"](%/blocks.6/attn/Sub_2_output_0, %/blocks.6/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_13\"](%/blocks.6/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_4\"](%blocks.6.attn.rel_pos_w, %/blocks.6/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_3\"](%/blocks.6/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_5\"](%/blocks.6/attn/Shape_3_output_0, %/blocks.6/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_4\"](%/blocks.6/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_6\"](%/blocks.6/attn/Shape_4_output_0, %/blocks.6/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2565 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_8\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2565), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2567 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_9\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2567), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2569 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_10\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2569), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_11\"](%/blocks.6/attn/Gather_6_output_0, %onnx::Unsqueeze_2571), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_2\"](%/blocks.6/attn/Unsqueeze_8_output_0, %/blocks.6/attn/Unsqueeze_9_output_0, %/blocks.6/attn/Unsqueeze_10_output_0, %/blocks.6/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.6/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_2\"](%/blocks.6/attn/Squeeze_output_0, %/blocks.6/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.6/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.6/attn/Einsum\"](%/blocks.6/attn/Reshape_2_output_0, %/blocks.6/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.6/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.6/attn/Einsum_1\"](%/blocks.6/attn/Reshape_2_output_0, %/blocks.6/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_12\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2577), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_13\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2579), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2581 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_14\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2581), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_15\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2583), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_16\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2585), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_3\"](%/blocks.6/attn/Unsqueeze_12_output_0, %/blocks.6/attn/Unsqueeze_13_output_0, %/blocks.6/attn/Unsqueeze_14_output_0, %/blocks.6/attn/Unsqueeze_15_output_0, %/blocks.6/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_3\"](%/blocks.6/attn/MatMul_output_0, %/blocks.6/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.6/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_17\"](%/blocks.6/attn/Einsum_output_0, %/blocks.6/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_2\"](%/blocks.6/attn/Reshape_3_output_0, %/blocks.6/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_18\"](%/blocks.6/attn/Einsum_1_output_0, %/blocks.6/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_3\"](%/blocks.6/attn/Add_2_output_0, %/blocks.6/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_19\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2595), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_20\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2597), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_21\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2599), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_4\"](%/blocks.6/attn/Unsqueeze_19_output_0, %/blocks.6/attn/Unsqueeze_20_output_0, %/blocks.6/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.6/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_4\"](%/blocks.6/attn/Add_3_output_0, %/blocks.6/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.6/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.6/attn/Softmax\"](%/blocks.6/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.6/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/MatMul_1\"](%/blocks.6/attn/Softmax_output_0, %/blocks.6/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2605 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_22\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2605), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2609 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_23\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2609), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2611 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_24\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2611), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_5\"](%/blocks.6/attn/Unsqueeze_22_output_0, %/blocks.6/attn/Constant_28_output_0, %/blocks.6/attn/Unsqueeze_23_output_0, %/blocks.6/attn/Unsqueeze_24_output_0, %/blocks.6/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_5\"](%/blocks.6/attn/MatMul_1_output_0, %/blocks.6/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.6/attn/Transpose_2\"](%/blocks.6/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_25\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2618), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2620 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_26\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2620), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2622 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_27\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2622), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_6\"](%/blocks.6/attn/Unsqueeze_25_output_0, %/blocks.6/attn/Unsqueeze_26_output_0, %/blocks.6/attn/Unsqueeze_27_output_0, %/blocks.6/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_6\"](%/blocks.6/attn/Transpose_2_output_0, %/blocks.6/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/proj/MatMul\"](%/blocks.6/attn/Reshape_6_output_0, %onnx::MatMul_5839), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/proj/Add\"](%blocks.6.attn.proj.bias, %/blocks.6/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_5\"](%/blocks.6/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_5\"](%/blocks.6/Shape_5_output_0, %/blocks.6/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/Mul\"](%/blocks.6/Add_output_0, %/blocks.6/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_2\"](%/blocks.6/Mul_output_0, %/blocks.6/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_6\"](%/blocks.6/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_7\"](%/blocks.6/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_3\"](%/blocks.6/Cast_7_output_0, %/blocks.6/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_8\"](%/blocks.6/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_9\"](%/blocks.6/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_4\"](%/blocks.6/Gather_5_output_0, %/blocks.6/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_10\"](%/blocks.6/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_11\"](%/blocks.6/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_9\"](%/blocks.6/Cast_11_output_0, %onnx::Unsqueeze_2646), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_10\"](%/blocks.6/Cast_3_output_0, %onnx::Unsqueeze_2648), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2650 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_11\"](%/blocks.6/Cast_5_output_0, %onnx::Unsqueeze_2650), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_5\"](%/blocks.6/Unsqueeze_9_output_0, %/blocks.6/Unsqueeze_10_output_0, %/blocks.6/Unsqueeze_11_output_0, %/blocks.6/Constant_36_output_0, %/blocks.6/Constant_37_output_0, %/blocks.6/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.6/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_4\"](%/blocks.6/attn/proj/Add_output_0, %/blocks.6/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.6/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.6/Transpose_2\"](%/blocks.6/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_2661 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_12\"](%/blocks.6/Cast_11_output_0, %onnx::Unsqueeze_2661), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2663 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_13\"](%/blocks.6/Add_output_0, %onnx::Unsqueeze_2663), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_14\"](%/blocks.6/Add_1_output_0, %onnx::Unsqueeze_2665), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_6\"](%/blocks.6/Unsqueeze_12_output_0, %/blocks.6/Unsqueeze_13_output_0, %/blocks.6/Unsqueeze_14_output_0, %/blocks.6/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.6/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_5\"](%/blocks.6/Transpose_2_output_0, %/blocks.6/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.6/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_15\"](%/blocks.6/Gather_output_0, %/blocks.6/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice_1\"](%/blocks.6/Reshape_5_output_0, %/blocks.6/Constant_41_output_0, %/blocks.6/Unsqueeze_15_output_0, %/blocks.6/Constant_40_output_0, %/blocks.6/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_16\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice_2\"](%/blocks.6/Slice_1_output_0, %/blocks.6/Constant_45_output_0, %/blocks.6/Unsqueeze_16_output_0, %/blocks.6/Constant_44_output_0, %/blocks.6/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_2\"](%/blocks.5/Add_3_output_0, %/blocks.6/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.6/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.6/norm2/LayerNormalization\"](%/blocks.6/Add_2_output_0, %blocks.6.norm2.weight, %blocks.6.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.6/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/mlp/lin1/MatMul\"](%/blocks.6/norm2/LayerNormalization_output_0, %onnx::MatMul_5850), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/lin1/Add\"](%blocks.6.mlp.lin1.bias, %/blocks.6/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.6/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/mlp/act/Div\"](%/blocks.6/mlp/lin1/Add_output_0, %/blocks.6/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.6/mlp/act/Erf\"](%/blocks.6/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/act/Add\"](%/blocks.6/mlp/act/Erf_output_0, %/blocks.6/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/mlp/act/Mul\"](%/blocks.6/mlp/lin1/Add_output_0, %/blocks.6/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.6/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/mlp/act/Mul_1\"](%/blocks.6/mlp/act/Mul_output_0, %/blocks.6/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/mlp/lin2/MatMul\"](%/blocks.6/mlp/act/Mul_1_output_0, %onnx::MatMul_5851), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/lin2/Add\"](%blocks.6.mlp.lin2.bias, %/blocks.6/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_3\"](%/blocks.6/Add_2_output_0, %/blocks.6/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.7/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.7/norm1/LayerNormalization\"](%/blocks.6/Add_3_output_0, %blocks.7.norm1.weight, %blocks.7.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.7/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather\"](%/blocks.7/attn/Shape_output_0, %/blocks.7/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_1\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_1\"](%/blocks.7/attn/Shape_1_output_0, %/blocks.7/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_2\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.7/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_2\"](%/blocks.7/attn/Shape_2_output_0, %/blocks.7/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/qkv/MatMul\"](%/blocks.7/norm1/LayerNormalization_output_0, %onnx::MatMul_5852), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[15728640, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/qkv/Add\"](%blocks.7.attn.qkv.bias, %/blocks.7/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul\"](%/blocks.7/attn/Gather_1_output_0, %/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2720), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2722 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_1\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2722), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat\"](%/blocks.7/attn/Unsqueeze_output_0, %/blocks.7/attn/Unsqueeze_1_output_0, %/blocks.7/attn/Constant_3_output_0, %/blocks.7/attn/Constant_4_output_0, %/blocks.7/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[15728640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape\"](%/blocks.7/attn/qkv/Add_output_0, %/blocks.7/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 15728640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.7/attn/Transpose\"](%/blocks.7/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_1\"](%/blocks.7/attn/Gather_output_0, %/blocks.7/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_2\"](%/blocks.7/attn/Mul_1_output_0, %onnx::Unsqueeze_2737), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_3\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2739), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_1\"](%/blocks.7/attn/Constant_7_output_0, %/blocks.7/attn/Unsqueeze_2_output_0, %/blocks.7/attn/Unsqueeze_3_output_0, %/blocks.7/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[1280, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_1\"](%/blocks.7/attn/Transpose_output_0, %/blocks.7/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.7/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.7/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.7/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.7/attn/Split\"](%/blocks.7/attn/Reshape_1_output_0, %/blocks.7/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze\"](%/blocks.7/attn/Split_output_0, %/blocks.7/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze_1\"](%/blocks.7/attn/Split_output_1, %/blocks.7/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze_2\"](%/blocks.7/attn/Split_output_2, %/blocks.7/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.7/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Mul_2_output_0 : Float(*, *, *, strides=[80, 1280, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_2\"](%/blocks.7/attn/Squeeze_output_0, %/blocks.7/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Transpose_1_output_0 : Float(*, *, *, strides=[80, 1, 3840], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.7/attn/Transpose_1\"](%/blocks.7/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/MatMul_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/MatMul\"](%/blocks.7/attn/Mul_2_output_0, %/blocks.7/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.7/attn/Range\"](%/blocks.7/attn/Constant_14_output_0, %/blocks.7/attn/Cast_output_0, %/blocks.7/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_4\"](%/blocks.7/attn/Range_output_0, %/blocks.7/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_1\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_2\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/attn/Div\"](%/blocks.7/attn/Cast_1_output_0, %/blocks.7/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_3\"](%/blocks.7/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_3\"](%/blocks.7/attn/Cast_3_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_5\"](%/blocks.7/attn/Range_output_0, %/blocks.7/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Cast_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_4\"](%/blocks.7/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Mul_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_4\"](%/blocks.7/attn/Cast_4_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Sub_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub\"](%/blocks.7/attn/Mul_3_output_0, %/blocks.7/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_1\"](%/blocks.7/attn/Gather_1_output_0, %/blocks.7/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_5\"](%/blocks.7/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_5\"](%/blocks.7/attn/Cast_5_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Add_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add\"](%/blocks.7/attn/Sub_output_0, %/blocks.7/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_6_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_6\"](%/blocks.7/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Gather_3_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_3\"](%blocks.7.attn.rel_pos_h, %/blocks.7/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_7\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.7/attn/Range_1\"](%/blocks.7/attn/Constant_19_output_0, %/blocks.7/attn/Cast_7_output_0, %/blocks.7/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_6\"](%/blocks.7/attn/Range_1_output_0, %/blocks.7/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_8\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_9\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/attn/Div_1\"](%/blocks.7/attn/Cast_8_output_0, %/blocks.7/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_10\"](%/blocks.7/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_6\"](%/blocks.7/attn/Cast_10_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_7\"](%/blocks.7/attn/Range_1_output_0, %/blocks.7/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Cast_11_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_11\"](%/blocks.7/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Mul_7_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_7\"](%/blocks.7/attn/Cast_11_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Sub_2_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_2\"](%/blocks.7/attn/Mul_6_output_0, %/blocks.7/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_3\"](%/blocks.7/attn/Gather_2_output_0, %/blocks.7/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_12\"](%/blocks.7/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_8\"](%/blocks.7/attn/Cast_12_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Add_1_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_1\"](%/blocks.7/attn/Sub_2_output_0, %/blocks.7/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_13_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_13\"](%/blocks.7/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Gather_4_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_4\"](%blocks.7.attn.rel_pos_w, %/blocks.7/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_3\"](%/blocks.7/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_5\"](%/blocks.7/attn/Shape_3_output_0, %/blocks.7/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_4\"](%/blocks.7/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.7/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_6\"](%/blocks.7/attn/Shape_4_output_0, %/blocks.7/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_8\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2811), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_9\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2813), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_10\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2815), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_11\"](%/blocks.7/attn/Gather_6_output_0, %onnx::Unsqueeze_2817), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_2\"](%/blocks.7/attn/Unsqueeze_8_output_0, %/blocks.7/attn/Unsqueeze_9_output_0, %/blocks.7/attn/Unsqueeze_10_output_0, %/blocks.7/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.7/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[80, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_2\"](%/blocks.7/attn/Squeeze_output_0, %/blocks.7/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.7/attn/Einsum_output_0 : Float(*, *, *, *, strides=[4096, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.7/attn/Einsum\"](%/blocks.7/attn/Reshape_2_output_0, %/blocks.7/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.7/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[4096, 64, 65536, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.7/attn/Einsum_1\"](%/blocks.7/attn/Reshape_2_output_0, %/blocks.7/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2823 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_12\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2823), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2825 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_13\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2825), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2827 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_14\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2827), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2829 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_15\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2829), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2831 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_16\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2831), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_3\"](%/blocks.7/attn/Unsqueeze_12_output_0, %/blocks.7/attn/Unsqueeze_13_output_0, %/blocks.7/attn/Unsqueeze_14_output_0, %/blocks.7/attn/Unsqueeze_15_output_0, %/blocks.7/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_3\"](%/blocks.7/attn/MatMul_output_0, %/blocks.7/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.7/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[4096, 65536, 64, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_17\"](%/blocks.7/attn/Einsum_output_0, %/blocks.7/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_2\"](%/blocks.7/attn/Reshape_3_output_0, %/blocks.7/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[4096, 64, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_18\"](%/blocks.7/attn/Einsum_1_output_0, %/blocks.7/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_3\"](%/blocks.7/attn/Add_2_output_0, %/blocks.7/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_19\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2841), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2843 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_20\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2843), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_21\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2845), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_4\"](%/blocks.7/attn/Unsqueeze_19_output_0, %/blocks.7/attn/Unsqueeze_20_output_0, %/blocks.7/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.7/attn/Reshape_4_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_4\"](%/blocks.7/attn/Add_3_output_0, %/blocks.7/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.7/attn/Softmax_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.7/attn/Softmax\"](%/blocks.7/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.7/attn/MatMul_1_output_0 : Float(*, *, *, strides=[327680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/MatMul_1\"](%/blocks.7/attn/Softmax_output_0, %/blocks.7/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_22\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2851), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_23\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2855), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_24\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2857), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_5\"](%/blocks.7/attn/Unsqueeze_22_output_0, %/blocks.7/attn/Constant_28_output_0, %/blocks.7/attn/Unsqueeze_23_output_0, %/blocks.7/attn/Unsqueeze_24_output_0, %/blocks.7/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[5242880, 327680, 5120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_5\"](%/blocks.7/attn/MatMul_1_output_0, %/blocks.7/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[5242880, 5120, 80, 327680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.7/attn/Transpose_2\"](%/blocks.7/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_25\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2864), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_26\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2866), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2868 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_27\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2868), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_6\"](%/blocks.7/attn/Unsqueeze_25_output_0, %/blocks.7/attn/Unsqueeze_26_output_0, %/blocks.7/attn/Unsqueeze_27_output_0, %/blocks.7/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_6\"](%/blocks.7/attn/Transpose_2_output_0, %/blocks.7/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/proj/MatMul\"](%/blocks.7/attn/Reshape_6_output_0, %onnx::MatMul_5861), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/proj/Add\"](%blocks.7.attn.proj.bias, %/blocks.7/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/Add_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/Add\"](%/blocks.6/Add_3_output_0, %/blocks.7/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.7/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.7/norm2/LayerNormalization\"](%/blocks.7/Add_output_0, %blocks.7.norm2.weight, %blocks.7.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.7/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/mlp/lin1/MatMul\"](%/blocks.7/norm2/LayerNormalization_output_0, %onnx::MatMul_5862), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/lin1/Add\"](%blocks.7.mlp.lin1.bias, %/blocks.7/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.7/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/mlp/act/Div\"](%/blocks.7/mlp/lin1/Add_output_0, %/blocks.7/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.7/mlp/act/Erf\"](%/blocks.7/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/act/Add\"](%/blocks.7/mlp/act/Erf_output_0, %/blocks.7/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/mlp/act/Mul\"](%/blocks.7/mlp/lin1/Add_output_0, %/blocks.7/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.7/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/mlp/act/Mul_1\"](%/blocks.7/mlp/act/Mul_output_0, %/blocks.7/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/mlp/lin2/MatMul\"](%/blocks.7/mlp/act/Mul_1_output_0, %onnx::MatMul_5863), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/lin2/Add\"](%blocks.7.mlp.lin2.bias, %/blocks.7/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/Add_1_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/Add_1\"](%/blocks.7/Add_output_0, %/blocks.7/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.8/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.8/norm1/LayerNormalization\"](%/blocks.7/Add_1_output_0, %blocks.8.norm1.weight, %blocks.8.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.8/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather\"](%/blocks.8/Shape_output_0, %/blocks.8/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_1\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_1\"](%/blocks.8/Shape_1_output_0, %/blocks.8/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_2\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_2\"](%/blocks.8/Shape_2_output_0, %/blocks.8/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_3\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_3\"](%/blocks.8/Shape_3_output_0, %/blocks.8/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod\"](%/blocks.8/Gather_output_0, %/blocks.8/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub\"](%/blocks.8/Constant_5_output_0, %/blocks.8/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_1\"](%/blocks.8/Sub_output_0, %/blocks.8/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_2\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub_1\"](%/blocks.8/Constant_8_output_0, %/blocks.8/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_3\"](%/blocks.8/Sub_1_output_0, %/blocks.8/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze\"](%/blocks.8/Mod_3_output_0, %onnx::Unsqueeze_2925), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_1\"](%/blocks.8/Mod_1_output_0, %onnx::Unsqueeze_2929), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat\"](%/blocks.8/Constant_10_output_0, %/blocks.8/Constant_11_output_0, %/blocks.8/Constant_12_output_0, %/blocks.8/Unsqueeze_output_0, %/blocks.8/Constant_13_output_0, %/blocks.8/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_2\"](%/blocks.8/Mod_3_output_0, %onnx::Unsqueeze_2938), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_3\"](%/blocks.8/Mod_1_output_0, %onnx::Unsqueeze_2942), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_1\"](%/blocks.8/Constant_14_output_0, %/blocks.8/Constant_15_output_0, %/blocks.8/Constant_16_output_0, %/blocks.8/Unsqueeze_2_output_0, %/blocks.8/Constant_17_output_0, %/blocks.8/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_4\"](%/blocks.8/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_4\"](%/blocks.8/Shape_4_output_0, %/blocks.8/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.8/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub_2\"](%/blocks.8/Constant_19_output_0, %/blocks.8/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast\"](%/blocks.8/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.8/ConstantOfShape\"](%/blocks.8/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_2\"](%/blocks.8/Cast_output_0, %/blocks.8/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.8/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape\"](%/blocks.8/Concat_2_output_0, %/blocks.8/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.8/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice\"](%/blocks.8/Reshape_output_0, %/blocks.8/Constant_22_output_0, %/blocks.8/Constant_23_output_0, %/blocks.8/Constant_21_output_0, %/blocks.8/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.8/Transpose\"](%/blocks.8/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_1\"](%/blocks.8/Transpose_output_0, %/blocks.8/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_1\"](%/blocks.8/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.8/Pad\"](%/blocks.8/norm1/LayerNormalization_output_0, %/blocks.8/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add\"](%/blocks.8/Gather_output_0, %/blocks.8/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.8/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_1\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.8/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div\"](%/blocks.8/Add_output_0, %/blocks.8/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_2\"](%/blocks.8/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_3\"](%/blocks.8/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_1\"](%/blocks.8/Add_1_output_0, %/blocks.8/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_4\"](%/blocks.8/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_5\"](%/blocks.8/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_4\"](%/blocks.8/Gather_2_output_0, %onnx::Unsqueeze_2977), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2979 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_5\"](%/blocks.8/Cast_3_output_0, %onnx::Unsqueeze_2979), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_6\"](%/blocks.8/Cast_5_output_0, %onnx::Unsqueeze_2983), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_7\"](%/blocks.8/Gather_3_output_0, %onnx::Unsqueeze_2987), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_3\"](%/blocks.8/Unsqueeze_4_output_0, %/blocks.8/Unsqueeze_5_output_0, %/blocks.8/Constant_28_output_0, %/blocks.8/Unsqueeze_6_output_0, %/blocks.8/Constant_29_output_0, %/blocks.8/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.8/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_2\"](%/blocks.8/Pad_output_0, %/blocks.8/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.8/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.8/Transpose_1\"](%/blocks.8/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2998 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_8\"](%/blocks.8/Gather_3_output_0, %onnx::Unsqueeze_2998), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_4\"](%/blocks.8/Constant_30_output_0, %/blocks.8/Constant_31_output_0, %/blocks.8/Constant_32_output_0, %/blocks.8/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_3\"](%/blocks.8/Transpose_1_output_0, %/blocks.8/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather\"](%/blocks.8/attn/Shape_output_0, %/blocks.8/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_1\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_1\"](%/blocks.8/attn/Shape_1_output_0, %/blocks.8/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_2\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_2\"](%/blocks.8/attn/Shape_2_output_0, %/blocks.8/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/qkv/MatMul\"](%/blocks.8/Reshape_3_output_0, %onnx::MatMul_5878), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/qkv/Add\"](%blocks.8.attn.qkv.bias, %/blocks.8/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul\"](%/blocks.8/attn/Gather_1_output_0, %/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3015 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3015), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3017 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_1\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3017), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat\"](%/blocks.8/attn/Unsqueeze_output_0, %/blocks.8/attn/Unsqueeze_1_output_0, %/blocks.8/attn/Constant_3_output_0, %/blocks.8/attn/Constant_4_output_0, %/blocks.8/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape\"](%/blocks.8/attn/qkv/Add_output_0, %/blocks.8/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.8/attn/Transpose\"](%/blocks.8/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_1\"](%/blocks.8/attn/Gather_output_0, %/blocks.8/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3032 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_2\"](%/blocks.8/attn/Mul_1_output_0, %onnx::Unsqueeze_3032), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3034 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_3\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3034), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_1\"](%/blocks.8/attn/Constant_7_output_0, %/blocks.8/attn/Unsqueeze_2_output_0, %/blocks.8/attn/Unsqueeze_3_output_0, %/blocks.8/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_1\"](%/blocks.8/attn/Transpose_output_0, %/blocks.8/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.8/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.8/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.8/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.8/attn/Split\"](%/blocks.8/attn/Reshape_1_output_0, %/blocks.8/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze\"](%/blocks.8/attn/Split_output_0, %/blocks.8/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze_1\"](%/blocks.8/attn/Split_output_1, %/blocks.8/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze_2\"](%/blocks.8/attn/Split_output_2, %/blocks.8/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.8/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_2\"](%/blocks.8/attn/Squeeze_output_0, %/blocks.8/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.8/attn/Transpose_1\"](%/blocks.8/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/MatMul\"](%/blocks.8/attn/Mul_2_output_0, %/blocks.8/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.8/attn/Range\"](%/blocks.8/attn/Constant_14_output_0, %/blocks.8/attn/Cast_output_0, %/blocks.8/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_4\"](%/blocks.8/attn/Range_output_0, %/blocks.8/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_1\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_2\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/attn/Div\"](%/blocks.8/attn/Cast_1_output_0, %/blocks.8/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_3\"](%/blocks.8/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_3\"](%/blocks.8/attn/Cast_3_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_5\"](%/blocks.8/attn/Range_output_0, %/blocks.8/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_4\"](%/blocks.8/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_4\"](%/blocks.8/attn/Cast_4_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub\"](%/blocks.8/attn/Mul_3_output_0, %/blocks.8/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_1\"](%/blocks.8/attn/Gather_1_output_0, %/blocks.8/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_5\"](%/blocks.8/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_5\"](%/blocks.8/attn/Cast_5_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add\"](%/blocks.8/attn/Sub_output_0, %/blocks.8/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_6\"](%/blocks.8/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_3\"](%blocks.8.attn.rel_pos_h, %/blocks.8/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_7\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.8/attn/Range_1\"](%/blocks.8/attn/Constant_19_output_0, %/blocks.8/attn/Cast_7_output_0, %/blocks.8/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_6\"](%/blocks.8/attn/Range_1_output_0, %/blocks.8/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_8\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_9\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/attn/Div_1\"](%/blocks.8/attn/Cast_8_output_0, %/blocks.8/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_10\"](%/blocks.8/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_6\"](%/blocks.8/attn/Cast_10_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_7\"](%/blocks.8/attn/Range_1_output_0, %/blocks.8/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_11\"](%/blocks.8/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_7\"](%/blocks.8/attn/Cast_11_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_2\"](%/blocks.8/attn/Mul_6_output_0, %/blocks.8/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_3\"](%/blocks.8/attn/Gather_2_output_0, %/blocks.8/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_12\"](%/blocks.8/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_8\"](%/blocks.8/attn/Cast_12_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_1\"](%/blocks.8/attn/Sub_2_output_0, %/blocks.8/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_13\"](%/blocks.8/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_4\"](%blocks.8.attn.rel_pos_w, %/blocks.8/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_3\"](%/blocks.8/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_5\"](%/blocks.8/attn/Shape_3_output_0, %/blocks.8/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_4\"](%/blocks.8/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_6\"](%/blocks.8/attn/Shape_4_output_0, %/blocks.8/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_8\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3106), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3108 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_9\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3108), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3110 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_10\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3110), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3112 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_11\"](%/blocks.8/attn/Gather_6_output_0, %onnx::Unsqueeze_3112), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_2\"](%/blocks.8/attn/Unsqueeze_8_output_0, %/blocks.8/attn/Unsqueeze_9_output_0, %/blocks.8/attn/Unsqueeze_10_output_0, %/blocks.8/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.8/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_2\"](%/blocks.8/attn/Squeeze_output_0, %/blocks.8/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.8/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.8/attn/Einsum\"](%/blocks.8/attn/Reshape_2_output_0, %/blocks.8/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.8/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.8/attn/Einsum_1\"](%/blocks.8/attn/Reshape_2_output_0, %/blocks.8/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_12\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3118), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3120 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_13\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3120), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_14\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3122), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_15\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3124), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3126 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_16\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3126), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_3\"](%/blocks.8/attn/Unsqueeze_12_output_0, %/blocks.8/attn/Unsqueeze_13_output_0, %/blocks.8/attn/Unsqueeze_14_output_0, %/blocks.8/attn/Unsqueeze_15_output_0, %/blocks.8/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_3\"](%/blocks.8/attn/MatMul_output_0, %/blocks.8/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.8/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_17\"](%/blocks.8/attn/Einsum_output_0, %/blocks.8/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_2\"](%/blocks.8/attn/Reshape_3_output_0, %/blocks.8/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_18\"](%/blocks.8/attn/Einsum_1_output_0, %/blocks.8/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_3\"](%/blocks.8/attn/Add_2_output_0, %/blocks.8/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_19\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3136), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_20\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3138), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_21\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3140), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_4\"](%/blocks.8/attn/Unsqueeze_19_output_0, %/blocks.8/attn/Unsqueeze_20_output_0, %/blocks.8/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.8/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_4\"](%/blocks.8/attn/Add_3_output_0, %/blocks.8/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.8/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.8/attn/Softmax\"](%/blocks.8/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.8/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/MatMul_1\"](%/blocks.8/attn/Softmax_output_0, %/blocks.8/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_22\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3146), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_23\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3150), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_24\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3152), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_5\"](%/blocks.8/attn/Unsqueeze_22_output_0, %/blocks.8/attn/Constant_28_output_0, %/blocks.8/attn/Unsqueeze_23_output_0, %/blocks.8/attn/Unsqueeze_24_output_0, %/blocks.8/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_5\"](%/blocks.8/attn/MatMul_1_output_0, %/blocks.8/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.8/attn/Transpose_2\"](%/blocks.8/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_25\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3159), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3161 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_26\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3161), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3163 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_27\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3163), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_6\"](%/blocks.8/attn/Unsqueeze_25_output_0, %/blocks.8/attn/Unsqueeze_26_output_0, %/blocks.8/attn/Unsqueeze_27_output_0, %/blocks.8/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_6\"](%/blocks.8/attn/Transpose_2_output_0, %/blocks.8/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/proj/MatMul\"](%/blocks.8/attn/Reshape_6_output_0, %onnx::MatMul_5887), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/proj/Add\"](%blocks.8.attn.proj.bias, %/blocks.8/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_5\"](%/blocks.8/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_5\"](%/blocks.8/Shape_5_output_0, %/blocks.8/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/Mul\"](%/blocks.8/Add_output_0, %/blocks.8/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_2\"](%/blocks.8/Mul_output_0, %/blocks.8/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_6\"](%/blocks.8/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_7\"](%/blocks.8/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_3\"](%/blocks.8/Cast_7_output_0, %/blocks.8/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_8\"](%/blocks.8/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_9\"](%/blocks.8/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_4\"](%/blocks.8/Gather_5_output_0, %/blocks.8/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_10\"](%/blocks.8/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_11\"](%/blocks.8/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_9\"](%/blocks.8/Cast_11_output_0, %onnx::Unsqueeze_3187), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_10\"](%/blocks.8/Cast_3_output_0, %onnx::Unsqueeze_3189), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_11\"](%/blocks.8/Cast_5_output_0, %onnx::Unsqueeze_3191), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_5\"](%/blocks.8/Unsqueeze_9_output_0, %/blocks.8/Unsqueeze_10_output_0, %/blocks.8/Unsqueeze_11_output_0, %/blocks.8/Constant_36_output_0, %/blocks.8/Constant_37_output_0, %/blocks.8/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.8/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_4\"](%/blocks.8/attn/proj/Add_output_0, %/blocks.8/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.8/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.8/Transpose_2\"](%/blocks.8/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3202 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_12\"](%/blocks.8/Cast_11_output_0, %onnx::Unsqueeze_3202), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3204 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_13\"](%/blocks.8/Add_output_0, %onnx::Unsqueeze_3204), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_14\"](%/blocks.8/Add_1_output_0, %onnx::Unsqueeze_3206), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_6\"](%/blocks.8/Unsqueeze_12_output_0, %/blocks.8/Unsqueeze_13_output_0, %/blocks.8/Unsqueeze_14_output_0, %/blocks.8/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.8/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_5\"](%/blocks.8/Transpose_2_output_0, %/blocks.8/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.8/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_15\"](%/blocks.8/Gather_output_0, %/blocks.8/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice_1\"](%/blocks.8/Reshape_5_output_0, %/blocks.8/Constant_41_output_0, %/blocks.8/Unsqueeze_15_output_0, %/blocks.8/Constant_40_output_0, %/blocks.8/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_16\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice_2\"](%/blocks.8/Slice_1_output_0, %/blocks.8/Constant_45_output_0, %/blocks.8/Unsqueeze_16_output_0, %/blocks.8/Constant_44_output_0, %/blocks.8/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_2\"](%/blocks.7/Add_1_output_0, %/blocks.8/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.8/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.8/norm2/LayerNormalization\"](%/blocks.8/Add_2_output_0, %blocks.8.norm2.weight, %blocks.8.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.8/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/mlp/lin1/MatMul\"](%/blocks.8/norm2/LayerNormalization_output_0, %onnx::MatMul_5898), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/lin1/Add\"](%blocks.8.mlp.lin1.bias, %/blocks.8/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.8/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/mlp/act/Div\"](%/blocks.8/mlp/lin1/Add_output_0, %/blocks.8/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.8/mlp/act/Erf\"](%/blocks.8/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/act/Add\"](%/blocks.8/mlp/act/Erf_output_0, %/blocks.8/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/mlp/act/Mul\"](%/blocks.8/mlp/lin1/Add_output_0, %/blocks.8/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.8/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/mlp/act/Mul_1\"](%/blocks.8/mlp/act/Mul_output_0, %/blocks.8/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/mlp/lin2/MatMul\"](%/blocks.8/mlp/act/Mul_1_output_0, %onnx::MatMul_5899), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/lin2/Add\"](%blocks.8.mlp.lin2.bias, %/blocks.8/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_3\"](%/blocks.8/Add_2_output_0, %/blocks.8/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.9/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.9/norm1/LayerNormalization\"](%/blocks.8/Add_3_output_0, %blocks.9.norm1.weight, %blocks.9.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.9/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather\"](%/blocks.9/Shape_output_0, %/blocks.9/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_1\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_1\"](%/blocks.9/Shape_1_output_0, %/blocks.9/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_2\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_2\"](%/blocks.9/Shape_2_output_0, %/blocks.9/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_3\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_3\"](%/blocks.9/Shape_3_output_0, %/blocks.9/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod\"](%/blocks.9/Gather_output_0, %/blocks.9/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub\"](%/blocks.9/Constant_5_output_0, %/blocks.9/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_1\"](%/blocks.9/Sub_output_0, %/blocks.9/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_2\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub_1\"](%/blocks.9/Constant_8_output_0, %/blocks.9/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_3\"](%/blocks.9/Sub_1_output_0, %/blocks.9/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze\"](%/blocks.9/Mod_3_output_0, %onnx::Unsqueeze_3278), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3282 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_1\"](%/blocks.9/Mod_1_output_0, %onnx::Unsqueeze_3282), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat\"](%/blocks.9/Constant_10_output_0, %/blocks.9/Constant_11_output_0, %/blocks.9/Constant_12_output_0, %/blocks.9/Unsqueeze_output_0, %/blocks.9/Constant_13_output_0, %/blocks.9/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_2\"](%/blocks.9/Mod_3_output_0, %onnx::Unsqueeze_3291), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_3\"](%/blocks.9/Mod_1_output_0, %onnx::Unsqueeze_3295), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_1\"](%/blocks.9/Constant_14_output_0, %/blocks.9/Constant_15_output_0, %/blocks.9/Constant_16_output_0, %/blocks.9/Unsqueeze_2_output_0, %/blocks.9/Constant_17_output_0, %/blocks.9/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_4\"](%/blocks.9/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_4\"](%/blocks.9/Shape_4_output_0, %/blocks.9/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.9/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub_2\"](%/blocks.9/Constant_19_output_0, %/blocks.9/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast\"](%/blocks.9/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.9/ConstantOfShape\"](%/blocks.9/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_2\"](%/blocks.9/Cast_output_0, %/blocks.9/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.9/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape\"](%/blocks.9/Concat_2_output_0, %/blocks.9/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.9/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice\"](%/blocks.9/Reshape_output_0, %/blocks.9/Constant_22_output_0, %/blocks.9/Constant_23_output_0, %/blocks.9/Constant_21_output_0, %/blocks.9/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.9/Transpose\"](%/blocks.9/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_1\"](%/blocks.9/Transpose_output_0, %/blocks.9/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_1\"](%/blocks.9/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.9/Pad\"](%/blocks.9/norm1/LayerNormalization_output_0, %/blocks.9/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add\"](%/blocks.9/Gather_output_0, %/blocks.9/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.9/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_1\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.9/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div\"](%/blocks.9/Add_output_0, %/blocks.9/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_2\"](%/blocks.9/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_3\"](%/blocks.9/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_1\"](%/blocks.9/Add_1_output_0, %/blocks.9/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_4\"](%/blocks.9/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_5\"](%/blocks.9/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3330 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_4\"](%/blocks.9/Gather_2_output_0, %onnx::Unsqueeze_3330), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3332 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_5\"](%/blocks.9/Cast_3_output_0, %onnx::Unsqueeze_3332), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3336 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_6\"](%/blocks.9/Cast_5_output_0, %onnx::Unsqueeze_3336), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3340 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_7\"](%/blocks.9/Gather_3_output_0, %onnx::Unsqueeze_3340), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_3\"](%/blocks.9/Unsqueeze_4_output_0, %/blocks.9/Unsqueeze_5_output_0, %/blocks.9/Constant_28_output_0, %/blocks.9/Unsqueeze_6_output_0, %/blocks.9/Constant_29_output_0, %/blocks.9/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.9/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_2\"](%/blocks.9/Pad_output_0, %/blocks.9/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.9/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.9/Transpose_1\"](%/blocks.9/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3351 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_8\"](%/blocks.9/Gather_3_output_0, %onnx::Unsqueeze_3351), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_4\"](%/blocks.9/Constant_30_output_0, %/blocks.9/Constant_31_output_0, %/blocks.9/Constant_32_output_0, %/blocks.9/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_3\"](%/blocks.9/Transpose_1_output_0, %/blocks.9/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather\"](%/blocks.9/attn/Shape_output_0, %/blocks.9/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_1\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_1\"](%/blocks.9/attn/Shape_1_output_0, %/blocks.9/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_2\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_2\"](%/blocks.9/attn/Shape_2_output_0, %/blocks.9/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/qkv/MatMul\"](%/blocks.9/Reshape_3_output_0, %onnx::MatMul_5914), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/qkv/Add\"](%blocks.9.attn.qkv.bias, %/blocks.9/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul\"](%/blocks.9/attn/Gather_1_output_0, %/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3368 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3368), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3370 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_1\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3370), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat\"](%/blocks.9/attn/Unsqueeze_output_0, %/blocks.9/attn/Unsqueeze_1_output_0, %/blocks.9/attn/Constant_3_output_0, %/blocks.9/attn/Constant_4_output_0, %/blocks.9/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape\"](%/blocks.9/attn/qkv/Add_output_0, %/blocks.9/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.9/attn/Transpose\"](%/blocks.9/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_1\"](%/blocks.9/attn/Gather_output_0, %/blocks.9/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3385 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_2\"](%/blocks.9/attn/Mul_1_output_0, %onnx::Unsqueeze_3385), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_3\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3387), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_1\"](%/blocks.9/attn/Constant_7_output_0, %/blocks.9/attn/Unsqueeze_2_output_0, %/blocks.9/attn/Unsqueeze_3_output_0, %/blocks.9/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_1\"](%/blocks.9/attn/Transpose_output_0, %/blocks.9/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.9/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.9/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.9/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.9/attn/Split\"](%/blocks.9/attn/Reshape_1_output_0, %/blocks.9/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze\"](%/blocks.9/attn/Split_output_0, %/blocks.9/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze_1\"](%/blocks.9/attn/Split_output_1, %/blocks.9/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze_2\"](%/blocks.9/attn/Split_output_2, %/blocks.9/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.9/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_2\"](%/blocks.9/attn/Squeeze_output_0, %/blocks.9/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.9/attn/Transpose_1\"](%/blocks.9/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/MatMul\"](%/blocks.9/attn/Mul_2_output_0, %/blocks.9/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.9/attn/Range\"](%/blocks.9/attn/Constant_14_output_0, %/blocks.9/attn/Cast_output_0, %/blocks.9/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_4\"](%/blocks.9/attn/Range_output_0, %/blocks.9/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_1\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_2\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/attn/Div\"](%/blocks.9/attn/Cast_1_output_0, %/blocks.9/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_3\"](%/blocks.9/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_3\"](%/blocks.9/attn/Cast_3_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_5\"](%/blocks.9/attn/Range_output_0, %/blocks.9/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_4\"](%/blocks.9/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_4\"](%/blocks.9/attn/Cast_4_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub\"](%/blocks.9/attn/Mul_3_output_0, %/blocks.9/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_1\"](%/blocks.9/attn/Gather_1_output_0, %/blocks.9/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_5\"](%/blocks.9/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_5\"](%/blocks.9/attn/Cast_5_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add\"](%/blocks.9/attn/Sub_output_0, %/blocks.9/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_6\"](%/blocks.9/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_3\"](%blocks.9.attn.rel_pos_h, %/blocks.9/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_7\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.9/attn/Range_1\"](%/blocks.9/attn/Constant_19_output_0, %/blocks.9/attn/Cast_7_output_0, %/blocks.9/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_6\"](%/blocks.9/attn/Range_1_output_0, %/blocks.9/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_8\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_9\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/attn/Div_1\"](%/blocks.9/attn/Cast_8_output_0, %/blocks.9/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_10\"](%/blocks.9/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_6\"](%/blocks.9/attn/Cast_10_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_7\"](%/blocks.9/attn/Range_1_output_0, %/blocks.9/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_11\"](%/blocks.9/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_7\"](%/blocks.9/attn/Cast_11_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_2\"](%/blocks.9/attn/Mul_6_output_0, %/blocks.9/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_3\"](%/blocks.9/attn/Gather_2_output_0, %/blocks.9/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_12\"](%/blocks.9/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_8\"](%/blocks.9/attn/Cast_12_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_1\"](%/blocks.9/attn/Sub_2_output_0, %/blocks.9/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_13\"](%/blocks.9/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_4\"](%blocks.9.attn.rel_pos_w, %/blocks.9/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_3\"](%/blocks.9/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_5\"](%/blocks.9/attn/Shape_3_output_0, %/blocks.9/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_4\"](%/blocks.9/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_6\"](%/blocks.9/attn/Shape_4_output_0, %/blocks.9/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_8\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3459), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_9\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3461), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_10\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3463), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_11\"](%/blocks.9/attn/Gather_6_output_0, %onnx::Unsqueeze_3465), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_2\"](%/blocks.9/attn/Unsqueeze_8_output_0, %/blocks.9/attn/Unsqueeze_9_output_0, %/blocks.9/attn/Unsqueeze_10_output_0, %/blocks.9/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.9/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_2\"](%/blocks.9/attn/Squeeze_output_0, %/blocks.9/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.9/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.9/attn/Einsum\"](%/blocks.9/attn/Reshape_2_output_0, %/blocks.9/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.9/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.9/attn/Einsum_1\"](%/blocks.9/attn/Reshape_2_output_0, %/blocks.9/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3471 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_12\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3471), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3473 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_13\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3473), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3475 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_14\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3475), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_15\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3477), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_16\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3479), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_3\"](%/blocks.9/attn/Unsqueeze_12_output_0, %/blocks.9/attn/Unsqueeze_13_output_0, %/blocks.9/attn/Unsqueeze_14_output_0, %/blocks.9/attn/Unsqueeze_15_output_0, %/blocks.9/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_3\"](%/blocks.9/attn/MatMul_output_0, %/blocks.9/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.9/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_17\"](%/blocks.9/attn/Einsum_output_0, %/blocks.9/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_2\"](%/blocks.9/attn/Reshape_3_output_0, %/blocks.9/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_18\"](%/blocks.9/attn/Einsum_1_output_0, %/blocks.9/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_3\"](%/blocks.9/attn/Add_2_output_0, %/blocks.9/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3489 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_19\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3489), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_20\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_21\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_4\"](%/blocks.9/attn/Unsqueeze_19_output_0, %/blocks.9/attn/Unsqueeze_20_output_0, %/blocks.9/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.9/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_4\"](%/blocks.9/attn/Add_3_output_0, %/blocks.9/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.9/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.9/attn/Softmax\"](%/blocks.9/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.9/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/MatMul_1\"](%/blocks.9/attn/Softmax_output_0, %/blocks.9/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_22\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3499), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_23\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3503), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_24\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3505), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_5\"](%/blocks.9/attn/Unsqueeze_22_output_0, %/blocks.9/attn/Constant_28_output_0, %/blocks.9/attn/Unsqueeze_23_output_0, %/blocks.9/attn/Unsqueeze_24_output_0, %/blocks.9/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_5\"](%/blocks.9/attn/MatMul_1_output_0, %/blocks.9/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.9/attn/Transpose_2\"](%/blocks.9/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_25\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3512), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_26\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3514), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_27\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3516), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_6\"](%/blocks.9/attn/Unsqueeze_25_output_0, %/blocks.9/attn/Unsqueeze_26_output_0, %/blocks.9/attn/Unsqueeze_27_output_0, %/blocks.9/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_6\"](%/blocks.9/attn/Transpose_2_output_0, %/blocks.9/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/proj/MatMul\"](%/blocks.9/attn/Reshape_6_output_0, %onnx::MatMul_5923), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/proj/Add\"](%blocks.9.attn.proj.bias, %/blocks.9/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_5\"](%/blocks.9/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_5\"](%/blocks.9/Shape_5_output_0, %/blocks.9/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/Mul\"](%/blocks.9/Add_output_0, %/blocks.9/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_2\"](%/blocks.9/Mul_output_0, %/blocks.9/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_6\"](%/blocks.9/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_7\"](%/blocks.9/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_3\"](%/blocks.9/Cast_7_output_0, %/blocks.9/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_8\"](%/blocks.9/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_9\"](%/blocks.9/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_4\"](%/blocks.9/Gather_5_output_0, %/blocks.9/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_10\"](%/blocks.9/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_11\"](%/blocks.9/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_9\"](%/blocks.9/Cast_11_output_0, %onnx::Unsqueeze_3540), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3542 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_10\"](%/blocks.9/Cast_3_output_0, %onnx::Unsqueeze_3542), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3544 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_11\"](%/blocks.9/Cast_5_output_0, %onnx::Unsqueeze_3544), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_5\"](%/blocks.9/Unsqueeze_9_output_0, %/blocks.9/Unsqueeze_10_output_0, %/blocks.9/Unsqueeze_11_output_0, %/blocks.9/Constant_36_output_0, %/blocks.9/Constant_37_output_0, %/blocks.9/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.9/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_4\"](%/blocks.9/attn/proj/Add_output_0, %/blocks.9/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.9/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.9/Transpose_2\"](%/blocks.9/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_12\"](%/blocks.9/Cast_11_output_0, %onnx::Unsqueeze_3555), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_13\"](%/blocks.9/Add_output_0, %onnx::Unsqueeze_3557), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_14\"](%/blocks.9/Add_1_output_0, %onnx::Unsqueeze_3559), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_6\"](%/blocks.9/Unsqueeze_12_output_0, %/blocks.9/Unsqueeze_13_output_0, %/blocks.9/Unsqueeze_14_output_0, %/blocks.9/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.9/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_5\"](%/blocks.9/Transpose_2_output_0, %/blocks.9/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.9/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_15\"](%/blocks.9/Gather_output_0, %/blocks.9/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice_1\"](%/blocks.9/Reshape_5_output_0, %/blocks.9/Constant_41_output_0, %/blocks.9/Unsqueeze_15_output_0, %/blocks.9/Constant_40_output_0, %/blocks.9/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_16\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice_2\"](%/blocks.9/Slice_1_output_0, %/blocks.9/Constant_45_output_0, %/blocks.9/Unsqueeze_16_output_0, %/blocks.9/Constant_44_output_0, %/blocks.9/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_2\"](%/blocks.8/Add_3_output_0, %/blocks.9/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.9/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.9/norm2/LayerNormalization\"](%/blocks.9/Add_2_output_0, %blocks.9.norm2.weight, %blocks.9.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.9/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/mlp/lin1/MatMul\"](%/blocks.9/norm2/LayerNormalization_output_0, %onnx::MatMul_5934), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/lin1/Add\"](%blocks.9.mlp.lin1.bias, %/blocks.9/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.9/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/mlp/act/Div\"](%/blocks.9/mlp/lin1/Add_output_0, %/blocks.9/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.9/mlp/act/Erf\"](%/blocks.9/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/act/Add\"](%/blocks.9/mlp/act/Erf_output_0, %/blocks.9/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/mlp/act/Mul\"](%/blocks.9/mlp/lin1/Add_output_0, %/blocks.9/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.9/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/mlp/act/Mul_1\"](%/blocks.9/mlp/act/Mul_output_0, %/blocks.9/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/mlp/lin2/MatMul\"](%/blocks.9/mlp/act/Mul_1_output_0, %onnx::MatMul_5935), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/lin2/Add\"](%blocks.9.mlp.lin2.bias, %/blocks.9/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_3\"](%/blocks.9/Add_2_output_0, %/blocks.9/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.10/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.10/norm1/LayerNormalization\"](%/blocks.9/Add_3_output_0, %blocks.10.norm1.weight, %blocks.10.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.10/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather\"](%/blocks.10/Shape_output_0, %/blocks.10/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_1\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_1\"](%/blocks.10/Shape_1_output_0, %/blocks.10/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_2\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_2\"](%/blocks.10/Shape_2_output_0, %/blocks.10/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_3\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_3\"](%/blocks.10/Shape_3_output_0, %/blocks.10/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod\"](%/blocks.10/Gather_output_0, %/blocks.10/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub\"](%/blocks.10/Constant_5_output_0, %/blocks.10/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_1\"](%/blocks.10/Sub_output_0, %/blocks.10/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_2\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub_1\"](%/blocks.10/Constant_8_output_0, %/blocks.10/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_3\"](%/blocks.10/Sub_1_output_0, %/blocks.10/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze\"](%/blocks.10/Mod_3_output_0, %onnx::Unsqueeze_3631), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_1\"](%/blocks.10/Mod_1_output_0, %onnx::Unsqueeze_3635), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat\"](%/blocks.10/Constant_10_output_0, %/blocks.10/Constant_11_output_0, %/blocks.10/Constant_12_output_0, %/blocks.10/Unsqueeze_output_0, %/blocks.10/Constant_13_output_0, %/blocks.10/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_2\"](%/blocks.10/Mod_3_output_0, %onnx::Unsqueeze_3644), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_3\"](%/blocks.10/Mod_1_output_0, %onnx::Unsqueeze_3648), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_1\"](%/blocks.10/Constant_14_output_0, %/blocks.10/Constant_15_output_0, %/blocks.10/Constant_16_output_0, %/blocks.10/Unsqueeze_2_output_0, %/blocks.10/Constant_17_output_0, %/blocks.10/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_4\"](%/blocks.10/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_4\"](%/blocks.10/Shape_4_output_0, %/blocks.10/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.10/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub_2\"](%/blocks.10/Constant_19_output_0, %/blocks.10/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast\"](%/blocks.10/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.10/ConstantOfShape\"](%/blocks.10/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_2\"](%/blocks.10/Cast_output_0, %/blocks.10/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.10/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape\"](%/blocks.10/Concat_2_output_0, %/blocks.10/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.10/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice\"](%/blocks.10/Reshape_output_0, %/blocks.10/Constant_22_output_0, %/blocks.10/Constant_23_output_0, %/blocks.10/Constant_21_output_0, %/blocks.10/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.10/Transpose\"](%/blocks.10/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_1\"](%/blocks.10/Transpose_output_0, %/blocks.10/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_1\"](%/blocks.10/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.10/Pad\"](%/blocks.10/norm1/LayerNormalization_output_0, %/blocks.10/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add\"](%/blocks.10/Gather_output_0, %/blocks.10/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.10/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_1\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.10/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div\"](%/blocks.10/Add_output_0, %/blocks.10/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_2\"](%/blocks.10/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_3\"](%/blocks.10/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_1\"](%/blocks.10/Add_1_output_0, %/blocks.10/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_4\"](%/blocks.10/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_5\"](%/blocks.10/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_4\"](%/blocks.10/Gather_2_output_0, %onnx::Unsqueeze_3683), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_5\"](%/blocks.10/Cast_3_output_0, %onnx::Unsqueeze_3685), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3689 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_6\"](%/blocks.10/Cast_5_output_0, %onnx::Unsqueeze_3689), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3693 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_7\"](%/blocks.10/Gather_3_output_0, %onnx::Unsqueeze_3693), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_3\"](%/blocks.10/Unsqueeze_4_output_0, %/blocks.10/Unsqueeze_5_output_0, %/blocks.10/Constant_28_output_0, %/blocks.10/Unsqueeze_6_output_0, %/blocks.10/Constant_29_output_0, %/blocks.10/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.10/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_2\"](%/blocks.10/Pad_output_0, %/blocks.10/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.10/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.10/Transpose_1\"](%/blocks.10/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3704 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_8\"](%/blocks.10/Gather_3_output_0, %onnx::Unsqueeze_3704), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_4\"](%/blocks.10/Constant_30_output_0, %/blocks.10/Constant_31_output_0, %/blocks.10/Constant_32_output_0, %/blocks.10/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_3\"](%/blocks.10/Transpose_1_output_0, %/blocks.10/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather\"](%/blocks.10/attn/Shape_output_0, %/blocks.10/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_1\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_1\"](%/blocks.10/attn/Shape_1_output_0, %/blocks.10/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_2\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_2\"](%/blocks.10/attn/Shape_2_output_0, %/blocks.10/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/qkv/MatMul\"](%/blocks.10/Reshape_3_output_0, %onnx::MatMul_5950), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/qkv/Add\"](%blocks.10.attn.qkv.bias, %/blocks.10/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul\"](%/blocks.10/attn/Gather_1_output_0, %/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3721), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_1\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3723), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat\"](%/blocks.10/attn/Unsqueeze_output_0, %/blocks.10/attn/Unsqueeze_1_output_0, %/blocks.10/attn/Constant_3_output_0, %/blocks.10/attn/Constant_4_output_0, %/blocks.10/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape\"](%/blocks.10/attn/qkv/Add_output_0, %/blocks.10/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.10/attn/Transpose\"](%/blocks.10/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_1\"](%/blocks.10/attn/Gather_output_0, %/blocks.10/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_2\"](%/blocks.10/attn/Mul_1_output_0, %onnx::Unsqueeze_3738), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_3\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3740), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_1\"](%/blocks.10/attn/Constant_7_output_0, %/blocks.10/attn/Unsqueeze_2_output_0, %/blocks.10/attn/Unsqueeze_3_output_0, %/blocks.10/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_1\"](%/blocks.10/attn/Transpose_output_0, %/blocks.10/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.10/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.10/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.10/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.10/attn/Split\"](%/blocks.10/attn/Reshape_1_output_0, %/blocks.10/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze\"](%/blocks.10/attn/Split_output_0, %/blocks.10/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze_1\"](%/blocks.10/attn/Split_output_1, %/blocks.10/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze_2\"](%/blocks.10/attn/Split_output_2, %/blocks.10/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.10/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_2\"](%/blocks.10/attn/Squeeze_output_0, %/blocks.10/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.10/attn/Transpose_1\"](%/blocks.10/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/MatMul\"](%/blocks.10/attn/Mul_2_output_0, %/blocks.10/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.10/attn/Range\"](%/blocks.10/attn/Constant_14_output_0, %/blocks.10/attn/Cast_output_0, %/blocks.10/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_4\"](%/blocks.10/attn/Range_output_0, %/blocks.10/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_1\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_2\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/attn/Div\"](%/blocks.10/attn/Cast_1_output_0, %/blocks.10/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_3\"](%/blocks.10/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_3\"](%/blocks.10/attn/Cast_3_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_5\"](%/blocks.10/attn/Range_output_0, %/blocks.10/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_4\"](%/blocks.10/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_4\"](%/blocks.10/attn/Cast_4_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub\"](%/blocks.10/attn/Mul_3_output_0, %/blocks.10/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_1\"](%/blocks.10/attn/Gather_1_output_0, %/blocks.10/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_5\"](%/blocks.10/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_5\"](%/blocks.10/attn/Cast_5_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add\"](%/blocks.10/attn/Sub_output_0, %/blocks.10/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_6\"](%/blocks.10/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_3\"](%blocks.10.attn.rel_pos_h, %/blocks.10/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_7\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.10/attn/Range_1\"](%/blocks.10/attn/Constant_19_output_0, %/blocks.10/attn/Cast_7_output_0, %/blocks.10/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_6\"](%/blocks.10/attn/Range_1_output_0, %/blocks.10/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_8\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_9\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/attn/Div_1\"](%/blocks.10/attn/Cast_8_output_0, %/blocks.10/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_10\"](%/blocks.10/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_6\"](%/blocks.10/attn/Cast_10_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_7\"](%/blocks.10/attn/Range_1_output_0, %/blocks.10/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_11\"](%/blocks.10/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_7\"](%/blocks.10/attn/Cast_11_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_2\"](%/blocks.10/attn/Mul_6_output_0, %/blocks.10/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_3\"](%/blocks.10/attn/Gather_2_output_0, %/blocks.10/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_12\"](%/blocks.10/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_8\"](%/blocks.10/attn/Cast_12_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_1\"](%/blocks.10/attn/Sub_2_output_0, %/blocks.10/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_13\"](%/blocks.10/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_4\"](%blocks.10.attn.rel_pos_w, %/blocks.10/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_3\"](%/blocks.10/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_5\"](%/blocks.10/attn/Shape_3_output_0, %/blocks.10/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_4\"](%/blocks.10/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_6\"](%/blocks.10/attn/Shape_4_output_0, %/blocks.10/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_8\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3812), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_9\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_10\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3816), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_11\"](%/blocks.10/attn/Gather_6_output_0, %onnx::Unsqueeze_3818), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_2\"](%/blocks.10/attn/Unsqueeze_8_output_0, %/blocks.10/attn/Unsqueeze_9_output_0, %/blocks.10/attn/Unsqueeze_10_output_0, %/blocks.10/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.10/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_2\"](%/blocks.10/attn/Squeeze_output_0, %/blocks.10/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.10/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.10/attn/Einsum\"](%/blocks.10/attn/Reshape_2_output_0, %/blocks.10/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.10/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.10/attn/Einsum_1\"](%/blocks.10/attn/Reshape_2_output_0, %/blocks.10/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3824 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_12\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3824), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_13\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3826), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_14\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3828), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_15\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_16\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3832), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_3\"](%/blocks.10/attn/Unsqueeze_12_output_0, %/blocks.10/attn/Unsqueeze_13_output_0, %/blocks.10/attn/Unsqueeze_14_output_0, %/blocks.10/attn/Unsqueeze_15_output_0, %/blocks.10/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_3\"](%/blocks.10/attn/MatMul_output_0, %/blocks.10/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.10/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_17\"](%/blocks.10/attn/Einsum_output_0, %/blocks.10/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_2\"](%/blocks.10/attn/Reshape_3_output_0, %/blocks.10/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_18\"](%/blocks.10/attn/Einsum_1_output_0, %/blocks.10/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_3\"](%/blocks.10/attn/Add_2_output_0, %/blocks.10/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3842 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_19\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3842), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3844 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_20\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3844), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_21\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3846), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_4\"](%/blocks.10/attn/Unsqueeze_19_output_0, %/blocks.10/attn/Unsqueeze_20_output_0, %/blocks.10/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.10/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_4\"](%/blocks.10/attn/Add_3_output_0, %/blocks.10/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.10/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.10/attn/Softmax\"](%/blocks.10/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.10/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/MatMul_1\"](%/blocks.10/attn/Softmax_output_0, %/blocks.10/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3852 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_22\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3852), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3856 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_23\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3856), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_24\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3858), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_5\"](%/blocks.10/attn/Unsqueeze_22_output_0, %/blocks.10/attn/Constant_28_output_0, %/blocks.10/attn/Unsqueeze_23_output_0, %/blocks.10/attn/Unsqueeze_24_output_0, %/blocks.10/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_5\"](%/blocks.10/attn/MatMul_1_output_0, %/blocks.10/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.10/attn/Transpose_2\"](%/blocks.10/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_25\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3865), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3867 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_26\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3867), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3869 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_27\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3869), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_6\"](%/blocks.10/attn/Unsqueeze_25_output_0, %/blocks.10/attn/Unsqueeze_26_output_0, %/blocks.10/attn/Unsqueeze_27_output_0, %/blocks.10/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_6\"](%/blocks.10/attn/Transpose_2_output_0, %/blocks.10/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/proj/MatMul\"](%/blocks.10/attn/Reshape_6_output_0, %onnx::MatMul_5959), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/proj/Add\"](%blocks.10.attn.proj.bias, %/blocks.10/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_5\"](%/blocks.10/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_5\"](%/blocks.10/Shape_5_output_0, %/blocks.10/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/Mul\"](%/blocks.10/Add_output_0, %/blocks.10/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_2\"](%/blocks.10/Mul_output_0, %/blocks.10/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_6\"](%/blocks.10/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_7\"](%/blocks.10/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_3\"](%/blocks.10/Cast_7_output_0, %/blocks.10/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_8\"](%/blocks.10/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_9\"](%/blocks.10/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_4\"](%/blocks.10/Gather_5_output_0, %/blocks.10/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_10\"](%/blocks.10/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_11\"](%/blocks.10/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_9\"](%/blocks.10/Cast_11_output_0, %onnx::Unsqueeze_3893), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_10\"](%/blocks.10/Cast_3_output_0, %onnx::Unsqueeze_3895), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_11\"](%/blocks.10/Cast_5_output_0, %onnx::Unsqueeze_3897), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_5\"](%/blocks.10/Unsqueeze_9_output_0, %/blocks.10/Unsqueeze_10_output_0, %/blocks.10/Unsqueeze_11_output_0, %/blocks.10/Constant_36_output_0, %/blocks.10/Constant_37_output_0, %/blocks.10/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.10/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_4\"](%/blocks.10/attn/proj/Add_output_0, %/blocks.10/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.10/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.10/Transpose_2\"](%/blocks.10/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3908 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_12\"](%/blocks.10/Cast_11_output_0, %onnx::Unsqueeze_3908), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3910 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_13\"](%/blocks.10/Add_output_0, %onnx::Unsqueeze_3910), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_14\"](%/blocks.10/Add_1_output_0, %onnx::Unsqueeze_3912), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_6\"](%/blocks.10/Unsqueeze_12_output_0, %/blocks.10/Unsqueeze_13_output_0, %/blocks.10/Unsqueeze_14_output_0, %/blocks.10/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.10/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_5\"](%/blocks.10/Transpose_2_output_0, %/blocks.10/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.10/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_15\"](%/blocks.10/Gather_output_0, %/blocks.10/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice_1\"](%/blocks.10/Reshape_5_output_0, %/blocks.10/Constant_41_output_0, %/blocks.10/Unsqueeze_15_output_0, %/blocks.10/Constant_40_output_0, %/blocks.10/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_16\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice_2\"](%/blocks.10/Slice_1_output_0, %/blocks.10/Constant_45_output_0, %/blocks.10/Unsqueeze_16_output_0, %/blocks.10/Constant_44_output_0, %/blocks.10/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_2\"](%/blocks.9/Add_3_output_0, %/blocks.10/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.10/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.10/norm2/LayerNormalization\"](%/blocks.10/Add_2_output_0, %blocks.10.norm2.weight, %blocks.10.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.10/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/mlp/lin1/MatMul\"](%/blocks.10/norm2/LayerNormalization_output_0, %onnx::MatMul_5970), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/lin1/Add\"](%blocks.10.mlp.lin1.bias, %/blocks.10/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.10/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/mlp/act/Div\"](%/blocks.10/mlp/lin1/Add_output_0, %/blocks.10/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.10/mlp/act/Erf\"](%/blocks.10/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/act/Add\"](%/blocks.10/mlp/act/Erf_output_0, %/blocks.10/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/mlp/act/Mul\"](%/blocks.10/mlp/lin1/Add_output_0, %/blocks.10/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.10/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/mlp/act/Mul_1\"](%/blocks.10/mlp/act/Mul_output_0, %/blocks.10/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/mlp/lin2/MatMul\"](%/blocks.10/mlp/act/Mul_1_output_0, %onnx::MatMul_5971), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/lin2/Add\"](%blocks.10.mlp.lin2.bias, %/blocks.10/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_3\"](%/blocks.10/Add_2_output_0, %/blocks.10/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.11/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.11/norm1/LayerNormalization\"](%/blocks.10/Add_3_output_0, %blocks.11.norm1.weight, %blocks.11.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.11/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather\"](%/blocks.11/Shape_output_0, %/blocks.11/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_1\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_1\"](%/blocks.11/Shape_1_output_0, %/blocks.11/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_2\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_2\"](%/blocks.11/Shape_2_output_0, %/blocks.11/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_3\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_3\"](%/blocks.11/Shape_3_output_0, %/blocks.11/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod\"](%/blocks.11/Gather_output_0, %/blocks.11/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub\"](%/blocks.11/Constant_5_output_0, %/blocks.11/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_1\"](%/blocks.11/Sub_output_0, %/blocks.11/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_2\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub_1\"](%/blocks.11/Constant_8_output_0, %/blocks.11/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_3\"](%/blocks.11/Sub_1_output_0, %/blocks.11/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze\"](%/blocks.11/Mod_3_output_0, %onnx::Unsqueeze_3984), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3988 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_1\"](%/blocks.11/Mod_1_output_0, %onnx::Unsqueeze_3988), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat\"](%/blocks.11/Constant_10_output_0, %/blocks.11/Constant_11_output_0, %/blocks.11/Constant_12_output_0, %/blocks.11/Unsqueeze_output_0, %/blocks.11/Constant_13_output_0, %/blocks.11/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_2\"](%/blocks.11/Mod_3_output_0, %onnx::Unsqueeze_3997), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_3\"](%/blocks.11/Mod_1_output_0, %onnx::Unsqueeze_4001), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_1\"](%/blocks.11/Constant_14_output_0, %/blocks.11/Constant_15_output_0, %/blocks.11/Constant_16_output_0, %/blocks.11/Unsqueeze_2_output_0, %/blocks.11/Constant_17_output_0, %/blocks.11/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_4\"](%/blocks.11/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_4\"](%/blocks.11/Shape_4_output_0, %/blocks.11/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.11/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub_2\"](%/blocks.11/Constant_19_output_0, %/blocks.11/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast\"](%/blocks.11/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.11/ConstantOfShape\"](%/blocks.11/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_2\"](%/blocks.11/Cast_output_0, %/blocks.11/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.11/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape\"](%/blocks.11/Concat_2_output_0, %/blocks.11/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.11/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice\"](%/blocks.11/Reshape_output_0, %/blocks.11/Constant_22_output_0, %/blocks.11/Constant_23_output_0, %/blocks.11/Constant_21_output_0, %/blocks.11/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.11/Transpose\"](%/blocks.11/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_1\"](%/blocks.11/Transpose_output_0, %/blocks.11/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_1\"](%/blocks.11/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.11/Pad\"](%/blocks.11/norm1/LayerNormalization_output_0, %/blocks.11/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add\"](%/blocks.11/Gather_output_0, %/blocks.11/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.11/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_1\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.11/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div\"](%/blocks.11/Add_output_0, %/blocks.11/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_2\"](%/blocks.11/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_3\"](%/blocks.11/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_1\"](%/blocks.11/Add_1_output_0, %/blocks.11/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_4\"](%/blocks.11/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_5\"](%/blocks.11/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4036 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_4\"](%/blocks.11/Gather_2_output_0, %onnx::Unsqueeze_4036), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4038 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_5\"](%/blocks.11/Cast_3_output_0, %onnx::Unsqueeze_4038), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4042 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_6\"](%/blocks.11/Cast_5_output_0, %onnx::Unsqueeze_4042), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4046 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_7\"](%/blocks.11/Gather_3_output_0, %onnx::Unsqueeze_4046), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_3\"](%/blocks.11/Unsqueeze_4_output_0, %/blocks.11/Unsqueeze_5_output_0, %/blocks.11/Constant_28_output_0, %/blocks.11/Unsqueeze_6_output_0, %/blocks.11/Constant_29_output_0, %/blocks.11/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.11/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_2\"](%/blocks.11/Pad_output_0, %/blocks.11/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.11/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.11/Transpose_1\"](%/blocks.11/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_8\"](%/blocks.11/Gather_3_output_0, %onnx::Unsqueeze_4057), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_4\"](%/blocks.11/Constant_30_output_0, %/blocks.11/Constant_31_output_0, %/blocks.11/Constant_32_output_0, %/blocks.11/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_3\"](%/blocks.11/Transpose_1_output_0, %/blocks.11/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather\"](%/blocks.11/attn/Shape_output_0, %/blocks.11/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_1\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_1\"](%/blocks.11/attn/Shape_1_output_0, %/blocks.11/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_2\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_2\"](%/blocks.11/attn/Shape_2_output_0, %/blocks.11/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/qkv/MatMul\"](%/blocks.11/Reshape_3_output_0, %onnx::MatMul_5986), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/qkv/Add\"](%blocks.11.attn.qkv.bias, %/blocks.11/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul\"](%/blocks.11/attn/Gather_1_output_0, %/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4074), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4076 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_1\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4076), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat\"](%/blocks.11/attn/Unsqueeze_output_0, %/blocks.11/attn/Unsqueeze_1_output_0, %/blocks.11/attn/Constant_3_output_0, %/blocks.11/attn/Constant_4_output_0, %/blocks.11/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape\"](%/blocks.11/attn/qkv/Add_output_0, %/blocks.11/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.11/attn/Transpose\"](%/blocks.11/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_1\"](%/blocks.11/attn/Gather_output_0, %/blocks.11/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4091 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_2\"](%/blocks.11/attn/Mul_1_output_0, %onnx::Unsqueeze_4091), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_3\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4093), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_1\"](%/blocks.11/attn/Constant_7_output_0, %/blocks.11/attn/Unsqueeze_2_output_0, %/blocks.11/attn/Unsqueeze_3_output_0, %/blocks.11/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_1\"](%/blocks.11/attn/Transpose_output_0, %/blocks.11/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.11/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.11/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.11/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.11/attn/Split\"](%/blocks.11/attn/Reshape_1_output_0, %/blocks.11/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze\"](%/blocks.11/attn/Split_output_0, %/blocks.11/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze_1\"](%/blocks.11/attn/Split_output_1, %/blocks.11/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze_2\"](%/blocks.11/attn/Split_output_2, %/blocks.11/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.11/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_2\"](%/blocks.11/attn/Squeeze_output_0, %/blocks.11/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.11/attn/Transpose_1\"](%/blocks.11/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/MatMul\"](%/blocks.11/attn/Mul_2_output_0, %/blocks.11/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.11/attn/Range\"](%/blocks.11/attn/Constant_14_output_0, %/blocks.11/attn/Cast_output_0, %/blocks.11/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_4\"](%/blocks.11/attn/Range_output_0, %/blocks.11/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_1\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_2\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/attn/Div\"](%/blocks.11/attn/Cast_1_output_0, %/blocks.11/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_3\"](%/blocks.11/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_3\"](%/blocks.11/attn/Cast_3_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_5\"](%/blocks.11/attn/Range_output_0, %/blocks.11/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_4\"](%/blocks.11/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_4\"](%/blocks.11/attn/Cast_4_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub\"](%/blocks.11/attn/Mul_3_output_0, %/blocks.11/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_1\"](%/blocks.11/attn/Gather_1_output_0, %/blocks.11/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_5\"](%/blocks.11/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_5\"](%/blocks.11/attn/Cast_5_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add\"](%/blocks.11/attn/Sub_output_0, %/blocks.11/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_6\"](%/blocks.11/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_3\"](%blocks.11.attn.rel_pos_h, %/blocks.11/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_7\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.11/attn/Range_1\"](%/blocks.11/attn/Constant_19_output_0, %/blocks.11/attn/Cast_7_output_0, %/blocks.11/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_6\"](%/blocks.11/attn/Range_1_output_0, %/blocks.11/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_8\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_9\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/attn/Div_1\"](%/blocks.11/attn/Cast_8_output_0, %/blocks.11/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_10\"](%/blocks.11/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_6\"](%/blocks.11/attn/Cast_10_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_7\"](%/blocks.11/attn/Range_1_output_0, %/blocks.11/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_11\"](%/blocks.11/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_7\"](%/blocks.11/attn/Cast_11_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_2\"](%/blocks.11/attn/Mul_6_output_0, %/blocks.11/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_3\"](%/blocks.11/attn/Gather_2_output_0, %/blocks.11/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_12\"](%/blocks.11/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_8\"](%/blocks.11/attn/Cast_12_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_1\"](%/blocks.11/attn/Sub_2_output_0, %/blocks.11/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_13\"](%/blocks.11/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_4\"](%blocks.11.attn.rel_pos_w, %/blocks.11/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_3\"](%/blocks.11/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_5\"](%/blocks.11/attn/Shape_3_output_0, %/blocks.11/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_4\"](%/blocks.11/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_6\"](%/blocks.11/attn/Shape_4_output_0, %/blocks.11/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_8\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4165), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_9\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4167), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4169 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_10\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4169), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4171 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_11\"](%/blocks.11/attn/Gather_6_output_0, %onnx::Unsqueeze_4171), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_2\"](%/blocks.11/attn/Unsqueeze_8_output_0, %/blocks.11/attn/Unsqueeze_9_output_0, %/blocks.11/attn/Unsqueeze_10_output_0, %/blocks.11/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.11/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_2\"](%/blocks.11/attn/Squeeze_output_0, %/blocks.11/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.11/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.11/attn/Einsum\"](%/blocks.11/attn/Reshape_2_output_0, %/blocks.11/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.11/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.11/attn/Einsum_1\"](%/blocks.11/attn/Reshape_2_output_0, %/blocks.11/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4177 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_12\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4177), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_13\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4179), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4181 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_14\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4181), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_15\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4183), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_16\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4185), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_3\"](%/blocks.11/attn/Unsqueeze_12_output_0, %/blocks.11/attn/Unsqueeze_13_output_0, %/blocks.11/attn/Unsqueeze_14_output_0, %/blocks.11/attn/Unsqueeze_15_output_0, %/blocks.11/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_3\"](%/blocks.11/attn/MatMul_output_0, %/blocks.11/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.11/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_17\"](%/blocks.11/attn/Einsum_output_0, %/blocks.11/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_2\"](%/blocks.11/attn/Reshape_3_output_0, %/blocks.11/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_18\"](%/blocks.11/attn/Einsum_1_output_0, %/blocks.11/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_3\"](%/blocks.11/attn/Add_2_output_0, %/blocks.11/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4195 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_19\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4195), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_20\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4197), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_21\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4199), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_4\"](%/blocks.11/attn/Unsqueeze_19_output_0, %/blocks.11/attn/Unsqueeze_20_output_0, %/blocks.11/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.11/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_4\"](%/blocks.11/attn/Add_3_output_0, %/blocks.11/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.11/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.11/attn/Softmax\"](%/blocks.11/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.11/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/MatMul_1\"](%/blocks.11/attn/Softmax_output_0, %/blocks.11/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4205 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_22\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4205), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4209 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_23\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4209), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4211 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_24\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4211), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_5\"](%/blocks.11/attn/Unsqueeze_22_output_0, %/blocks.11/attn/Constant_28_output_0, %/blocks.11/attn/Unsqueeze_23_output_0, %/blocks.11/attn/Unsqueeze_24_output_0, %/blocks.11/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_5\"](%/blocks.11/attn/MatMul_1_output_0, %/blocks.11/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.11/attn/Transpose_2\"](%/blocks.11/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_25\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4218), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4220 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_26\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4220), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4222 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_27\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4222), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_6\"](%/blocks.11/attn/Unsqueeze_25_output_0, %/blocks.11/attn/Unsqueeze_26_output_0, %/blocks.11/attn/Unsqueeze_27_output_0, %/blocks.11/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_6\"](%/blocks.11/attn/Transpose_2_output_0, %/blocks.11/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/proj/MatMul\"](%/blocks.11/attn/Reshape_6_output_0, %onnx::MatMul_5995), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/proj/Add\"](%blocks.11.attn.proj.bias, %/blocks.11/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_5\"](%/blocks.11/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_5\"](%/blocks.11/Shape_5_output_0, %/blocks.11/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/Mul\"](%/blocks.11/Add_output_0, %/blocks.11/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_2\"](%/blocks.11/Mul_output_0, %/blocks.11/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_6\"](%/blocks.11/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_7\"](%/blocks.11/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_3\"](%/blocks.11/Cast_7_output_0, %/blocks.11/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_8\"](%/blocks.11/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_9\"](%/blocks.11/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_4\"](%/blocks.11/Gather_5_output_0, %/blocks.11/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_10\"](%/blocks.11/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_11\"](%/blocks.11/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4246 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_9\"](%/blocks.11/Cast_11_output_0, %onnx::Unsqueeze_4246), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4248 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_10\"](%/blocks.11/Cast_3_output_0, %onnx::Unsqueeze_4248), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4250 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_11\"](%/blocks.11/Cast_5_output_0, %onnx::Unsqueeze_4250), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_5\"](%/blocks.11/Unsqueeze_9_output_0, %/blocks.11/Unsqueeze_10_output_0, %/blocks.11/Unsqueeze_11_output_0, %/blocks.11/Constant_36_output_0, %/blocks.11/Constant_37_output_0, %/blocks.11/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.11/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_4\"](%/blocks.11/attn/proj/Add_output_0, %/blocks.11/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.11/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.11/Transpose_2\"](%/blocks.11/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_12\"](%/blocks.11/Cast_11_output_0, %onnx::Unsqueeze_4261), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_13\"](%/blocks.11/Add_output_0, %onnx::Unsqueeze_4263), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_14\"](%/blocks.11/Add_1_output_0, %onnx::Unsqueeze_4265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_6\"](%/blocks.11/Unsqueeze_12_output_0, %/blocks.11/Unsqueeze_13_output_0, %/blocks.11/Unsqueeze_14_output_0, %/blocks.11/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.11/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_5\"](%/blocks.11/Transpose_2_output_0, %/blocks.11/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.11/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_15\"](%/blocks.11/Gather_output_0, %/blocks.11/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice_1\"](%/blocks.11/Reshape_5_output_0, %/blocks.11/Constant_41_output_0, %/blocks.11/Unsqueeze_15_output_0, %/blocks.11/Constant_40_output_0, %/blocks.11/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_16\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice_2\"](%/blocks.11/Slice_1_output_0, %/blocks.11/Constant_45_output_0, %/blocks.11/Unsqueeze_16_output_0, %/blocks.11/Constant_44_output_0, %/blocks.11/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_2\"](%/blocks.10/Add_3_output_0, %/blocks.11/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.11/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.11/norm2/LayerNormalization\"](%/blocks.11/Add_2_output_0, %blocks.11.norm2.weight, %blocks.11.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.11/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/mlp/lin1/MatMul\"](%/blocks.11/norm2/LayerNormalization_output_0, %onnx::MatMul_6006), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/lin1/Add\"](%blocks.11.mlp.lin1.bias, %/blocks.11/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.11/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/mlp/act/Div\"](%/blocks.11/mlp/lin1/Add_output_0, %/blocks.11/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.11/mlp/act/Erf\"](%/blocks.11/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/act/Add\"](%/blocks.11/mlp/act/Erf_output_0, %/blocks.11/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/mlp/act/Mul\"](%/blocks.11/mlp/lin1/Add_output_0, %/blocks.11/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.11/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/mlp/act/Mul_1\"](%/blocks.11/mlp/act/Mul_output_0, %/blocks.11/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/mlp/lin2/MatMul\"](%/blocks.11/mlp/act/Mul_1_output_0, %onnx::MatMul_6007), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/lin2/Add\"](%blocks.11.mlp.lin2.bias, %/blocks.11/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_3\"](%/blocks.11/Add_2_output_0, %/blocks.11/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.12/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.12/norm1/LayerNormalization\"](%/blocks.11/Add_3_output_0, %blocks.12.norm1.weight, %blocks.12.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.12/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather\"](%/blocks.12/Shape_output_0, %/blocks.12/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_1\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_1\"](%/blocks.12/Shape_1_output_0, %/blocks.12/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_2\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_2\"](%/blocks.12/Shape_2_output_0, %/blocks.12/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_3\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_3\"](%/blocks.12/Shape_3_output_0, %/blocks.12/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod\"](%/blocks.12/Gather_output_0, %/blocks.12/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub\"](%/blocks.12/Constant_5_output_0, %/blocks.12/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_1\"](%/blocks.12/Sub_output_0, %/blocks.12/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_2\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub_1\"](%/blocks.12/Constant_8_output_0, %/blocks.12/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_3\"](%/blocks.12/Sub_1_output_0, %/blocks.12/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze\"](%/blocks.12/Mod_3_output_0, %onnx::Unsqueeze_4337), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4341 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_1\"](%/blocks.12/Mod_1_output_0, %onnx::Unsqueeze_4341), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat\"](%/blocks.12/Constant_10_output_0, %/blocks.12/Constant_11_output_0, %/blocks.12/Constant_12_output_0, %/blocks.12/Unsqueeze_output_0, %/blocks.12/Constant_13_output_0, %/blocks.12/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4350 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_2\"](%/blocks.12/Mod_3_output_0, %onnx::Unsqueeze_4350), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_3\"](%/blocks.12/Mod_1_output_0, %onnx::Unsqueeze_4354), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_1\"](%/blocks.12/Constant_14_output_0, %/blocks.12/Constant_15_output_0, %/blocks.12/Constant_16_output_0, %/blocks.12/Unsqueeze_2_output_0, %/blocks.12/Constant_17_output_0, %/blocks.12/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_4\"](%/blocks.12/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_4\"](%/blocks.12/Shape_4_output_0, %/blocks.12/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.12/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub_2\"](%/blocks.12/Constant_19_output_0, %/blocks.12/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast\"](%/blocks.12/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.12/ConstantOfShape\"](%/blocks.12/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_2\"](%/blocks.12/Cast_output_0, %/blocks.12/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.12/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape\"](%/blocks.12/Concat_2_output_0, %/blocks.12/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.12/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice\"](%/blocks.12/Reshape_output_0, %/blocks.12/Constant_22_output_0, %/blocks.12/Constant_23_output_0, %/blocks.12/Constant_21_output_0, %/blocks.12/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.12/Transpose\"](%/blocks.12/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_1\"](%/blocks.12/Transpose_output_0, %/blocks.12/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_1\"](%/blocks.12/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.12/Pad\"](%/blocks.12/norm1/LayerNormalization_output_0, %/blocks.12/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add\"](%/blocks.12/Gather_output_0, %/blocks.12/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.12/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_1\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.12/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div\"](%/blocks.12/Add_output_0, %/blocks.12/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_2\"](%/blocks.12/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_3\"](%/blocks.12/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_1\"](%/blocks.12/Add_1_output_0, %/blocks.12/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_4\"](%/blocks.12/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_5\"](%/blocks.12/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4389 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_4\"](%/blocks.12/Gather_2_output_0, %onnx::Unsqueeze_4389), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4391 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_5\"](%/blocks.12/Cast_3_output_0, %onnx::Unsqueeze_4391), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4395 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_6\"](%/blocks.12/Cast_5_output_0, %onnx::Unsqueeze_4395), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4399 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_7\"](%/blocks.12/Gather_3_output_0, %onnx::Unsqueeze_4399), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_3\"](%/blocks.12/Unsqueeze_4_output_0, %/blocks.12/Unsqueeze_5_output_0, %/blocks.12/Constant_28_output_0, %/blocks.12/Unsqueeze_6_output_0, %/blocks.12/Constant_29_output_0, %/blocks.12/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.12/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_2\"](%/blocks.12/Pad_output_0, %/blocks.12/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.12/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.12/Transpose_1\"](%/blocks.12/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_8\"](%/blocks.12/Gather_3_output_0, %onnx::Unsqueeze_4410), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_4\"](%/blocks.12/Constant_30_output_0, %/blocks.12/Constant_31_output_0, %/blocks.12/Constant_32_output_0, %/blocks.12/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_3\"](%/blocks.12/Transpose_1_output_0, %/blocks.12/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather\"](%/blocks.12/attn/Shape_output_0, %/blocks.12/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_1\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_1\"](%/blocks.12/attn/Shape_1_output_0, %/blocks.12/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_2\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_2\"](%/blocks.12/attn/Shape_2_output_0, %/blocks.12/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/qkv/MatMul\"](%/blocks.12/Reshape_3_output_0, %onnx::MatMul_6022), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/qkv/Add\"](%blocks.12.attn.qkv.bias, %/blocks.12/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul\"](%/blocks.12/attn/Gather_1_output_0, %/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4427 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4427), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4429 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_1\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4429), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat\"](%/blocks.12/attn/Unsqueeze_output_0, %/blocks.12/attn/Unsqueeze_1_output_0, %/blocks.12/attn/Constant_3_output_0, %/blocks.12/attn/Constant_4_output_0, %/blocks.12/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape\"](%/blocks.12/attn/qkv/Add_output_0, %/blocks.12/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.12/attn/Transpose\"](%/blocks.12/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_1\"](%/blocks.12/attn/Gather_output_0, %/blocks.12/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4444 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_2\"](%/blocks.12/attn/Mul_1_output_0, %onnx::Unsqueeze_4444), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_3\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4446), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_1\"](%/blocks.12/attn/Constant_7_output_0, %/blocks.12/attn/Unsqueeze_2_output_0, %/blocks.12/attn/Unsqueeze_3_output_0, %/blocks.12/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_1\"](%/blocks.12/attn/Transpose_output_0, %/blocks.12/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.12/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.12/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.12/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.12/attn/Split\"](%/blocks.12/attn/Reshape_1_output_0, %/blocks.12/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze\"](%/blocks.12/attn/Split_output_0, %/blocks.12/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze_1\"](%/blocks.12/attn/Split_output_1, %/blocks.12/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze_2\"](%/blocks.12/attn/Split_output_2, %/blocks.12/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.12/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_2\"](%/blocks.12/attn/Squeeze_output_0, %/blocks.12/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.12/attn/Transpose_1\"](%/blocks.12/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/MatMul\"](%/blocks.12/attn/Mul_2_output_0, %/blocks.12/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.12/attn/Range\"](%/blocks.12/attn/Constant_14_output_0, %/blocks.12/attn/Cast_output_0, %/blocks.12/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_4\"](%/blocks.12/attn/Range_output_0, %/blocks.12/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_1\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_2\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/attn/Div\"](%/blocks.12/attn/Cast_1_output_0, %/blocks.12/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_3\"](%/blocks.12/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_3\"](%/blocks.12/attn/Cast_3_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_5\"](%/blocks.12/attn/Range_output_0, %/blocks.12/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_4\"](%/blocks.12/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_4\"](%/blocks.12/attn/Cast_4_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub\"](%/blocks.12/attn/Mul_3_output_0, %/blocks.12/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_1\"](%/blocks.12/attn/Gather_1_output_0, %/blocks.12/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_5\"](%/blocks.12/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_5\"](%/blocks.12/attn/Cast_5_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add\"](%/blocks.12/attn/Sub_output_0, %/blocks.12/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_6\"](%/blocks.12/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_3\"](%blocks.12.attn.rel_pos_h, %/blocks.12/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_7\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.12/attn/Range_1\"](%/blocks.12/attn/Constant_19_output_0, %/blocks.12/attn/Cast_7_output_0, %/blocks.12/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_6\"](%/blocks.12/attn/Range_1_output_0, %/blocks.12/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_8\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_9\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/attn/Div_1\"](%/blocks.12/attn/Cast_8_output_0, %/blocks.12/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_10\"](%/blocks.12/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_6\"](%/blocks.12/attn/Cast_10_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_7\"](%/blocks.12/attn/Range_1_output_0, %/blocks.12/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_11\"](%/blocks.12/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_7\"](%/blocks.12/attn/Cast_11_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_2\"](%/blocks.12/attn/Mul_6_output_0, %/blocks.12/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_3\"](%/blocks.12/attn/Gather_2_output_0, %/blocks.12/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_12\"](%/blocks.12/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_8\"](%/blocks.12/attn/Cast_12_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_1\"](%/blocks.12/attn/Sub_2_output_0, %/blocks.12/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_13\"](%/blocks.12/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_4\"](%blocks.12.attn.rel_pos_w, %/blocks.12/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_3\"](%/blocks.12/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_5\"](%/blocks.12/attn/Shape_3_output_0, %/blocks.12/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_4\"](%/blocks.12/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_6\"](%/blocks.12/attn/Shape_4_output_0, %/blocks.12/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4518 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_8\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4518), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_9\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4520), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_10\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4522), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4524 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_11\"](%/blocks.12/attn/Gather_6_output_0, %onnx::Unsqueeze_4524), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_2\"](%/blocks.12/attn/Unsqueeze_8_output_0, %/blocks.12/attn/Unsqueeze_9_output_0, %/blocks.12/attn/Unsqueeze_10_output_0, %/blocks.12/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.12/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_2\"](%/blocks.12/attn/Squeeze_output_0, %/blocks.12/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.12/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.12/attn/Einsum\"](%/blocks.12/attn/Reshape_2_output_0, %/blocks.12/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.12/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.12/attn/Einsum_1\"](%/blocks.12/attn/Reshape_2_output_0, %/blocks.12/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_12\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4530), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_13\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4532), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_14\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4534), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_15\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4536), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_16\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4538), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_3\"](%/blocks.12/attn/Unsqueeze_12_output_0, %/blocks.12/attn/Unsqueeze_13_output_0, %/blocks.12/attn/Unsqueeze_14_output_0, %/blocks.12/attn/Unsqueeze_15_output_0, %/blocks.12/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_3\"](%/blocks.12/attn/MatMul_output_0, %/blocks.12/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.12/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_17\"](%/blocks.12/attn/Einsum_output_0, %/blocks.12/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_2\"](%/blocks.12/attn/Reshape_3_output_0, %/blocks.12/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_18\"](%/blocks.12/attn/Einsum_1_output_0, %/blocks.12/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_3\"](%/blocks.12/attn/Add_2_output_0, %/blocks.12/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4548 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_19\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4548), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_20\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4550), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_21\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4552), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_4\"](%/blocks.12/attn/Unsqueeze_19_output_0, %/blocks.12/attn/Unsqueeze_20_output_0, %/blocks.12/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.12/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_4\"](%/blocks.12/attn/Add_3_output_0, %/blocks.12/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.12/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.12/attn/Softmax\"](%/blocks.12/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.12/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/MatMul_1\"](%/blocks.12/attn/Softmax_output_0, %/blocks.12/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4558 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_22\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4558), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_23\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4562), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_24\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4564), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_5\"](%/blocks.12/attn/Unsqueeze_22_output_0, %/blocks.12/attn/Constant_28_output_0, %/blocks.12/attn/Unsqueeze_23_output_0, %/blocks.12/attn/Unsqueeze_24_output_0, %/blocks.12/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_5\"](%/blocks.12/attn/MatMul_1_output_0, %/blocks.12/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.12/attn/Transpose_2\"](%/blocks.12/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_25\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4571), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_26\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4573), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_27\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4575), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_6\"](%/blocks.12/attn/Unsqueeze_25_output_0, %/blocks.12/attn/Unsqueeze_26_output_0, %/blocks.12/attn/Unsqueeze_27_output_0, %/blocks.12/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_6\"](%/blocks.12/attn/Transpose_2_output_0, %/blocks.12/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/proj/MatMul\"](%/blocks.12/attn/Reshape_6_output_0, %onnx::MatMul_6031), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/proj/Add\"](%blocks.12.attn.proj.bias, %/blocks.12/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_5\"](%/blocks.12/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_5\"](%/blocks.12/Shape_5_output_0, %/blocks.12/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/Mul\"](%/blocks.12/Add_output_0, %/blocks.12/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_2\"](%/blocks.12/Mul_output_0, %/blocks.12/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_6\"](%/blocks.12/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_7\"](%/blocks.12/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_3\"](%/blocks.12/Cast_7_output_0, %/blocks.12/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_8\"](%/blocks.12/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_9\"](%/blocks.12/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_4\"](%/blocks.12/Gather_5_output_0, %/blocks.12/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_10\"](%/blocks.12/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_11\"](%/blocks.12/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_9\"](%/blocks.12/Cast_11_output_0, %onnx::Unsqueeze_4599), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_10\"](%/blocks.12/Cast_3_output_0, %onnx::Unsqueeze_4601), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4603 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_11\"](%/blocks.12/Cast_5_output_0, %onnx::Unsqueeze_4603), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_5\"](%/blocks.12/Unsqueeze_9_output_0, %/blocks.12/Unsqueeze_10_output_0, %/blocks.12/Unsqueeze_11_output_0, %/blocks.12/Constant_36_output_0, %/blocks.12/Constant_37_output_0, %/blocks.12/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.12/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_4\"](%/blocks.12/attn/proj/Add_output_0, %/blocks.12/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.12/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.12/Transpose_2\"](%/blocks.12/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4614 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_12\"](%/blocks.12/Cast_11_output_0, %onnx::Unsqueeze_4614), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4616 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_13\"](%/blocks.12/Add_output_0, %onnx::Unsqueeze_4616), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_14\"](%/blocks.12/Add_1_output_0, %onnx::Unsqueeze_4618), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_6\"](%/blocks.12/Unsqueeze_12_output_0, %/blocks.12/Unsqueeze_13_output_0, %/blocks.12/Unsqueeze_14_output_0, %/blocks.12/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.12/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_5\"](%/blocks.12/Transpose_2_output_0, %/blocks.12/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.12/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_15\"](%/blocks.12/Gather_output_0, %/blocks.12/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice_1\"](%/blocks.12/Reshape_5_output_0, %/blocks.12/Constant_41_output_0, %/blocks.12/Unsqueeze_15_output_0, %/blocks.12/Constant_40_output_0, %/blocks.12/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_16\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice_2\"](%/blocks.12/Slice_1_output_0, %/blocks.12/Constant_45_output_0, %/blocks.12/Unsqueeze_16_output_0, %/blocks.12/Constant_44_output_0, %/blocks.12/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_2\"](%/blocks.11/Add_3_output_0, %/blocks.12/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.12/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.12/norm2/LayerNormalization\"](%/blocks.12/Add_2_output_0, %blocks.12.norm2.weight, %blocks.12.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.12/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/mlp/lin1/MatMul\"](%/blocks.12/norm2/LayerNormalization_output_0, %onnx::MatMul_6042), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/lin1/Add\"](%blocks.12.mlp.lin1.bias, %/blocks.12/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.12/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/mlp/act/Div\"](%/blocks.12/mlp/lin1/Add_output_0, %/blocks.12/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.12/mlp/act/Erf\"](%/blocks.12/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/act/Add\"](%/blocks.12/mlp/act/Erf_output_0, %/blocks.12/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/mlp/act/Mul\"](%/blocks.12/mlp/lin1/Add_output_0, %/blocks.12/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.12/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/mlp/act/Mul_1\"](%/blocks.12/mlp/act/Mul_output_0, %/blocks.12/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/mlp/lin2/MatMul\"](%/blocks.12/mlp/act/Mul_1_output_0, %onnx::MatMul_6043), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/lin2/Add\"](%blocks.12.mlp.lin2.bias, %/blocks.12/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_3\"](%/blocks.12/Add_2_output_0, %/blocks.12/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.13/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.13/norm1/LayerNormalization\"](%/blocks.12/Add_3_output_0, %blocks.13.norm1.weight, %blocks.13.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.13/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather\"](%/blocks.13/Shape_output_0, %/blocks.13/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_1\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_1\"](%/blocks.13/Shape_1_output_0, %/blocks.13/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_2\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_2\"](%/blocks.13/Shape_2_output_0, %/blocks.13/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_3\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_3\"](%/blocks.13/Shape_3_output_0, %/blocks.13/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod\"](%/blocks.13/Gather_output_0, %/blocks.13/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub\"](%/blocks.13/Constant_5_output_0, %/blocks.13/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_1\"](%/blocks.13/Sub_output_0, %/blocks.13/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_2\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub_1\"](%/blocks.13/Constant_8_output_0, %/blocks.13/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_3\"](%/blocks.13/Sub_1_output_0, %/blocks.13/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze\"](%/blocks.13/Mod_3_output_0, %onnx::Unsqueeze_4690), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4694 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_1\"](%/blocks.13/Mod_1_output_0, %onnx::Unsqueeze_4694), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat\"](%/blocks.13/Constant_10_output_0, %/blocks.13/Constant_11_output_0, %/blocks.13/Constant_12_output_0, %/blocks.13/Unsqueeze_output_0, %/blocks.13/Constant_13_output_0, %/blocks.13/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_2\"](%/blocks.13/Mod_3_output_0, %onnx::Unsqueeze_4703), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_3\"](%/blocks.13/Mod_1_output_0, %onnx::Unsqueeze_4707), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_1\"](%/blocks.13/Constant_14_output_0, %/blocks.13/Constant_15_output_0, %/blocks.13/Constant_16_output_0, %/blocks.13/Unsqueeze_2_output_0, %/blocks.13/Constant_17_output_0, %/blocks.13/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_4\"](%/blocks.13/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_4\"](%/blocks.13/Shape_4_output_0, %/blocks.13/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.13/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub_2\"](%/blocks.13/Constant_19_output_0, %/blocks.13/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast\"](%/blocks.13/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.13/ConstantOfShape\"](%/blocks.13/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_2\"](%/blocks.13/Cast_output_0, %/blocks.13/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.13/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape\"](%/blocks.13/Concat_2_output_0, %/blocks.13/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.13/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice\"](%/blocks.13/Reshape_output_0, %/blocks.13/Constant_22_output_0, %/blocks.13/Constant_23_output_0, %/blocks.13/Constant_21_output_0, %/blocks.13/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.13/Transpose\"](%/blocks.13/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_1\"](%/blocks.13/Transpose_output_0, %/blocks.13/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_1\"](%/blocks.13/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.13/Pad\"](%/blocks.13/norm1/LayerNormalization_output_0, %/blocks.13/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add\"](%/blocks.13/Gather_output_0, %/blocks.13/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.13/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_1\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.13/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div\"](%/blocks.13/Add_output_0, %/blocks.13/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_2\"](%/blocks.13/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_3\"](%/blocks.13/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_1\"](%/blocks.13/Add_1_output_0, %/blocks.13/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_4\"](%/blocks.13/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_5\"](%/blocks.13/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4742 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_4\"](%/blocks.13/Gather_2_output_0, %onnx::Unsqueeze_4742), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4744 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_5\"](%/blocks.13/Cast_3_output_0, %onnx::Unsqueeze_4744), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4748 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_6\"](%/blocks.13/Cast_5_output_0, %onnx::Unsqueeze_4748), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4752 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_7\"](%/blocks.13/Gather_3_output_0, %onnx::Unsqueeze_4752), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_3\"](%/blocks.13/Unsqueeze_4_output_0, %/blocks.13/Unsqueeze_5_output_0, %/blocks.13/Constant_28_output_0, %/blocks.13/Unsqueeze_6_output_0, %/blocks.13/Constant_29_output_0, %/blocks.13/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.13/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_2\"](%/blocks.13/Pad_output_0, %/blocks.13/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.13/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.13/Transpose_1\"](%/blocks.13/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_8\"](%/blocks.13/Gather_3_output_0, %onnx::Unsqueeze_4763), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_4\"](%/blocks.13/Constant_30_output_0, %/blocks.13/Constant_31_output_0, %/blocks.13/Constant_32_output_0, %/blocks.13/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_3\"](%/blocks.13/Transpose_1_output_0, %/blocks.13/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather\"](%/blocks.13/attn/Shape_output_0, %/blocks.13/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_1\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_1\"](%/blocks.13/attn/Shape_1_output_0, %/blocks.13/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_2\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_2\"](%/blocks.13/attn/Shape_2_output_0, %/blocks.13/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/qkv/MatMul\"](%/blocks.13/Reshape_3_output_0, %onnx::MatMul_6058), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/qkv/Add\"](%blocks.13.attn.qkv.bias, %/blocks.13/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul\"](%/blocks.13/attn/Gather_1_output_0, %/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4780 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4780), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4782 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_1\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4782), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat\"](%/blocks.13/attn/Unsqueeze_output_0, %/blocks.13/attn/Unsqueeze_1_output_0, %/blocks.13/attn/Constant_3_output_0, %/blocks.13/attn/Constant_4_output_0, %/blocks.13/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape\"](%/blocks.13/attn/qkv/Add_output_0, %/blocks.13/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.13/attn/Transpose\"](%/blocks.13/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_1\"](%/blocks.13/attn/Gather_output_0, %/blocks.13/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4797 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_2\"](%/blocks.13/attn/Mul_1_output_0, %onnx::Unsqueeze_4797), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4799 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_3\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4799), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_1\"](%/blocks.13/attn/Constant_7_output_0, %/blocks.13/attn/Unsqueeze_2_output_0, %/blocks.13/attn/Unsqueeze_3_output_0, %/blocks.13/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_1\"](%/blocks.13/attn/Transpose_output_0, %/blocks.13/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.13/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.13/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.13/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.13/attn/Split\"](%/blocks.13/attn/Reshape_1_output_0, %/blocks.13/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze\"](%/blocks.13/attn/Split_output_0, %/blocks.13/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze_1\"](%/blocks.13/attn/Split_output_1, %/blocks.13/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze_2\"](%/blocks.13/attn/Split_output_2, %/blocks.13/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.13/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_2\"](%/blocks.13/attn/Squeeze_output_0, %/blocks.13/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.13/attn/Transpose_1\"](%/blocks.13/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/MatMul\"](%/blocks.13/attn/Mul_2_output_0, %/blocks.13/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.13/attn/Range\"](%/blocks.13/attn/Constant_14_output_0, %/blocks.13/attn/Cast_output_0, %/blocks.13/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_4\"](%/blocks.13/attn/Range_output_0, %/blocks.13/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_1\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_2\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/attn/Div\"](%/blocks.13/attn/Cast_1_output_0, %/blocks.13/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_3\"](%/blocks.13/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_3\"](%/blocks.13/attn/Cast_3_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_5\"](%/blocks.13/attn/Range_output_0, %/blocks.13/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_4\"](%/blocks.13/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_4\"](%/blocks.13/attn/Cast_4_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub\"](%/blocks.13/attn/Mul_3_output_0, %/blocks.13/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_1\"](%/blocks.13/attn/Gather_1_output_0, %/blocks.13/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_5\"](%/blocks.13/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_5\"](%/blocks.13/attn/Cast_5_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add\"](%/blocks.13/attn/Sub_output_0, %/blocks.13/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_6\"](%/blocks.13/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_3\"](%blocks.13.attn.rel_pos_h, %/blocks.13/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_7\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.13/attn/Range_1\"](%/blocks.13/attn/Constant_19_output_0, %/blocks.13/attn/Cast_7_output_0, %/blocks.13/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_6\"](%/blocks.13/attn/Range_1_output_0, %/blocks.13/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_8\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_9\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/attn/Div_1\"](%/blocks.13/attn/Cast_8_output_0, %/blocks.13/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_10\"](%/blocks.13/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_6\"](%/blocks.13/attn/Cast_10_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_7\"](%/blocks.13/attn/Range_1_output_0, %/blocks.13/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_11\"](%/blocks.13/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_7\"](%/blocks.13/attn/Cast_11_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_2\"](%/blocks.13/attn/Mul_6_output_0, %/blocks.13/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_3\"](%/blocks.13/attn/Gather_2_output_0, %/blocks.13/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_12\"](%/blocks.13/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_8\"](%/blocks.13/attn/Cast_12_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_1\"](%/blocks.13/attn/Sub_2_output_0, %/blocks.13/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_13\"](%/blocks.13/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_4\"](%blocks.13.attn.rel_pos_w, %/blocks.13/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_3\"](%/blocks.13/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_5\"](%/blocks.13/attn/Shape_3_output_0, %/blocks.13/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_4\"](%/blocks.13/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_6\"](%/blocks.13/attn/Shape_4_output_0, %/blocks.13/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4871 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_8\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4871), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4873 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_9\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4873), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_10\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4875), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_11\"](%/blocks.13/attn/Gather_6_output_0, %onnx::Unsqueeze_4877), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_2\"](%/blocks.13/attn/Unsqueeze_8_output_0, %/blocks.13/attn/Unsqueeze_9_output_0, %/blocks.13/attn/Unsqueeze_10_output_0, %/blocks.13/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.13/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_2\"](%/blocks.13/attn/Squeeze_output_0, %/blocks.13/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.13/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.13/attn/Einsum\"](%/blocks.13/attn/Reshape_2_output_0, %/blocks.13/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.13/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.13/attn/Einsum_1\"](%/blocks.13/attn/Reshape_2_output_0, %/blocks.13/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_12\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4883), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_13\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4885), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_14\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4887), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_15\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4889), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_16\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4891), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_3\"](%/blocks.13/attn/Unsqueeze_12_output_0, %/blocks.13/attn/Unsqueeze_13_output_0, %/blocks.13/attn/Unsqueeze_14_output_0, %/blocks.13/attn/Unsqueeze_15_output_0, %/blocks.13/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_3\"](%/blocks.13/attn/MatMul_output_0, %/blocks.13/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.13/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_17\"](%/blocks.13/attn/Einsum_output_0, %/blocks.13/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_2\"](%/blocks.13/attn/Reshape_3_output_0, %/blocks.13/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_18\"](%/blocks.13/attn/Einsum_1_output_0, %/blocks.13/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_3\"](%/blocks.13/attn/Add_2_output_0, %/blocks.13/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4901 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_19\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4901), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_20\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4903), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_21\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4905), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_4\"](%/blocks.13/attn/Unsqueeze_19_output_0, %/blocks.13/attn/Unsqueeze_20_output_0, %/blocks.13/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.13/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_4\"](%/blocks.13/attn/Add_3_output_0, %/blocks.13/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.13/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.13/attn/Softmax\"](%/blocks.13/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.13/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/MatMul_1\"](%/blocks.13/attn/Softmax_output_0, %/blocks.13/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4911 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_22\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4911), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4915 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_23\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4915), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4917 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_24\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4917), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_5\"](%/blocks.13/attn/Unsqueeze_22_output_0, %/blocks.13/attn/Constant_28_output_0, %/blocks.13/attn/Unsqueeze_23_output_0, %/blocks.13/attn/Unsqueeze_24_output_0, %/blocks.13/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_5\"](%/blocks.13/attn/MatMul_1_output_0, %/blocks.13/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.13/attn/Transpose_2\"](%/blocks.13/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4924 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_25\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4924), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4926 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_26\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4926), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_27\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4928), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_6\"](%/blocks.13/attn/Unsqueeze_25_output_0, %/blocks.13/attn/Unsqueeze_26_output_0, %/blocks.13/attn/Unsqueeze_27_output_0, %/blocks.13/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_6\"](%/blocks.13/attn/Transpose_2_output_0, %/blocks.13/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/proj/MatMul\"](%/blocks.13/attn/Reshape_6_output_0, %onnx::MatMul_6067), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/proj/Add\"](%blocks.13.attn.proj.bias, %/blocks.13/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_5\"](%/blocks.13/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_5\"](%/blocks.13/Shape_5_output_0, %/blocks.13/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/Mul\"](%/blocks.13/Add_output_0, %/blocks.13/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_2\"](%/blocks.13/Mul_output_0, %/blocks.13/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_6\"](%/blocks.13/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_7\"](%/blocks.13/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_3\"](%/blocks.13/Cast_7_output_0, %/blocks.13/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_8\"](%/blocks.13/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_9\"](%/blocks.13/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_4\"](%/blocks.13/Gather_5_output_0, %/blocks.13/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_10\"](%/blocks.13/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_11\"](%/blocks.13/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4952 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_9\"](%/blocks.13/Cast_11_output_0, %onnx::Unsqueeze_4952), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4954 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_10\"](%/blocks.13/Cast_3_output_0, %onnx::Unsqueeze_4954), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4956 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_11\"](%/blocks.13/Cast_5_output_0, %onnx::Unsqueeze_4956), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_5\"](%/blocks.13/Unsqueeze_9_output_0, %/blocks.13/Unsqueeze_10_output_0, %/blocks.13/Unsqueeze_11_output_0, %/blocks.13/Constant_36_output_0, %/blocks.13/Constant_37_output_0, %/blocks.13/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.13/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_4\"](%/blocks.13/attn/proj/Add_output_0, %/blocks.13/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.13/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.13/Transpose_2\"](%/blocks.13/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_12\"](%/blocks.13/Cast_11_output_0, %onnx::Unsqueeze_4967), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4969 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_13\"](%/blocks.13/Add_output_0, %onnx::Unsqueeze_4969), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_14\"](%/blocks.13/Add_1_output_0, %onnx::Unsqueeze_4971), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_6\"](%/blocks.13/Unsqueeze_12_output_0, %/blocks.13/Unsqueeze_13_output_0, %/blocks.13/Unsqueeze_14_output_0, %/blocks.13/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.13/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_5\"](%/blocks.13/Transpose_2_output_0, %/blocks.13/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.13/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_15\"](%/blocks.13/Gather_output_0, %/blocks.13/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice_1\"](%/blocks.13/Reshape_5_output_0, %/blocks.13/Constant_41_output_0, %/blocks.13/Unsqueeze_15_output_0, %/blocks.13/Constant_40_output_0, %/blocks.13/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_16\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice_2\"](%/blocks.13/Slice_1_output_0, %/blocks.13/Constant_45_output_0, %/blocks.13/Unsqueeze_16_output_0, %/blocks.13/Constant_44_output_0, %/blocks.13/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_2\"](%/blocks.12/Add_3_output_0, %/blocks.13/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.13/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.13/norm2/LayerNormalization\"](%/blocks.13/Add_2_output_0, %blocks.13.norm2.weight, %blocks.13.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.13/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/mlp/lin1/MatMul\"](%/blocks.13/norm2/LayerNormalization_output_0, %onnx::MatMul_6078), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/lin1/Add\"](%blocks.13.mlp.lin1.bias, %/blocks.13/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.13/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/mlp/act/Div\"](%/blocks.13/mlp/lin1/Add_output_0, %/blocks.13/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.13/mlp/act/Erf\"](%/blocks.13/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/act/Add\"](%/blocks.13/mlp/act/Erf_output_0, %/blocks.13/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/mlp/act/Mul\"](%/blocks.13/mlp/lin1/Add_output_0, %/blocks.13/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.13/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/mlp/act/Mul_1\"](%/blocks.13/mlp/act/Mul_output_0, %/blocks.13/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/mlp/lin2/MatMul\"](%/blocks.13/mlp/act/Mul_1_output_0, %onnx::MatMul_6079), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/lin2/Add\"](%blocks.13.mlp.lin2.bias, %/blocks.13/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_3\"](%/blocks.13/Add_2_output_0, %/blocks.13/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.14/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.14/norm1/LayerNormalization\"](%/blocks.13/Add_3_output_0, %blocks.14.norm1.weight, %blocks.14.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.14/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather\"](%/blocks.14/Shape_output_0, %/blocks.14/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_1\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_1\"](%/blocks.14/Shape_1_output_0, %/blocks.14/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_2\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_2\"](%/blocks.14/Shape_2_output_0, %/blocks.14/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_3\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_3\"](%/blocks.14/Shape_3_output_0, %/blocks.14/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod\"](%/blocks.14/Gather_output_0, %/blocks.14/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub\"](%/blocks.14/Constant_5_output_0, %/blocks.14/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_1\"](%/blocks.14/Sub_output_0, %/blocks.14/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_2\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub_1\"](%/blocks.14/Constant_8_output_0, %/blocks.14/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_3\"](%/blocks.14/Sub_1_output_0, %/blocks.14/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze\"](%/blocks.14/Mod_3_output_0, %onnx::Unsqueeze_5043), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5047 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_1\"](%/blocks.14/Mod_1_output_0, %onnx::Unsqueeze_5047), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat\"](%/blocks.14/Constant_10_output_0, %/blocks.14/Constant_11_output_0, %/blocks.14/Constant_12_output_0, %/blocks.14/Unsqueeze_output_0, %/blocks.14/Constant_13_output_0, %/blocks.14/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_2\"](%/blocks.14/Mod_3_output_0, %onnx::Unsqueeze_5056), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_3\"](%/blocks.14/Mod_1_output_0, %onnx::Unsqueeze_5060), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_1\"](%/blocks.14/Constant_14_output_0, %/blocks.14/Constant_15_output_0, %/blocks.14/Constant_16_output_0, %/blocks.14/Unsqueeze_2_output_0, %/blocks.14/Constant_17_output_0, %/blocks.14/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_4\"](%/blocks.14/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_4\"](%/blocks.14/Shape_4_output_0, %/blocks.14/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.14/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub_2\"](%/blocks.14/Constant_19_output_0, %/blocks.14/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast\"](%/blocks.14/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.14/ConstantOfShape\"](%/blocks.14/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_2\"](%/blocks.14/Cast_output_0, %/blocks.14/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.14/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape\"](%/blocks.14/Concat_2_output_0, %/blocks.14/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.14/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice\"](%/blocks.14/Reshape_output_0, %/blocks.14/Constant_22_output_0, %/blocks.14/Constant_23_output_0, %/blocks.14/Constant_21_output_0, %/blocks.14/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.14/Transpose\"](%/blocks.14/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_1\"](%/blocks.14/Transpose_output_0, %/blocks.14/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_1\"](%/blocks.14/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.14/Pad\"](%/blocks.14/norm1/LayerNormalization_output_0, %/blocks.14/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add\"](%/blocks.14/Gather_output_0, %/blocks.14/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.14/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_1\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.14/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div\"](%/blocks.14/Add_output_0, %/blocks.14/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_2\"](%/blocks.14/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_3\"](%/blocks.14/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_1\"](%/blocks.14/Add_1_output_0, %/blocks.14/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_4\"](%/blocks.14/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_5\"](%/blocks.14/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_5095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_4\"](%/blocks.14/Gather_2_output_0, %onnx::Unsqueeze_5095), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5097 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_5\"](%/blocks.14/Cast_3_output_0, %onnx::Unsqueeze_5097), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5101 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_6\"](%/blocks.14/Cast_5_output_0, %onnx::Unsqueeze_5101), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_7\"](%/blocks.14/Gather_3_output_0, %onnx::Unsqueeze_5105), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_3\"](%/blocks.14/Unsqueeze_4_output_0, %/blocks.14/Unsqueeze_5_output_0, %/blocks.14/Constant_28_output_0, %/blocks.14/Unsqueeze_6_output_0, %/blocks.14/Constant_29_output_0, %/blocks.14/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.14/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_2\"](%/blocks.14/Pad_output_0, %/blocks.14/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.14/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.14/Transpose_1\"](%/blocks.14/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5116 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_8\"](%/blocks.14/Gather_3_output_0, %onnx::Unsqueeze_5116), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_4\"](%/blocks.14/Constant_30_output_0, %/blocks.14/Constant_31_output_0, %/blocks.14/Constant_32_output_0, %/blocks.14/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_3\"](%/blocks.14/Transpose_1_output_0, %/blocks.14/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather\"](%/blocks.14/attn/Shape_output_0, %/blocks.14/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_1\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_1\"](%/blocks.14/attn/Shape_1_output_0, %/blocks.14/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_2\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_2\"](%/blocks.14/attn/Shape_2_output_0, %/blocks.14/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/qkv/MatMul\"](%/blocks.14/Reshape_3_output_0, %onnx::MatMul_6094), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/qkv/Add\"](%blocks.14.attn.qkv.bias, %/blocks.14/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul\"](%/blocks.14/attn/Gather_1_output_0, %/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_5133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5133), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5135 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_1\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5135), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat\"](%/blocks.14/attn/Unsqueeze_output_0, %/blocks.14/attn/Unsqueeze_1_output_0, %/blocks.14/attn/Constant_3_output_0, %/blocks.14/attn/Constant_4_output_0, %/blocks.14/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape\"](%/blocks.14/attn/qkv/Add_output_0, %/blocks.14/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.14/attn/Transpose\"](%/blocks.14/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_1\"](%/blocks.14/attn/Gather_output_0, %/blocks.14/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_2\"](%/blocks.14/attn/Mul_1_output_0, %onnx::Unsqueeze_5150), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_3\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5152), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_1\"](%/blocks.14/attn/Constant_7_output_0, %/blocks.14/attn/Unsqueeze_2_output_0, %/blocks.14/attn/Unsqueeze_3_output_0, %/blocks.14/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_1\"](%/blocks.14/attn/Transpose_output_0, %/blocks.14/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.14/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.14/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.14/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.14/attn/Split\"](%/blocks.14/attn/Reshape_1_output_0, %/blocks.14/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze\"](%/blocks.14/attn/Split_output_0, %/blocks.14/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze_1\"](%/blocks.14/attn/Split_output_1, %/blocks.14/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze_2\"](%/blocks.14/attn/Split_output_2, %/blocks.14/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.14/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_2\"](%/blocks.14/attn/Squeeze_output_0, %/blocks.14/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.14/attn/Transpose_1\"](%/blocks.14/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/MatMul\"](%/blocks.14/attn/Mul_2_output_0, %/blocks.14/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.14/attn/Range\"](%/blocks.14/attn/Constant_14_output_0, %/blocks.14/attn/Cast_output_0, %/blocks.14/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_4\"](%/blocks.14/attn/Range_output_0, %/blocks.14/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_1\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_2\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/attn/Div\"](%/blocks.14/attn/Cast_1_output_0, %/blocks.14/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_3\"](%/blocks.14/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_3\"](%/blocks.14/attn/Cast_3_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_5\"](%/blocks.14/attn/Range_output_0, %/blocks.14/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_4\"](%/blocks.14/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_4\"](%/blocks.14/attn/Cast_4_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub\"](%/blocks.14/attn/Mul_3_output_0, %/blocks.14/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_1\"](%/blocks.14/attn/Gather_1_output_0, %/blocks.14/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_5\"](%/blocks.14/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_5\"](%/blocks.14/attn/Cast_5_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add\"](%/blocks.14/attn/Sub_output_0, %/blocks.14/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_6\"](%/blocks.14/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_3\"](%blocks.14.attn.rel_pos_h, %/blocks.14/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_7\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.14/attn/Range_1\"](%/blocks.14/attn/Constant_19_output_0, %/blocks.14/attn/Cast_7_output_0, %/blocks.14/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_6\"](%/blocks.14/attn/Range_1_output_0, %/blocks.14/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_8\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_9\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/attn/Div_1\"](%/blocks.14/attn/Cast_8_output_0, %/blocks.14/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_10\"](%/blocks.14/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_6\"](%/blocks.14/attn/Cast_10_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_7\"](%/blocks.14/attn/Range_1_output_0, %/blocks.14/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_11\"](%/blocks.14/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_7\"](%/blocks.14/attn/Cast_11_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_2\"](%/blocks.14/attn/Mul_6_output_0, %/blocks.14/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_3\"](%/blocks.14/attn/Gather_2_output_0, %/blocks.14/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_12\"](%/blocks.14/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_8\"](%/blocks.14/attn/Cast_12_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_1\"](%/blocks.14/attn/Sub_2_output_0, %/blocks.14/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_13\"](%/blocks.14/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_4\"](%blocks.14.attn.rel_pos_w, %/blocks.14/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_3\"](%/blocks.14/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_5\"](%/blocks.14/attn/Shape_3_output_0, %/blocks.14/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_4\"](%/blocks.14/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_6\"](%/blocks.14/attn/Shape_4_output_0, %/blocks.14/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_5224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_8\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5224), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_9\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5226), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_10\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5228), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_11\"](%/blocks.14/attn/Gather_6_output_0, %onnx::Unsqueeze_5230), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_2\"](%/blocks.14/attn/Unsqueeze_8_output_0, %/blocks.14/attn/Unsqueeze_9_output_0, %/blocks.14/attn/Unsqueeze_10_output_0, %/blocks.14/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.14/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_2\"](%/blocks.14/attn/Squeeze_output_0, %/blocks.14/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.14/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.14/attn/Einsum\"](%/blocks.14/attn/Reshape_2_output_0, %/blocks.14/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.14/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.14/attn/Einsum_1\"](%/blocks.14/attn/Reshape_2_output_0, %/blocks.14/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_5236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_12\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5236), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_13\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5238), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5240 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_14\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5240), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_15\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5242), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_16\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5244), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_3\"](%/blocks.14/attn/Unsqueeze_12_output_0, %/blocks.14/attn/Unsqueeze_13_output_0, %/blocks.14/attn/Unsqueeze_14_output_0, %/blocks.14/attn/Unsqueeze_15_output_0, %/blocks.14/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_3\"](%/blocks.14/attn/MatMul_output_0, %/blocks.14/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.14/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_17\"](%/blocks.14/attn/Einsum_output_0, %/blocks.14/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_2\"](%/blocks.14/attn/Reshape_3_output_0, %/blocks.14/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_18\"](%/blocks.14/attn/Einsum_1_output_0, %/blocks.14/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_3\"](%/blocks.14/attn/Add_2_output_0, %/blocks.14/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_5254 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_19\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5254), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_20\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5256), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5258 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_21\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5258), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_4\"](%/blocks.14/attn/Unsqueeze_19_output_0, %/blocks.14/attn/Unsqueeze_20_output_0, %/blocks.14/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.14/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_4\"](%/blocks.14/attn/Add_3_output_0, %/blocks.14/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.14/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.14/attn/Softmax\"](%/blocks.14/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.14/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/MatMul_1\"](%/blocks.14/attn/Softmax_output_0, %/blocks.14/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5264 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_22\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5264), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5268 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_23\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5268), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5270 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_24\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5270), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_5\"](%/blocks.14/attn/Unsqueeze_22_output_0, %/blocks.14/attn/Constant_28_output_0, %/blocks.14/attn/Unsqueeze_23_output_0, %/blocks.14/attn/Unsqueeze_24_output_0, %/blocks.14/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_5\"](%/blocks.14/attn/MatMul_1_output_0, %/blocks.14/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.14/attn/Transpose_2\"](%/blocks.14/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_25\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5277), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5279 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_26\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5279), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_27\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_6\"](%/blocks.14/attn/Unsqueeze_25_output_0, %/blocks.14/attn/Unsqueeze_26_output_0, %/blocks.14/attn/Unsqueeze_27_output_0, %/blocks.14/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_6\"](%/blocks.14/attn/Transpose_2_output_0, %/blocks.14/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/proj/MatMul\"](%/blocks.14/attn/Reshape_6_output_0, %onnx::MatMul_6103), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/proj/Add\"](%blocks.14.attn.proj.bias, %/blocks.14/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_5\"](%/blocks.14/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_5\"](%/blocks.14/Shape_5_output_0, %/blocks.14/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/Mul\"](%/blocks.14/Add_output_0, %/blocks.14/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_2\"](%/blocks.14/Mul_output_0, %/blocks.14/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_6\"](%/blocks.14/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_7\"](%/blocks.14/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_3\"](%/blocks.14/Cast_7_output_0, %/blocks.14/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_8\"](%/blocks.14/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_9\"](%/blocks.14/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_4\"](%/blocks.14/Gather_5_output_0, %/blocks.14/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_10\"](%/blocks.14/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_11\"](%/blocks.14/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_5305 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_9\"](%/blocks.14/Cast_11_output_0, %onnx::Unsqueeze_5305), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5307 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_10\"](%/blocks.14/Cast_3_output_0, %onnx::Unsqueeze_5307), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5309 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_11\"](%/blocks.14/Cast_5_output_0, %onnx::Unsqueeze_5309), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_5\"](%/blocks.14/Unsqueeze_9_output_0, %/blocks.14/Unsqueeze_10_output_0, %/blocks.14/Unsqueeze_11_output_0, %/blocks.14/Constant_36_output_0, %/blocks.14/Constant_37_output_0, %/blocks.14/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.14/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_4\"](%/blocks.14/attn/proj/Add_output_0, %/blocks.14/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.14/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.14/Transpose_2\"](%/blocks.14/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_5320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_12\"](%/blocks.14/Cast_11_output_0, %onnx::Unsqueeze_5320), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_13\"](%/blocks.14/Add_output_0, %onnx::Unsqueeze_5322), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5324 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_14\"](%/blocks.14/Add_1_output_0, %onnx::Unsqueeze_5324), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_6\"](%/blocks.14/Unsqueeze_12_output_0, %/blocks.14/Unsqueeze_13_output_0, %/blocks.14/Unsqueeze_14_output_0, %/blocks.14/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.14/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_5\"](%/blocks.14/Transpose_2_output_0, %/blocks.14/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.14/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_15\"](%/blocks.14/Gather_output_0, %/blocks.14/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice_1\"](%/blocks.14/Reshape_5_output_0, %/blocks.14/Constant_41_output_0, %/blocks.14/Unsqueeze_15_output_0, %/blocks.14/Constant_40_output_0, %/blocks.14/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_16\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice_2\"](%/blocks.14/Slice_1_output_0, %/blocks.14/Constant_45_output_0, %/blocks.14/Unsqueeze_16_output_0, %/blocks.14/Constant_44_output_0, %/blocks.14/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_2\"](%/blocks.13/Add_3_output_0, %/blocks.14/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.14/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.14/norm2/LayerNormalization\"](%/blocks.14/Add_2_output_0, %blocks.14.norm2.weight, %blocks.14.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.14/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/mlp/lin1/MatMul\"](%/blocks.14/norm2/LayerNormalization_output_0, %onnx::MatMul_6114), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/lin1/Add\"](%blocks.14.mlp.lin1.bias, %/blocks.14/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.14/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/mlp/act/Div\"](%/blocks.14/mlp/lin1/Add_output_0, %/blocks.14/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.14/mlp/act/Erf\"](%/blocks.14/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/act/Add\"](%/blocks.14/mlp/act/Erf_output_0, %/blocks.14/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/mlp/act/Mul\"](%/blocks.14/mlp/lin1/Add_output_0, %/blocks.14/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.14/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/mlp/act/Mul_1\"](%/blocks.14/mlp/act/Mul_output_0, %/blocks.14/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/mlp/lin2/MatMul\"](%/blocks.14/mlp/act/Mul_1_output_0, %onnx::MatMul_6115), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/lin2/Add\"](%blocks.14.mlp.lin2.bias, %/blocks.14/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_3\"](%/blocks.14/Add_2_output_0, %/blocks.14/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.15/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.15/norm1/LayerNormalization\"](%/blocks.14/Add_3_output_0, %blocks.15.norm1.weight, %blocks.15.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.15/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather\"](%/blocks.15/attn/Shape_output_0, %/blocks.15/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_1\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_1\"](%/blocks.15/attn/Shape_1_output_0, %/blocks.15/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_2\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.15/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_2\"](%/blocks.15/attn/Shape_2_output_0, %/blocks.15/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/qkv/MatMul\"](%/blocks.15/norm1/LayerNormalization_output_0, %onnx::MatMul_6116), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[15728640, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/qkv/Add\"](%blocks.15.attn.qkv.bias, %/blocks.15/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul\"](%/blocks.15/attn/Gather_1_output_0, %/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_5379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5379), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5381 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_1\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5381), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat\"](%/blocks.15/attn/Unsqueeze_output_0, %/blocks.15/attn/Unsqueeze_1_output_0, %/blocks.15/attn/Constant_3_output_0, %/blocks.15/attn/Constant_4_output_0, %/blocks.15/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[15728640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape\"](%/blocks.15/attn/qkv/Add_output_0, %/blocks.15/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 15728640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.15/attn/Transpose\"](%/blocks.15/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_1\"](%/blocks.15/attn/Gather_output_0, %/blocks.15/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5396 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_2\"](%/blocks.15/attn/Mul_1_output_0, %onnx::Unsqueeze_5396), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5398 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_3\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5398), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_1\"](%/blocks.15/attn/Constant_7_output_0, %/blocks.15/attn/Unsqueeze_2_output_0, %/blocks.15/attn/Unsqueeze_3_output_0, %/blocks.15/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[1280, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_1\"](%/blocks.15/attn/Transpose_output_0, %/blocks.15/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.15/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.15/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.15/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.15/attn/Split\"](%/blocks.15/attn/Reshape_1_output_0, %/blocks.15/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze\"](%/blocks.15/attn/Split_output_0, %/blocks.15/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze_1\"](%/blocks.15/attn/Split_output_1, %/blocks.15/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze_2\"](%/blocks.15/attn/Split_output_2, %/blocks.15/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.15/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Mul_2_output_0 : Float(*, *, *, strides=[80, 1280, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_2\"](%/blocks.15/attn/Squeeze_output_0, %/blocks.15/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Transpose_1_output_0 : Float(*, *, *, strides=[80, 1, 3840], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.15/attn/Transpose_1\"](%/blocks.15/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/MatMul_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/MatMul\"](%/blocks.15/attn/Mul_2_output_0, %/blocks.15/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.15/attn/Range\"](%/blocks.15/attn/Constant_14_output_0, %/blocks.15/attn/Cast_output_0, %/blocks.15/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_4\"](%/blocks.15/attn/Range_output_0, %/blocks.15/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_1\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_2\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/attn/Div\"](%/blocks.15/attn/Cast_1_output_0, %/blocks.15/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_3\"](%/blocks.15/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_3\"](%/blocks.15/attn/Cast_3_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_5\"](%/blocks.15/attn/Range_output_0, %/blocks.15/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Cast_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_4\"](%/blocks.15/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Mul_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_4\"](%/blocks.15/attn/Cast_4_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Sub_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub\"](%/blocks.15/attn/Mul_3_output_0, %/blocks.15/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_1\"](%/blocks.15/attn/Gather_1_output_0, %/blocks.15/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_5\"](%/blocks.15/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_5\"](%/blocks.15/attn/Cast_5_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Add_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add\"](%/blocks.15/attn/Sub_output_0, %/blocks.15/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_6_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_6\"](%/blocks.15/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Gather_3_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_3\"](%blocks.15.attn.rel_pos_h, %/blocks.15/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_7\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.15/attn/Range_1\"](%/blocks.15/attn/Constant_19_output_0, %/blocks.15/attn/Cast_7_output_0, %/blocks.15/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_6\"](%/blocks.15/attn/Range_1_output_0, %/blocks.15/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_8\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_9\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/attn/Div_1\"](%/blocks.15/attn/Cast_8_output_0, %/blocks.15/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_10\"](%/blocks.15/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_6\"](%/blocks.15/attn/Cast_10_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_7\"](%/blocks.15/attn/Range_1_output_0, %/blocks.15/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Cast_11_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_11\"](%/blocks.15/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Mul_7_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_7\"](%/blocks.15/attn/Cast_11_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Sub_2_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_2\"](%/blocks.15/attn/Mul_6_output_0, %/blocks.15/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_3\"](%/blocks.15/attn/Gather_2_output_0, %/blocks.15/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_12\"](%/blocks.15/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_8\"](%/blocks.15/attn/Cast_12_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Add_1_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_1\"](%/blocks.15/attn/Sub_2_output_0, %/blocks.15/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_13_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_13\"](%/blocks.15/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Gather_4_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_4\"](%blocks.15.attn.rel_pos_w, %/blocks.15/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_3\"](%/blocks.15/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_5\"](%/blocks.15/attn/Shape_3_output_0, %/blocks.15/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_4\"](%/blocks.15/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.15/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_6\"](%/blocks.15/attn/Shape_4_output_0, %/blocks.15/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_5470 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_8\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5470), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5472 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_9\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5472), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5474 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_10\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5474), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_11\"](%/blocks.15/attn/Gather_6_output_0, %onnx::Unsqueeze_5476), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_2\"](%/blocks.15/attn/Unsqueeze_8_output_0, %/blocks.15/attn/Unsqueeze_9_output_0, %/blocks.15/attn/Unsqueeze_10_output_0, %/blocks.15/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.15/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[80, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_2\"](%/blocks.15/attn/Squeeze_output_0, %/blocks.15/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.15/attn/Einsum_output_0 : Float(*, *, *, *, strides=[4096, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.15/attn/Einsum\"](%/blocks.15/attn/Reshape_2_output_0, %/blocks.15/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.15/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[4096, 64, 65536, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.15/attn/Einsum_1\"](%/blocks.15/attn/Reshape_2_output_0, %/blocks.15/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_5482 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_12\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5482), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5484 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_13\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5484), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_14\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5486), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_15\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5488), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_16\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5490), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_3\"](%/blocks.15/attn/Unsqueeze_12_output_0, %/blocks.15/attn/Unsqueeze_13_output_0, %/blocks.15/attn/Unsqueeze_14_output_0, %/blocks.15/attn/Unsqueeze_15_output_0, %/blocks.15/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_3\"](%/blocks.15/attn/MatMul_output_0, %/blocks.15/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.15/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[4096, 65536, 64, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_17\"](%/blocks.15/attn/Einsum_output_0, %/blocks.15/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_2\"](%/blocks.15/attn/Reshape_3_output_0, %/blocks.15/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[4096, 64, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_18\"](%/blocks.15/attn/Einsum_1_output_0, %/blocks.15/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_3\"](%/blocks.15/attn/Add_2_output_0, %/blocks.15/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_5500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_19\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5500), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_20\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5502), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_21\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5504), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_4\"](%/blocks.15/attn/Unsqueeze_19_output_0, %/blocks.15/attn/Unsqueeze_20_output_0, %/blocks.15/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.15/attn/Reshape_4_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_4\"](%/blocks.15/attn/Add_3_output_0, %/blocks.15/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.15/attn/Softmax_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.15/attn/Softmax\"](%/blocks.15/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.15/attn/MatMul_1_output_0 : Float(*, *, *, strides=[327680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/MatMul_1\"](%/blocks.15/attn/Softmax_output_0, %/blocks.15/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5510 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_22\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5510), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_23\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5514), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_24\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5516), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_5\"](%/blocks.15/attn/Unsqueeze_22_output_0, %/blocks.15/attn/Constant_28_output_0, %/blocks.15/attn/Unsqueeze_23_output_0, %/blocks.15/attn/Unsqueeze_24_output_0, %/blocks.15/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[5242880, 327680, 5120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_5\"](%/blocks.15/attn/MatMul_1_output_0, %/blocks.15/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[5242880, 5120, 80, 327680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.15/attn/Transpose_2\"](%/blocks.15/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_25\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5523), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_26\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5525), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_27\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5527), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_6\"](%/blocks.15/attn/Unsqueeze_25_output_0, %/blocks.15/attn/Unsqueeze_26_output_0, %/blocks.15/attn/Unsqueeze_27_output_0, %/blocks.15/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_6\"](%/blocks.15/attn/Transpose_2_output_0, %/blocks.15/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/proj/MatMul\"](%/blocks.15/attn/Reshape_6_output_0, %onnx::MatMul_6125), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/proj/Add\"](%blocks.15.attn.proj.bias, %/blocks.15/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/Add_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add\"](%/blocks.14/Add_3_output_0, %/blocks.15/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.15/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.15/norm2/LayerNormalization\"](%/blocks.15/Add_output_0, %blocks.15.norm2.weight, %blocks.15.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.15/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin1/MatMul\"](%/blocks.15/norm2/LayerNormalization_output_0, %onnx::MatMul_6126), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin1/Add\"](%blocks.15.mlp.lin1.bias, %/blocks.15/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.15/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/mlp/act/Div\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.15/mlp/act/Erf\"](%/blocks.15/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/act/Add\"](%/blocks.15/mlp/act/Erf_output_0, %/blocks.15/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.15/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul_1\"](%/blocks.15/mlp/act/Mul_output_0, %/blocks.15/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin2/MatMul\"](%/blocks.15/mlp/act/Mul_1_output_0, %onnx::MatMul_6127), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin2/Add\"](%blocks.15.mlp.lin2.bias, %/blocks.15/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/Add_1_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add_1\"](%/blocks.15/Add_output_0, %/blocks.15/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/Transpose_output_0 : Float(*, *, *, *, strides=[5242880, 1, 81920, 1280], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/Transpose\"](%/blocks.15/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf:: # /content/SegmentAnything-TensorRT/sam_modification/ImageEncoderModels.py:208:0\n",
            "  %/neck/neck.0/Conv_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/neck.0/Conv\"](%/Transpose_output_0, %neck.0.weight), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/torch.nn.modules.conv.Conv2d::neck.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n",
            "  %/neck/neck.1/ReduceMean_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.1/ReduceMean\"](%/neck/neck.0/Conv_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:39:0\n",
            "  %/neck/neck.1/Sub_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/neck/neck.1/Sub\"](%/neck/neck.0/Conv_output_0, %/neck/neck.1/ReduceMean_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/neck/neck.1/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Pow_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Pow[onnx_name=\"/neck/neck.1/Pow\"](%/neck/neck.1/Sub_output_0, %/neck/neck.1/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/ReduceMean_1_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.1/ReduceMean_1\"](%/neck/neck.1/Pow_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/neck/neck.1/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Add_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.1/Add\"](%/neck/neck.1/ReduceMean_1_output_0, %/neck/neck.1/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Sqrt_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name=\"/neck/neck.1/Sqrt\"](%/neck/neck.1/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Div_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/neck/neck.1/Div\"](%/neck/neck.1/Sub_output_0, %/neck/neck.1/Sqrt_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Mul_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/neck/neck.1/Mul\"](%onnx::Mul_6129, %/neck/neck.1/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %/neck/neck.1/Add_1_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.1/Add_1\"](%/neck/neck.1/Mul_output_0, %onnx::Add_6131), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %/neck/neck.2/Conv_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/neck.2/Conv\"](%/neck/neck.1/Add_1_output_0, %neck.2.weight), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/torch.nn.modules.conv.Conv2d::neck.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n",
            "  %/neck/neck.3/ReduceMean_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.3/ReduceMean\"](%/neck/neck.2/Conv_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:39:0\n",
            "  %/neck/neck.3/Sub_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/neck/neck.3/Sub\"](%/neck/neck.2/Conv_output_0, %/neck/neck.3/ReduceMean_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/neck/neck.3/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Pow_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Pow[onnx_name=\"/neck/neck.3/Pow\"](%/neck/neck.3/Sub_output_0, %/neck/neck.3/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/ReduceMean_1_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.3/ReduceMean_1\"](%/neck/neck.3/Pow_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/neck/neck.3/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Add_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.3/Add\"](%/neck/neck.3/ReduceMean_1_output_0, %/neck/neck.3/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Sqrt_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name=\"/neck/neck.3/Sqrt\"](%/neck/neck.3/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Div_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/neck/neck.3/Div\"](%/neck/neck.3/Sub_output_0, %/neck/neck.3/Sqrt_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Mul_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/neck/neck.3/Mul\"](%onnx::Mul_6133, %/neck/neck.3/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %output_1 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.3/Add_1\"](%/neck/neck.3/Mul_output_0, %onnx::Add_6135), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  return (%output_1)\n",
            "\n",
            "sh: 1: trtexec: not found\n",
            "sh: 1: trtexec: not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Exportar primer modelo ONNX a ENGINE (.engine)\n",
        "!python export_engine.py \\\n",
        "  --onnx_model_path exported_models/vit_h/sam_vit_h_embedding_first.onnx \\\n",
        "  --engine_output_path checkpoints/sam_vit_h_embedding_first.engine \\\n",
        "  --use_fp16 True\n",
        "\n",
        "# ✅ Exportar segundo modelo ONNX a ENGINE (.engine)\n",
        "!python export_engine.py \\\n",
        "  --onnx_model_path exported_models/vit_h/sam_vit_h_embedding_second.onnx \\\n",
        "  --engine_output_path checkpoints/sam_vit_h_embedding_second.engine \\\n",
        "  --use_fp16 True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVJn2ypAr8p",
        "outputId": "706dbd62-92d8-4aba-cb49-ad176a3b524d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TensorRT engine successfully saved to checkpoints/sam_vit_h_embedding_first.engine\n",
            "[06/16/2025-10:36:00] [TRT] [W] Detected layernorm nodes in FP16.\n",
            "[06/16/2025-10:36:00] [TRT] [W] Running layernorm after self-attention with FP16 Reduce or Pow may cause overflow. Forcing Reduce or Pow Layers in FP32 precision, or exporting the model to use INormalizationLayer (available with ONNX opset >= 17) can help preserving accuracy.\n",
            "✅ TensorRT engine successfully saved to checkpoints/sam_vit_h_embedding_second.engine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzJJX9qTaTPI",
        "outputId": "7fc735cb-aa51-4a8e-9430-3e9758ae51c7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwx------  6 root root 4096 Jun 16 10:14 drive\n",
            "drwxr-xr-x  1 root root 4096 Jun 12 13:36 sample_data\n",
            "drwxr-xr-x  9 root root 4096 Jun 16 10:18 segment_anything\n",
            "drwxr-xr-x 10 root root 4096 Jun 16 10:34 SegmentAnything-TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Ruta al directorio que CONTIENE el paquete\n",
        "ruta_paquete = '/content/segment_anything'\n",
        "\n",
        "# Añadimos la ruta (si no está ya)\n",
        "if ruta_paquete not in sys.path:\n",
        "    sys.path.append(ruta_paquete)\n",
        "\n",
        "try:\n",
        "    # --- LA CORRECCIÓN ESTÁ AQUÍ ---\n",
        "    # Importamos cada objeto desde su archivo correcto.\n",
        "    from segment_anything.build_sam import sam_model_registry\n",
        "    from segment_anything.predictor import SamPredictor\n",
        "\n",
        "    print(\"✅✅✅ ¡ÉXITO TOTAL! Los módulos se han importado correctamente.\")\n",
        "    print(\"SamPredictor y sam_model_registry están listos para ser usados.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Un último error de importación: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAEl1jlpak5x",
        "outputId": "f52a43ea-2cbc-4409-ecd9-369d72ac8d34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅✅✅ ¡ÉXITO TOTAL! Los módulos se han importado correctamente.\n",
            "SamPredictor y sam_model_registry están listos para ser usados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/segment_anything/segment_anything/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NojEeDVRa2vI",
        "outputId": "505929d6-7750-4f67-9a37-1eea120dd17a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 48\n",
            "-rw-r--r-- 1 root root 15148 Jun 16 10:18 automatic_mask_generator.py\n",
            "-rw-r--r-- 1 root root  2941 Jun 16 10:18 build_sam.py\n",
            "-rw-r--r-- 1 root root   427 Jun 16 10:18 __init__.py\n",
            "drwxr-xr-x 3 root root  4096 Jun 16 10:20 modeling\n",
            "-rw-r--r-- 1 root root 11649 Jun 16 10:18 predictor.py\n",
            "drwxr-xr-x 2 root root  4096 Jun 16 10:20 __pycache__\n",
            "drwxr-xr-x 3 root root  4096 Jun 16 10:20 utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# --- 1. RUTA AL DIRECTORIO RAÍZ DEL PROYECTO ---\n",
        "# La ruta correcta es a la carpeta principal, la que contiene 'src'.\n",
        "ruta_proyecto = '/content/SegmentAnything-TensorRT'\n",
        "\n",
        "# --- 2. AÑADIR LA RUTA RAÍZ AL PATH ---\n",
        "if ruta_proyecto not in sys.path:\n",
        "    sys.path.append(ruta_proyecto)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto}\")\n",
        "\n",
        "# --- 3. IMPORTAR USANDO LA RUTA COMPLETA DESDE LA RAÍZ ---\n",
        "# El cambio clave: especificamos 'src.infer' para indicar la ruta completa.\n",
        "try:\n",
        "    from src.infer import InferenceEngine\n",
        "\n",
        "    print(\"\\n✅ ¡Éxito! Ahora sí. Se ha importado 'InferenceEngine' correctamente.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\n❌ Error de importación: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rgo_5M_ew0p",
        "outputId": "2081fbc0-dc08-4b40-d55a-acf0c923a3d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta del proyecto añadida: /content/SegmentAnything-TensorRT\n",
            "\n",
            "✅ ¡Éxito! Ahora sí. Se ha importado 'InferenceEngine' correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SegmentAnything-TensorRT/src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jztEFI3be9-X",
        "outputId": "254d8af8-fd08-4180-dc36-fbdbf108953d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 60\n",
            "-rw-r--r-- 1 root root 18664 Jun 16 10:15 benchmark.py\n",
            "-rw-r--r-- 1 root root 18414 Jun 16 10:15 export.py\n",
            "-rw-r--r-- 1 root root  7897 Jun 16 10:53 infer.py\n",
            "drwxr-xr-x 2 root root  4096 Jun 16 10:54 __pycache__\n",
            "-rw-r--r-- 1 root root  7506 Jun 16 10:50 utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# --- PASO 1: DEFINIR LA RUTA AL DIRECTORIO RAÍZ DEL PROYECTO ---\n",
        "# Esta es la carpeta que contiene el directorio 'src'.\n",
        "ruta_proyecto_tensorrt = '/content/SegmentAnything-TensorRT'\n",
        "\n",
        "# --- PASO 2: ASEGURARSE DE QUE LA RUTA ESTÉ EN EL PATH DE PYTHON ---\n",
        "# Este código se asegura de que no añadamos la ruta múltiples veces.\n",
        "if ruta_proyecto_tensorrt not in sys.path:\n",
        "    sys.path.append(ruta_proyecto_tensorrt)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto_tensorrt}\")\n",
        "else:\n",
        "    print(\"La ruta del proyecto ya está en el path.\")\n",
        "\n",
        "# --- PASO 3: IMPORTAR USANDO LA RUTA COMPLETA ---\n",
        "# Ahora que Python conoce la ruta al proyecto, podemos importar desde 'src.infer'.\n",
        "try:\n",
        "    # Como descubrimos, la clase InferenceEngine está dentro del archivo 'infer.py',\n",
        "    # que a su vez está dentro de la carpeta 'src'.\n",
        "    from src.infer import InferenceEngine\n",
        "\n",
        "    print(\"\\n✅ ¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\n❌ Error de importación: {e}\")\n",
        "    print(\"Verifica que el archivo '/content/SegmentAnything-TensorRT/src/infer.py' existe y contiene la clase 'InferenceEngine'.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIc11ISggI0w",
        "outputId": "dce85356-350c-4e48-c11d-fea34004f18e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta del proyecto ya está en el path.\n",
            "\n",
            "✅ ¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import tensorrt as trt\n",
        "# Añade el directorio que CONTIENE al paquete 'segment_anything'\n",
        "sys.path.append(\"/content\")\n",
        "\n",
        "from segment_anything.build_sam import sam_model_registry\n",
        "from segment_anything.predictor import SamPredictor\n",
        "from src.infer import InferenceEngine\n",
        "print(\"¡Importación correcta! Ya puedes usar 'sam_model_registry' y 'SamPredictor'.\")\n",
        "\n",
        "# (Aquí va la celda con las importaciones que ya funcionan)\n",
        "\n",
        "# --- AHORA, LA LÓGICA PARA CREAR EL ENGINE ---\n",
        "\n",
        "# PASO 1: Definir las rutas a los modelos PRIMERO\n",
        "print(\"Definiendo rutas a los modelos...\")\n",
        "pth_path = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h.pth\"\n",
        "trt_model_1 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_first.engine\"\n",
        "trt_model_2 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_second.engine\"\n",
        "print(\"Rutas definidas.\")\n",
        "\n",
        "# PASO 2: Crear el 'engine' PASANDO las rutas como argumentos\n",
        "# El mensaje de error nos dijo exactamente qué argumentos necesitaba.\n",
        "try:\n",
        "    print(\"\\nCreando la instancia de InferenceEngine...\")\n",
        "    engine = InferenceEngine(\n",
        "        pth_path=pth_path,\n",
        "        trt_model_1=trt_model_1,\n",
        "        trt_model_2=trt_model_2  # Añadimos también este, ya que es muy probable que lo necesite\n",
        "    )\n",
        "    print(\"✅ ¡Éxito! Objeto 'engine' creado y listo para usarse.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error al crear el engine: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McsKRxANX_j3",
        "outputId": "5054c679-3308-42e0-b5e3-a65c1130d889"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Importación correcta! Ya puedes usar 'sam_model_registry' y 'SamPredictor'.\n",
            "Definiendo rutas a los modelos...\n",
            "Rutas definidas.\n",
            "\n",
            "Creando la instancia de InferenceEngine...\n",
            "✅ ¡Éxito! Objeto 'engine' creado y listo para usarse.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/SegmentAnything-TensorRT/src/__pycache__\n",
        "print(\"✅ Caché de Python limpiada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1_Is-e2ifof",
        "outputId": "3fc47868-5a10-45bd-b91d-c891c553828e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Caché de Python limpiada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "#  SOLUCIÓN FINAL: INYECCIÓN DE DEPENDENCIA\n",
        "# ===============================================\n",
        "import sys\n",
        "import tensorrt as trt\n",
        "import os\n",
        "\n",
        "print(f\"Versión de TensorRT: {trt.__version__}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- CONFIGURACIÓN DE RUTA ---\n",
        "ruta_proyecto = '/content/SegmentAnything-TensorRT'\n",
        "if ruta_proyecto not in sys.path:\n",
        "    sys.path.append(ruta_proyecto)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto}\")\n",
        "else:\n",
        "    print(\"La ruta del proyecto ya está en el path.\")\n",
        "\n",
        "# --- LÓGICA DEL PROGRAMA ---\n",
        "try:\n",
        "    # 1. Importamos el MÓDULO entero ('infer'), no solo la clase\n",
        "    import src.infer\n",
        "    print(\"✅ Módulo 'src.infer' importado.\")\n",
        "\n",
        "    # 2. \"Inyectamos\" la librería 'trt' en el módulo 'infer'\n",
        "    # Esto asegura que cualquier código dentro de 'infer.py' tenga acceso a 'trt'.\n",
        "    # Es como si le diéramos el martillo directamente en la mano.\n",
        "    src.infer.trt = trt\n",
        "    print(\"✅ Dependencia 'trt' inyectada manualmente en 'src.infer'.\")\n",
        "\n",
        "    # 3. Definimos las rutas a los modelos\n",
        "    pth_path = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h.pth\"\n",
        "    trt_model_1 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_first.engine\"\n",
        "    trt_model_2 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_second.engine\"\n",
        "    print(\"Rutas a los modelos definidas.\")\n",
        "\n",
        "    # 4. Creamos la instancia usando la clase del módulo que hemos modificado\n",
        "    print(\"\\nCreando la instancia de InferenceEngine...\")\n",
        "    engine = src.infer.InferenceEngine(\n",
        "        pth_path=pth_path,\n",
        "        trt_model_1=trt_model_1,\n",
        "        trt_model_2=trt_model_2\n",
        "    )\n",
        "    print(\"\\n✅✅✅ ¡ÉXITO! Objeto 'engine' creado sin errores.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Ocurrió un error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQ4ZDSxh7V4",
        "outputId": "0055dad6-6d7a-45dc-b009-019e879947f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorRT: 10.12.0.36\n",
            "----------------------------------------\n",
            "La ruta del proyecto ya está en el path.\n",
            "✅ Módulo 'src.infer' importado.\n",
            "✅ Dependencia 'trt' inyectada manualmente en 'src.infer'.\n",
            "Rutas a los modelos definidas.\n",
            "\n",
            "Creando la instancia de InferenceEngine...\n",
            "\n",
            "✅✅✅ ¡ÉXITO! Objeto 'engine' creado sin errores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Carga la imagen\n",
        "image_path = \"/content/SegmentAnything-TensorRT/images/original_image.jpg\"\n",
        "if not os.path.exists(image_path):\n",
        "    raise FileNotFoundError(f\"No se encontró la imagen en {image_path}\")\n",
        "\n",
        "image_bgr = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Define el punto y etiqueta para el prompt\n",
        "input_point = np.array([[623, 401]])  # ajusta según el perro\n",
        "\n",
        "input_label = np.array([1])  # 1 para foreground\n",
        "\n",
        "print(f\"Imagen cargada y punto definido en {input_point}.\")\n",
        "\n",
        "# Ejecuta la inferencia con el engine\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "\n",
        "# Visualización con matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image.astype(np.uint8))\n",
        "plt.title(\"Segmentación aplicada\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "xJJrsz92Xz-o",
        "outputId": "4d7244ca-624e-47a0-a32a-f994179dfca8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen cargada y punto definido en [[623 401]].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Carga la imagen\n",
        "image_path = \"/content/SegmentAnything-TensorRT/images/01_missing_hole_01.jpg\"\n",
        "if not os.path.exists(image_path):\n",
        "    raise FileNotFoundError(f\"No se encontró la imagen en {image_path}\")\n",
        "\n",
        "image_bgr = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Define el punto y etiqueta para el prompt\n",
        "input_point = np.array([[1759, 831],\n",
        "                        [2492,1305],\n",
        "                        [2575,1307],\n",
        "                        [2492,1247]\n",
        "\n",
        "\n",
        "                        ])\n",
        "\n",
        "input_label = np.array([1,1,0,0])  # 1 para foreground\n",
        "\n",
        "print(f\"Imagen cargada y punto definido en {input_point}.\")\n",
        "\n",
        "# Ejecuta la inferencia con el engine\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "\n",
        "# Visualización con matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image.astype(np.uint8))\n",
        "plt.title(\"Segmentación aplicada\")\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "kN4D7AKv1tJL",
        "outputId": "f22e74af-012f-4a70-fdb6-94161e29b3e6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen cargada y punto definido en [[1759  831]\n",
            " [2492 1305]\n",
            " [2575 1307]\n",
            " [2492 1247]].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# Liberar caché de GPU antes de medir\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.synchronize()\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# Ejecutar inferencia con TensorRT\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "end_time = time.perf_counter()\n",
        "\n",
        "# Tiempo total de inferencia\n",
        "inference_time = end_time - start_time\n",
        "# Memoria máxima usada en GPU\n",
        "memory_used_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "\n",
        "print(f\"🕒 Tiempo de inferencia: {inference_time:.4f} segundos\")\n",
        "print(f\"💾 Memoria GPU usada: {memory_used_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmXvxHhc4bzc",
        "outputId": "d968f244-9488-4024-ba74-2c192b69e462"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🕒 Tiempo de inferencia: 2.4001 segundos\n",
            "💾 Memoria GPU usada: 5737.77 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    import numpy as np\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])  # Azul con transparencia\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    import numpy as np\n",
        "    pos_points = coords[labels == 1]\n",
        "    neg_points = coords[labels == 0]\n",
        "\n",
        "    if len(pos_points) > 0:\n",
        "        ax.scatter(pos_points[:, 0], pos_points[:, 1],\n",
        "                   color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    if len(neg_points) > 0:\n",
        "        ax.scatter(neg_points[:, 0], neg_points[:, 1],\n",
        "                   color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n"
      ],
      "metadata": {
        "id": "7vB1_09251dM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import pynvml\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# FUNCIONES DE VISUALIZACIÓN\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels == 1]\n",
        "    neg_points = coords[labels == 0]\n",
        "    if len(pos_points) > 0:\n",
        "        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*',\n",
        "                   s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    if len(neg_points) > 0:\n",
        "        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*',\n",
        "                   s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "# BENCHMARK + VISUALIZACIÓN\n",
        "def benchmark_inference(engine, image, point, label, show=True, save_path=None):\n",
        "    torch.cuda.empty_cache()\n",
        "    pynvml.nvmlInit()\n",
        "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "    mem_before = pynvml.nvmlDeviceGetMemoryInfo(handle).used / (1024 ** 2)\n",
        "\n",
        "    start_time = time.time()\n",
        "    masks = engine(image, point, label)\n",
        "    end_time = time.time()\n",
        "\n",
        "    mem_after = pynvml.nvmlDeviceGetMemoryInfo(handle).used / (1024 ** 2)\n",
        "    pynvml.nvmlShutdown()\n",
        "\n",
        "    print(f\"🕒 Tiempo de inferencia: {end_time - start_time:.4f} segundos\")\n",
        "    print(f\"💾 Memoria GPU usada: {mem_after - mem_before:.2f} MB\")\n",
        "\n",
        "    if show:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(image)\n",
        "        show_mask(masks[0], plt.gca())\n",
        "        show_points(point, label, plt.gca())\n",
        "        plt.axis('off')\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, bbox_inches='tight')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "ladLNnNG5YUr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(engine.currentModel.context1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXBDy0VL05RU",
        "outputId": "e0366a1e-9cd2-47eb-9474-a8cd9302c8b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorrt_bindings.tensorrt.IExecutionContext'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SegmentAnything-TensorRT/images/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CLjyuK0jdjf",
        "outputId": "ecc3293f-246a-4ecb-98bd-523d9f9bbe6c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 332\n",
            "-rw-r--r-- 1 root root 99846 Jun 16 10:15 original_image.jpg\n",
            "-rw-r--r-- 1 root root 25039 Jun 16 10:15 vit_b_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 25957 Jun 16 10:15 vit_b_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 24976 Jun 16 10:15 vit_b_Mask_TensorRT.png\n",
            "-rw-r--r-- 1 root root 23657 Jun 16 10:15 vit_h_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 24672 Jun 16 10:15 vit_h_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 23573 Jun 16 10:15 vit_h_Mask_TensorRT.png\n",
            "-rw-r--r-- 1 root root 23551 Jun 16 10:15 vit_l_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 24547 Jun 16 10:15 vit_l_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 23467 Jun 16 10:15 vit_l_Mask_TensorRT.png\n"
          ]
        }
      ]
    }
  ]
}