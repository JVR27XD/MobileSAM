{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1nZTeTU5B3q2sXPPFqqz8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVR27XD/MobileSAM/blob/main/TensorRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_xhz3KVpON5",
        "outputId": "aaad3476-9d45-4620-e514-a3247c1b64a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clonación del repositorio\n",
        "Clona el repositorio SegmentAnything-TensorRT desde GitHub.\n",
        "\n",
        "Cambia el directorio actual de trabajo a la carpeta recién clonada."
      ],
      "metadata": {
        "id": "9uv_OeJRBd9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ItayElam/SegmentAnything-TensorRT.git\n",
        "%cd SegmentAnything-TensorRT\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chi93VTVtV4O",
        "outputId": "9a823383-b3dc-4d50-da2a-9e540c868a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SegmentAnything-TensorRT'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 42 (delta 7), reused 41 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (42/42), 280.67 KiB | 5.73 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/SegmentAnything-TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Montaje de Google Drive y copia del modelo\n",
        "\n",
        "Se sube Google Drive en el entorno de Colab para acceder a archivos personales desde /content/drive.\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "Crea una carpeta llamada checkpoints si no existe. Aquí se guardarán los modelos.\n",
        "\n",
        "!cp ...\n",
        "\n",
        "Copia el modelo preentrenado sam_vit_h_4b8939.pth desde el Google Drive a la carpeta checkpoints, renombrándolo como sam_vit_h.pth"
      ],
      "metadata": {
        "id": "5C96Bw0PBsOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/SAM_TENSOR/sam_vit_h_4b8939.pth\" checkpoints/sam_vit_h.pth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UNzDoPWu3FQ",
        "outputId": "3e194f26-bb63-4e49-f8e0-e523f611625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar dependencias"
      ],
      "metadata": {
        "id": "BlZqUWHgCXpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime onnxruntime-gpu nvidia-pyindex nvidia-tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mERdFY68wNx2",
        "outputId": "11556aa4-64ab-4934-973d-a43e38065873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-10.12.0.36.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Collecting tensorrt_cu12==10.12.0.36 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12-10.12.0.36.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_libs==10.12.0.36 (from tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.12.0.36.tar.gz (709 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.12.0.36 (from tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.12.0.36-cp311-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.12.0.36->tensorrt_cu12==10.12.0.36->tensorrt->nvidia-tensorrt) (12.5.82)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.12.0.36-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex, tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=3c776aaaafc4b997d5ebb9ac2eac578c8603382957539ad2431f291eafe879df\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/d0/7d/b68b3665d16ee20355e65fb7ef48b7ca26533217d9f09924fe\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.12.0.36-py2.py3-none-any.whl size=46638 sha256=45642e4fb1cd24a0289e8d0db0d9c34593b01b6321184562573dc418616bbaea\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/7e/1d/fa229fa908a941f493812047b942b726d18e66f30fe2ac3854\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.12.0.36-py2.py3-none-any.whl size=17480 sha256=34c90fbcefc85ca7d9b49f366eb96ff0bd68d1190542109e480d8da2c00938aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/b2/d6/1629763d3e056546381842f6216f736bf45390fc25cf204091\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.12.0.36-py2.py3-none-manylinux_2_28_x86_64.whl size=3095483544 sha256=3910039e1d49de0edfdc8bf273e40ad4b85a9d57c7c383fe0e22f75417df9610\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/57/d0/c32fb4b4873adbbadcf505f348d120a5b5c3aaab46617e52ac\n",
            "Successfully built nvidia-pyindex tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, nvidia-pyindex, tensorrt_cu12_libs, onnx, humanfriendly, tensorrt_cu12, coloredlogs, tensorrt, onnxruntime-gpu, onnxruntime, nvidia-tensorrt\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-pyindex-1.0.9 nvidia-tensorrt-99.0.0 onnx-1.18.0 onnxruntime-1.22.0 onnxruntime-gpu-1.22.0 tensorrt-10.12.0.36 tensorrt_cu12-10.12.0.36 tensorrt_cu12_bindings-10.12.0.36 tensorrt_cu12_libs-10.12.0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clonar Segment Anything oficial y renombrar\n",
        "\n",
        "\n",
        "%cd /content\n",
        "\n",
        "Asegura que se está en el directorio raíz del entorno de Colab antes de clonar el repositorio.\n",
        "\n",
        "!git clone https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        " Clona el repositorio oficial de Facebook Research que contiene el modelo SAM y sus utilidades.\n",
        "\n",
        "!mv segment-anything segment_anything\n",
        "\n",
        "Renombra la carpeta clonada de segment-anything a segment_anything (usando guion bajo en lugar de guion medio), para evitar posibles conflictos de importación en Python."
      ],
      "metadata": {
        "id": "BgpO2nRVCiOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/segment-anything.git\n",
        "!mv segment-anything segment_anything"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUhEauiBwRGl",
        "outputId": "06f9c615-3a36-40fc-aa4a-6087c193711f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'segment-anything'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 304 (delta 2), reused 1 (delta 1), pack-reused 299 (from 2)\u001b[K\n",
            "Receiving objects: 100% (304/304), 18.31 MiB | 44.64 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar SAM como paquete Python local"
      ],
      "metadata": {
        "id": "GNr7NbQ7DGXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/segment_anything\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC1GqQPHwiRd",
        "outputId": "4ec7ce69-a4e5-4565-cf03-7c345cb710af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/segment_anything\n",
            "Obtaining file:///content/segment_anything\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: segment_anything\n",
            "  Running setup.py develop for segment_anything\n",
            "Successfully installed segment_anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Volver al proyecto principal"
      ],
      "metadata": {
        "id": "B7ACkCWbDLPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/SegmentAnything-TensorRT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuuJZTmlwq0W",
        "outputId": "1158d9e1-72af-406f-b84f-3731474813fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SegmentAnything-TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar PyCUDA"
      ],
      "metadata": {
        "id": "BCpsWIIADPST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSUA9p-xi32",
        "outputId": "5b9e57d6-0b86-4be3-c875-984fad399cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.14.0)\n",
            "Downloading pytools-2025.1.6-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1.1-cp311-cp311-linux_x86_64.whl size=660712 sha256=1c24184f00c2f150b56b6bc67ece7adc5b1cbe54c25e73d31b868e517c986de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/0a/64/6530a5fde64f984ebb4992e38744fdfd2a61f510377b3a24d9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1.1 pytools-2025.1.6 siphash24-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportar a ONNX y TensorRT\n",
        "\n",
        "Ejecuta el script main.py con el subcomando export.\n",
        "\n",
        "Exporta el modelo SAM (sam_vit_h.pth) a:\n",
        "\n",
        "ONNX (Open Neural Network Exchange): un formato intermedio para modelos de deep learning.\n",
        "\n",
        "TensorRT: una versión optimizada del modelo ONNX para ejecución acelerada en GPU de NVIDIA.\n",
        "\n",
        "--model_precision fp16: especifica que la exportación se realice en precisión flotante de 16 bits, lo cual:\n",
        "\n",
        "Reduce el tamaño del modelo.\n",
        "\n",
        "Mejora la velocidad de inferencia.\n",
        "\n",
        "Usa menos memoria GPU."
      ],
      "metadata": {
        "id": "--QvXcIADhLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py export \\\n",
        "  --model_path checkpoints/sam_vit_h.pth \\\n",
        "  --model_precision fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9upl1eWRv1F9",
        "outputId": "d0da02df-fb98-4e68-d6bb-08f17265a61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "  %/blocks.15/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/mlp/act/Div\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.15/mlp/act/Erf\"](%/blocks.15/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/act/Add\"](%/blocks.15/mlp/act/Erf_output_0, %/blocks.15/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.15/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul_1\"](%/blocks.15/mlp/act/Mul_output_0, %/blocks.15/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin2/MatMul\"](%/blocks.15/mlp/act/Mul_1_output_0, %onnx::MatMul_6086), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin2/Add\"](%blocks.15.mlp.lin2.bias, %/blocks.15/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %intermediate_output : Float(*, *, *, *, strides=[5242880, 64, 1, 4096], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add_1\"](%/blocks.15/Add_output_0, %/blocks.15/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTFirstHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  return (%intermediate_output)\n",
            "\n",
            "Exported graph: graph(%intermediate_input : Float(1, 64, 64, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu),\n",
            "      %blocks.0.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.0.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.1.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.2.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.3.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.4.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.5.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.6.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.rel_pos_h : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.rel_pos_w : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.7.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.8.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.9.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.10.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.11.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.12.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.13.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.rel_pos_h : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.rel_pos_w : Float(27, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.14.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm1.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm1.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.rel_pos_h : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.rel_pos_w : Float(127, 80, strides=[80, 1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.qkv.bias : Float(3840, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.attn.proj.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm2.weight : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.norm2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.mlp.lin1.bias : Float(5120, strides=[1], requires_grad=1, device=cpu),\n",
            "      %blocks.15.mlp.lin2.bias : Float(1280, strides=[1], requires_grad=1, device=cpu),\n",
            "      %neck.0.weight : Float(256, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %neck.2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
            "      %onnx::MatMul_5612 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5621 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5634 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5635 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5650 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5659 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5670 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5671 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5686 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5695 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5706 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5707 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5722 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5731 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5742 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5743 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5758 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5767 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5778 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5779 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5794 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5803 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5814 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5815 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5830 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5839 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5850 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5851 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5852 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5861 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5862 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5863 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5878 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5887 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5898 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5899 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5914 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5923 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5934 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5935 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5950 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5959 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5970 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5971 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5986 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_5995 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6006 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6007 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6022 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6031 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6042 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6043 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6058 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6067 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6078 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6079 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6094 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6103 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6114 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6115 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6116 : Float(1280, 3840, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6125 : Float(1280, 1280, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6126 : Float(1280, 5120, strides=[1, 1280], requires_grad=0, device=cpu),\n",
            "      %onnx::MatMul_6127 : Float(5120, 1280, strides=[1, 5120], requires_grad=0, device=cpu),\n",
            "      %onnx::Mul_6129 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Add_6131 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Mul_6133 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Add_6135 : Float(256, 1, 1, strides=[1, 1, 1], requires_grad=0, device=cpu)):\n",
            "  %/blocks.0/norm1/LayerNormalization_output_0 : Float(1, 64, 64, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.0/norm1/LayerNormalization\"](%intermediate_input, %blocks.0.norm1.weight, %blocks.0.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.0/Constant_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod\"](%/blocks.0/Constant_output_0, %/blocks.0/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub\"](%/blocks.0/Constant_2_output_0, %/blocks.0/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_1\"](%/blocks.0/Sub_output_0, %/blocks.0/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.0/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_2\"](%/blocks.0/Constant_4_output_0, %/blocks.0/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub_1\"](%/blocks.0/Constant_6_output_0, %/blocks.0/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.0/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.0/Mod_3\"](%/blocks.0/Sub_1_output_0, %/blocks.0/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.0/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze\"](%/blocks.0/Mod_3_output_0, %onnx::Unsqueeze_261), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_1\"](%/blocks.0/Mod_1_output_0, %onnx::Unsqueeze_265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat\"](%/blocks.0/Constant_8_output_0, %/blocks.0/Constant_9_output_0, %/blocks.0/Constant_10_output_0, %/blocks.0/Unsqueeze_output_0, %/blocks.0/Constant_11_output_0, %/blocks.0/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_2\"](%/blocks.0/Mod_3_output_0, %onnx::Unsqueeze_274), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_3\"](%/blocks.0/Mod_1_output_0, %onnx::Unsqueeze_278), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_1\"](%/blocks.0/Constant_12_output_0, %/blocks.0/Constant_13_output_0, %/blocks.0/Constant_14_output_0, %/blocks.0/Unsqueeze_2_output_0, %/blocks.0/Constant_15_output_0, %/blocks.0/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %onnx::Pad_281 : NoneType = prim::Constant(), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Shape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/Shape\"](%/blocks.0/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Gather_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/Gather\"](%/blocks.0/Shape_output_0, %/blocks.0/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_17_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.0/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/Sub_2\"](%/blocks.0/Constant_17_output_0, %/blocks.0/Gather_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast\"](%/blocks.0/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.0/ConstantOfShape\"](%/blocks.0/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_2\"](%/blocks.0/Cast_output_0, %/blocks.0/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.0/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape\"](%/blocks.0/Concat_2_output_0, %/blocks.0/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.0/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice\"](%/blocks.0/Reshape_output_0, %/blocks.0/Constant_20_output_0, %/blocks.0/Constant_21_output_0, %/blocks.0/Constant_19_output_0, %/blocks.0/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.0/Transpose\"](%/blocks.0/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_1\"](%/blocks.0/Transpose_output_0, %/blocks.0/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_1\"](%/blocks.0/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.0/Pad\"](%/blocks.0/norm1/LayerNormalization_output_0, %/blocks.0/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.0/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add\"](%/blocks.0/Constant_24_output_0, %/blocks.0/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Constant_25_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_1\"](%/blocks.0/Constant_25_output_0, %/blocks.0/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.0/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div\"](%/blocks.0/Add_output_0, %/blocks.0/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_2\"](%/blocks.0/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_3\"](%/blocks.0/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_1\"](%/blocks.0/Add_1_output_0, %/blocks.0/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_4\"](%/blocks.0/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_5\"](%/blocks.0/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_4\"](%/blocks.0/Cast_3_output_0, %onnx::Unsqueeze_318), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_5\"](%/blocks.0/Cast_5_output_0, %onnx::Unsqueeze_322), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1280}, onnx_name=\"/blocks.0/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_3\"](%/blocks.0/Constant_28_output_0, %/blocks.0/Unsqueeze_4_output_0, %/blocks.0/Constant_29_output_0, %/blocks.0/Unsqueeze_5_output_0, %/blocks.0/Constant_30_output_0, %/blocks.0/Constant_31_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.0/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_2\"](%/blocks.0/Pad_output_0, %/blocks.0/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.0/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.0/Transpose_1\"](%/blocks.0/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/Constant_32_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   -1    14    14  1280 [ CPULongType{4} ], onnx_name=\"/blocks.0/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_3\"](%/blocks.0/Transpose_1_output_0, %/blocks.0/Constant_32_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.0/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather\"](%/blocks.0/attn/Shape_output_0, %/blocks.0/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_1\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_1\"](%/blocks.0/attn/Shape_1_output_0, %/blocks.0/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_2\"](%/blocks.0/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_2\"](%/blocks.0/attn/Shape_2_output_0, %/blocks.0/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.0/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/qkv/MatMul\"](%/blocks.0/Reshape_3_output_0, %onnx::MatMul_5612), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/qkv/Add\"](%blocks.0.attn.qkv.bias, %/blocks.0/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul\"](%/blocks.0/attn/Gather_1_output_0, %/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_356 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_356), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_1\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_358), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat\"](%/blocks.0/attn/Unsqueeze_output_0, %/blocks.0/attn/Unsqueeze_1_output_0, %/blocks.0/attn/Constant_3_output_0, %/blocks.0/attn/Constant_4_output_0, %/blocks.0/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape\"](%/blocks.0/attn/qkv/Add_output_0, %/blocks.0/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.0/attn/Transpose\"](%/blocks.0/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.0/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_1\"](%/blocks.0/attn/Gather_output_0, %/blocks.0/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_2\"](%/blocks.0/attn/Mul_1_output_0, %onnx::Unsqueeze_373), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_3\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_375), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_1\"](%/blocks.0/attn/Constant_7_output_0, %/blocks.0/attn/Unsqueeze_2_output_0, %/blocks.0/attn/Unsqueeze_3_output_0, %/blocks.0/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_1\"](%/blocks.0/attn/Transpose_output_0, %/blocks.0/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.0/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.0/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.0/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.0/attn/Split\"](%/blocks.0/attn/Reshape_1_output_0, %/blocks.0/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze\"](%/blocks.0/attn/Split_output_0, %/blocks.0/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze_1\"](%/blocks.0/attn/Split_output_1, %/blocks.0/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.0/attn/Squeeze_2\"](%/blocks.0/attn/Split_output_2, %/blocks.0/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.0/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.0/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_2\"](%/blocks.0/attn/Squeeze_output_0, %/blocks.0/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.0/attn/Transpose_1\"](%/blocks.0/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/MatMul\"](%/blocks.0/attn/Mul_2_output_0, %/blocks.0/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.0/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.0/attn/Range\"](%/blocks.0/attn/Constant_14_output_0, %/blocks.0/attn/Cast_output_0, %/blocks.0/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_4\"](%/blocks.0/attn/Range_output_0, %/blocks.0/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_1\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_2\"](%/blocks.0/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/attn/Div\"](%/blocks.0/attn/Cast_1_output_0, %/blocks.0/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_3\"](%/blocks.0/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_3\"](%/blocks.0/attn/Cast_3_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_5\"](%/blocks.0/attn/Range_output_0, %/blocks.0/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_4\"](%/blocks.0/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_4\"](%/blocks.0/attn/Cast_4_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub\"](%/blocks.0/attn/Mul_3_output_0, %/blocks.0/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_1\"](%/blocks.0/attn/Gather_1_output_0, %/blocks.0/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_5\"](%/blocks.0/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_5\"](%/blocks.0/attn/Cast_5_output_0, %/blocks.0/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add\"](%/blocks.0/attn/Sub_output_0, %/blocks.0/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_6\"](%/blocks.0/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_3\"](%blocks.0.attn.rel_pos_h, %/blocks.0/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_7\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.0/attn/Range_1\"](%/blocks.0/attn/Constant_19_output_0, %/blocks.0/attn/Cast_7_output_0, %/blocks.0/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_6\"](%/blocks.0/attn/Range_1_output_0, %/blocks.0/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_8\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_9\"](%/blocks.0/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/attn/Div_1\"](%/blocks.0/attn/Cast_8_output_0, %/blocks.0/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_10\"](%/blocks.0/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_6\"](%/blocks.0/attn/Cast_10_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.0/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_7\"](%/blocks.0/attn/Range_1_output_0, %/blocks.0/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_11\"](%/blocks.0/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_7\"](%/blocks.0/attn/Cast_11_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.0/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_2\"](%/blocks.0/attn/Mul_6_output_0, %/blocks.0/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.0/attn/Sub_3\"](%/blocks.0/attn/Gather_2_output_0, %/blocks.0/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.0/attn/Cast_12\"](%/blocks.0/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/attn/Mul_8\"](%/blocks.0/attn/Cast_12_output_0, %/blocks.0/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_1\"](%/blocks.0/attn/Sub_2_output_0, %/blocks.0/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.0/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/attn/Cast_13\"](%/blocks.0/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_4\"](%blocks.0.attn.rel_pos_w, %/blocks.0/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.0/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_3\"](%/blocks.0/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_5\"](%/blocks.0/attn/Shape_3_output_0, %/blocks.0/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/attn/Shape_4\"](%/blocks.0/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.0/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/attn/Gather_6\"](%/blocks.0/attn/Shape_4_output_0, %/blocks.0/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_8\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_447), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_449 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_9\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_449), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_10\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_451), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_11\"](%/blocks.0/attn/Gather_6_output_0, %onnx::Unsqueeze_453), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_2\"](%/blocks.0/attn/Unsqueeze_8_output_0, %/blocks.0/attn/Unsqueeze_9_output_0, %/blocks.0/attn/Unsqueeze_10_output_0, %/blocks.0/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.0/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_2\"](%/blocks.0/attn/Squeeze_output_0, %/blocks.0/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.0/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.0/attn/Einsum\"](%/blocks.0/attn/Reshape_2_output_0, %/blocks.0/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.0/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.0/attn/Einsum_1\"](%/blocks.0/attn/Reshape_2_output_0, %/blocks.0/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_12\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_459), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_13\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_461), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_14\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_463), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_15\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_465), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_467 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_16\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_467), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_3\"](%/blocks.0/attn/Unsqueeze_12_output_0, %/blocks.0/attn/Unsqueeze_13_output_0, %/blocks.0/attn/Unsqueeze_14_output_0, %/blocks.0/attn/Unsqueeze_15_output_0, %/blocks.0/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_3\"](%/blocks.0/attn/MatMul_output_0, %/blocks.0/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.0/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_17\"](%/blocks.0/attn/Einsum_output_0, %/blocks.0/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_2\"](%/blocks.0/attn/Reshape_3_output_0, %/blocks.0/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.0/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_18\"](%/blocks.0/attn/Einsum_1_output_0, %/blocks.0/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.0/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/Add_3\"](%/blocks.0/attn/Add_2_output_0, %/blocks.0/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_19\"](%/blocks.0/attn/Gather_5_output_0, %onnx::Unsqueeze_477), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_20\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_479), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_481 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_21\"](%/blocks.0/attn/Mul_output_0, %onnx::Unsqueeze_481), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_4\"](%/blocks.0/attn/Unsqueeze_19_output_0, %/blocks.0/attn/Unsqueeze_20_output_0, %/blocks.0/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.0/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_4\"](%/blocks.0/attn/Add_3_output_0, %/blocks.0/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.0/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.0/attn/Softmax\"](%/blocks.0/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.0/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/MatMul_1\"](%/blocks.0/attn/Softmax_output_0, %/blocks.0/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_22\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_487), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.0/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_23\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_24\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_5\"](%/blocks.0/attn/Unsqueeze_22_output_0, %/blocks.0/attn/Constant_28_output_0, %/blocks.0/attn/Unsqueeze_23_output_0, %/blocks.0/attn/Unsqueeze_24_output_0, %/blocks.0/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_5\"](%/blocks.0/attn/MatMul_1_output_0, %/blocks.0/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.0/attn/Transpose_2\"](%/blocks.0/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_25\"](%/blocks.0/attn/Gather_output_0, %onnx::Unsqueeze_500), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_26\"](%/blocks.0/attn/Gather_1_output_0, %onnx::Unsqueeze_502), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/attn/Unsqueeze_27\"](%/blocks.0/attn/Gather_2_output_0, %onnx::Unsqueeze_504), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.0/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/attn/Concat_6\"](%/blocks.0/attn/Unsqueeze_25_output_0, %/blocks.0/attn/Unsqueeze_26_output_0, %/blocks.0/attn/Unsqueeze_27_output_0, %/blocks.0/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/attn/Reshape_6\"](%/blocks.0/attn/Transpose_2_output_0, %/blocks.0/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.0/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/attn/proj/MatMul\"](%/blocks.0/attn/Reshape_6_output_0, %onnx::MatMul_5621), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/attn/proj/Add\"](%blocks.0.attn.proj.bias, %/blocks.0/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.0/Shape_1\"](%/blocks.0/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.0/Gather_1\"](%/blocks.0/Shape_1_output_0, %/blocks.0/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/Mul\"](%/blocks.0/Add_output_0, %/blocks.0/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.0/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_2\"](%/blocks.0/Mul_output_0, %/blocks.0/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_6\"](%/blocks.0/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_7\"](%/blocks.0/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_3\"](%/blocks.0/Cast_7_output_0, %/blocks.0/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_8\"](%/blocks.0/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_9\"](%/blocks.0/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.0/Div_4\"](%/blocks.0/Gather_1_output_0, %/blocks.0/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_10\"](%/blocks.0/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.0/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.0/Cast_11\"](%/blocks.0/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_6\"](%/blocks.0/Cast_11_output_0, %onnx::Unsqueeze_528), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_7\"](%/blocks.0/Cast_3_output_0, %onnx::Unsqueeze_530), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_8\"](%/blocks.0/Cast_5_output_0, %onnx::Unsqueeze_532), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.0/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_4\"](%/blocks.0/Unsqueeze_6_output_0, %/blocks.0/Unsqueeze_7_output_0, %/blocks.0/Unsqueeze_8_output_0, %/blocks.0/Constant_36_output_0, %/blocks.0/Constant_37_output_0, %/blocks.0/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.0/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_4\"](%/blocks.0/attn/proj/Add_output_0, %/blocks.0/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.0/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.0/Transpose_2\"](%/blocks.0/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_543 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_9\"](%/blocks.0/Cast_11_output_0, %onnx::Unsqueeze_543), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_545 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_10\"](%/blocks.0/Add_output_0, %onnx::Unsqueeze_545), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %onnx::Unsqueeze_547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.0/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.0/Unsqueeze_11\"](%/blocks.0/Add_1_output_0, %onnx::Unsqueeze_547), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.0/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0\n",
            "  %/blocks.0/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.0/Concat_5\"](%/blocks.0/Unsqueeze_9_output_0, %/blocks.0/Unsqueeze_10_output_0, %/blocks.0/Unsqueeze_11_output_0, %/blocks.0/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.0/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.0/Reshape_5\"](%/blocks.0/Transpose_2_output_0, %/blocks.0/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.0/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_42_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice_1\"](%/blocks.0/Reshape_5_output_0, %/blocks.0/Constant_41_output_0, %/blocks.0/Constant_42_output_0, %/blocks.0/Constant_40_output_0, %/blocks.0/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.0/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.0/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={64}, onnx_name=\"/blocks.0/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.0/Slice_2\"](%/blocks.0/Slice_1_output_0, %/blocks.0/Constant_45_output_0, %/blocks.0/Constant_46_output_0, %/blocks.0/Constant_44_output_0, %/blocks.0/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.0/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_2\"](%intermediate_input, %/blocks.0/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.0/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.0/norm2/LayerNormalization\"](%/blocks.0/Add_2_output_0, %blocks.0.norm2.weight, %blocks.0.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.0/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/mlp/lin1/MatMul\"](%/blocks.0/norm2/LayerNormalization_output_0, %onnx::MatMul_5634), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/lin1/Add\"](%blocks.0.mlp.lin1.bias, %/blocks.0/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.0/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.0/mlp/act/Div\"](%/blocks.0/mlp/lin1/Add_output_0, %/blocks.0/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.0/mlp/act/Erf\"](%/blocks.0/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.0/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/act/Add\"](%/blocks.0/mlp/act/Erf_output_0, %/blocks.0/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/mlp/act/Mul\"](%/blocks.0/mlp/lin1/Add_output_0, %/blocks.0/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.0/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.0/mlp/act/Mul_1\"](%/blocks.0/mlp/act/Mul_output_0, %/blocks.0/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.0/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.0/mlp/lin2/MatMul\"](%/blocks.0/mlp/act/Mul_1_output_0, %onnx::MatMul_5635), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/mlp/lin2/Add\"](%blocks.0.mlp.lin2.bias, %/blocks.0/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.0/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.0/Add_3\"](%/blocks.0/Add_2_output_0, %/blocks.0/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.0 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.1/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.1/norm1/LayerNormalization\"](%/blocks.0/Add_3_output_0, %blocks.1.norm1.weight, %blocks.1.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.1/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather\"](%/blocks.1/Shape_output_0, %/blocks.1/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_1\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_1\"](%/blocks.1/Shape_1_output_0, %/blocks.1/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.1/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_2\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_2\"](%/blocks.1/Shape_2_output_0, %/blocks.1/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_3\"](%/blocks.1/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_3\"](%/blocks.1/Shape_3_output_0, %/blocks.1/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.1/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod\"](%/blocks.1/Gather_output_0, %/blocks.1/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub\"](%/blocks.1/Constant_5_output_0, %/blocks.1/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_1\"](%/blocks.1/Sub_output_0, %/blocks.1/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.1/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_2\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub_1\"](%/blocks.1/Constant_8_output_0, %/blocks.1/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.1/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.1/Mod_3\"](%/blocks.1/Sub_1_output_0, %/blocks.1/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.1/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_619 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze\"](%/blocks.1/Mod_3_output_0, %onnx::Unsqueeze_619), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_623 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_1\"](%/blocks.1/Mod_1_output_0, %onnx::Unsqueeze_623), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat\"](%/blocks.1/Constant_10_output_0, %/blocks.1/Constant_11_output_0, %/blocks.1/Constant_12_output_0, %/blocks.1/Unsqueeze_output_0, %/blocks.1/Constant_13_output_0, %/blocks.1/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_2\"](%/blocks.1/Mod_3_output_0, %onnx::Unsqueeze_632), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_636 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_3\"](%/blocks.1/Mod_1_output_0, %onnx::Unsqueeze_636), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_1\"](%/blocks.1/Constant_14_output_0, %/blocks.1/Constant_15_output_0, %/blocks.1/Constant_16_output_0, %/blocks.1/Unsqueeze_2_output_0, %/blocks.1/Constant_17_output_0, %/blocks.1/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_4\"](%/blocks.1/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_4\"](%/blocks.1/Shape_4_output_0, %/blocks.1/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.1/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/Sub_2\"](%/blocks.1/Constant_19_output_0, %/blocks.1/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast\"](%/blocks.1/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.1/ConstantOfShape\"](%/blocks.1/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_2\"](%/blocks.1/Cast_output_0, %/blocks.1/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.1/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape\"](%/blocks.1/Concat_2_output_0, %/blocks.1/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.1/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice\"](%/blocks.1/Reshape_output_0, %/blocks.1/Constant_22_output_0, %/blocks.1/Constant_23_output_0, %/blocks.1/Constant_21_output_0, %/blocks.1/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.1/Transpose\"](%/blocks.1/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_1\"](%/blocks.1/Transpose_output_0, %/blocks.1/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_1\"](%/blocks.1/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.1/Pad\"](%/blocks.1/norm1/LayerNormalization_output_0, %/blocks.1/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.1/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add\"](%/blocks.1/Gather_output_0, %/blocks.1/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.1/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_1\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.1/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div\"](%/blocks.1/Add_output_0, %/blocks.1/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_2\"](%/blocks.1/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_3\"](%/blocks.1/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_1\"](%/blocks.1/Add_1_output_0, %/blocks.1/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_4\"](%/blocks.1/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_5\"](%/blocks.1/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_4\"](%/blocks.1/Gather_2_output_0, %onnx::Unsqueeze_671), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_5\"](%/blocks.1/Cast_3_output_0, %onnx::Unsqueeze_673), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_677 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_6\"](%/blocks.1/Cast_5_output_0, %onnx::Unsqueeze_677), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_681 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_7\"](%/blocks.1/Gather_3_output_0, %onnx::Unsqueeze_681), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_3\"](%/blocks.1/Unsqueeze_4_output_0, %/blocks.1/Unsqueeze_5_output_0, %/blocks.1/Constant_28_output_0, %/blocks.1/Unsqueeze_6_output_0, %/blocks.1/Constant_29_output_0, %/blocks.1/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.1/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_2\"](%/blocks.1/Pad_output_0, %/blocks.1/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.1/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.1/Transpose_1\"](%/blocks.1/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_8\"](%/blocks.1/Gather_3_output_0, %onnx::Unsqueeze_692), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_4\"](%/blocks.1/Constant_30_output_0, %/blocks.1/Constant_31_output_0, %/blocks.1/Constant_32_output_0, %/blocks.1/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_3\"](%/blocks.1/Transpose_1_output_0, %/blocks.1/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.1/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather\"](%/blocks.1/attn/Shape_output_0, %/blocks.1/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_1\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_1\"](%/blocks.1/attn/Shape_1_output_0, %/blocks.1/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_2\"](%/blocks.1/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_2\"](%/blocks.1/attn/Shape_2_output_0, %/blocks.1/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.1/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/qkv/MatMul\"](%/blocks.1/Reshape_3_output_0, %onnx::MatMul_5650), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/qkv/Add\"](%blocks.1.attn.qkv.bias, %/blocks.1/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul\"](%/blocks.1/attn/Gather_1_output_0, %/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_709 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_709), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_1\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_711), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat\"](%/blocks.1/attn/Unsqueeze_output_0, %/blocks.1/attn/Unsqueeze_1_output_0, %/blocks.1/attn/Constant_3_output_0, %/blocks.1/attn/Constant_4_output_0, %/blocks.1/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape\"](%/blocks.1/attn/qkv/Add_output_0, %/blocks.1/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.1/attn/Transpose\"](%/blocks.1/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.1/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_1\"](%/blocks.1/attn/Gather_output_0, %/blocks.1/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_726 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_2\"](%/blocks.1/attn/Mul_1_output_0, %onnx::Unsqueeze_726), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_728 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_3\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_728), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_1\"](%/blocks.1/attn/Constant_7_output_0, %/blocks.1/attn/Unsqueeze_2_output_0, %/blocks.1/attn/Unsqueeze_3_output_0, %/blocks.1/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_1\"](%/blocks.1/attn/Transpose_output_0, %/blocks.1/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.1/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.1/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.1/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.1/attn/Split\"](%/blocks.1/attn/Reshape_1_output_0, %/blocks.1/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze\"](%/blocks.1/attn/Split_output_0, %/blocks.1/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze_1\"](%/blocks.1/attn/Split_output_1, %/blocks.1/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.1/attn/Squeeze_2\"](%/blocks.1/attn/Split_output_2, %/blocks.1/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.1/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.1/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_2\"](%/blocks.1/attn/Squeeze_output_0, %/blocks.1/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.1/attn/Transpose_1\"](%/blocks.1/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/MatMul\"](%/blocks.1/attn/Mul_2_output_0, %/blocks.1/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.1/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.1/attn/Range\"](%/blocks.1/attn/Constant_14_output_0, %/blocks.1/attn/Cast_output_0, %/blocks.1/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_4\"](%/blocks.1/attn/Range_output_0, %/blocks.1/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_1\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_2\"](%/blocks.1/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/attn/Div\"](%/blocks.1/attn/Cast_1_output_0, %/blocks.1/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_3\"](%/blocks.1/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_3\"](%/blocks.1/attn/Cast_3_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_5\"](%/blocks.1/attn/Range_output_0, %/blocks.1/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_4\"](%/blocks.1/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_4\"](%/blocks.1/attn/Cast_4_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub\"](%/blocks.1/attn/Mul_3_output_0, %/blocks.1/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_1\"](%/blocks.1/attn/Gather_1_output_0, %/blocks.1/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_5\"](%/blocks.1/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_5\"](%/blocks.1/attn/Cast_5_output_0, %/blocks.1/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add\"](%/blocks.1/attn/Sub_output_0, %/blocks.1/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_6\"](%/blocks.1/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_3\"](%blocks.1.attn.rel_pos_h, %/blocks.1/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_7\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.1/attn/Range_1\"](%/blocks.1/attn/Constant_19_output_0, %/blocks.1/attn/Cast_7_output_0, %/blocks.1/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_6\"](%/blocks.1/attn/Range_1_output_0, %/blocks.1/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_8\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_9\"](%/blocks.1/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/attn/Div_1\"](%/blocks.1/attn/Cast_8_output_0, %/blocks.1/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_10\"](%/blocks.1/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_6\"](%/blocks.1/attn/Cast_10_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.1/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_7\"](%/blocks.1/attn/Range_1_output_0, %/blocks.1/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_11\"](%/blocks.1/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_7\"](%/blocks.1/attn/Cast_11_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.1/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_2\"](%/blocks.1/attn/Mul_6_output_0, %/blocks.1/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.1/attn/Sub_3\"](%/blocks.1/attn/Gather_2_output_0, %/blocks.1/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.1/attn/Cast_12\"](%/blocks.1/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/attn/Mul_8\"](%/blocks.1/attn/Cast_12_output_0, %/blocks.1/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_1\"](%/blocks.1/attn/Sub_2_output_0, %/blocks.1/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.1/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/attn/Cast_13\"](%/blocks.1/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_4\"](%blocks.1.attn.rel_pos_w, %/blocks.1/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.1/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_3\"](%/blocks.1/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_5\"](%/blocks.1/attn/Shape_3_output_0, %/blocks.1/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/attn/Shape_4\"](%/blocks.1/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.1/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/attn/Gather_6\"](%/blocks.1/attn/Shape_4_output_0, %/blocks.1/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_800 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_8\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_800), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_802 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_9\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_802), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_804 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_10\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_804), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_806 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_11\"](%/blocks.1/attn/Gather_6_output_0, %onnx::Unsqueeze_806), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_2\"](%/blocks.1/attn/Unsqueeze_8_output_0, %/blocks.1/attn/Unsqueeze_9_output_0, %/blocks.1/attn/Unsqueeze_10_output_0, %/blocks.1/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.1/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_2\"](%/blocks.1/attn/Squeeze_output_0, %/blocks.1/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.1/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.1/attn/Einsum\"](%/blocks.1/attn/Reshape_2_output_0, %/blocks.1/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.1/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.1/attn/Einsum_1\"](%/blocks.1/attn/Reshape_2_output_0, %/blocks.1/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_12\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_812), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_13\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_14\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_816), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_15\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_818), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_16\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_820), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_3\"](%/blocks.1/attn/Unsqueeze_12_output_0, %/blocks.1/attn/Unsqueeze_13_output_0, %/blocks.1/attn/Unsqueeze_14_output_0, %/blocks.1/attn/Unsqueeze_15_output_0, %/blocks.1/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_3\"](%/blocks.1/attn/MatMul_output_0, %/blocks.1/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.1/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_17\"](%/blocks.1/attn/Einsum_output_0, %/blocks.1/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_2\"](%/blocks.1/attn/Reshape_3_output_0, %/blocks.1/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.1/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_18\"](%/blocks.1/attn/Einsum_1_output_0, %/blocks.1/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.1/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/Add_3\"](%/blocks.1/attn/Add_2_output_0, %/blocks.1/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_19\"](%/blocks.1/attn/Gather_5_output_0, %onnx::Unsqueeze_830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_20\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_832), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_21\"](%/blocks.1/attn/Mul_output_0, %onnx::Unsqueeze_834), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_4\"](%/blocks.1/attn/Unsqueeze_19_output_0, %/blocks.1/attn/Unsqueeze_20_output_0, %/blocks.1/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.1/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_4\"](%/blocks.1/attn/Add_3_output_0, %/blocks.1/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.1/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.1/attn/Softmax\"](%/blocks.1/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.1/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/MatMul_1\"](%/blocks.1/attn/Softmax_output_0, %/blocks.1/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_840 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_22\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_840), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.1/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_844 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_23\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_844), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_24\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_846), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_5\"](%/blocks.1/attn/Unsqueeze_22_output_0, %/blocks.1/attn/Constant_28_output_0, %/blocks.1/attn/Unsqueeze_23_output_0, %/blocks.1/attn/Unsqueeze_24_output_0, %/blocks.1/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_5\"](%/blocks.1/attn/MatMul_1_output_0, %/blocks.1/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.1/attn/Transpose_2\"](%/blocks.1/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_25\"](%/blocks.1/attn/Gather_output_0, %onnx::Unsqueeze_853), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_26\"](%/blocks.1/attn/Gather_1_output_0, %onnx::Unsqueeze_855), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/attn/Unsqueeze_27\"](%/blocks.1/attn/Gather_2_output_0, %onnx::Unsqueeze_857), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.1/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/attn/Concat_6\"](%/blocks.1/attn/Unsqueeze_25_output_0, %/blocks.1/attn/Unsqueeze_26_output_0, %/blocks.1/attn/Unsqueeze_27_output_0, %/blocks.1/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/attn/Reshape_6\"](%/blocks.1/attn/Transpose_2_output_0, %/blocks.1/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.1/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/attn/proj/MatMul\"](%/blocks.1/attn/Reshape_6_output_0, %onnx::MatMul_5659), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/attn/proj/Add\"](%blocks.1.attn.proj.bias, %/blocks.1/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.1/Shape_5\"](%/blocks.1/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.1/Gather_5\"](%/blocks.1/Shape_5_output_0, %/blocks.1/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/Mul\"](%/blocks.1/Add_output_0, %/blocks.1/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.1/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_2\"](%/blocks.1/Mul_output_0, %/blocks.1/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_6\"](%/blocks.1/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_7\"](%/blocks.1/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_3\"](%/blocks.1/Cast_7_output_0, %/blocks.1/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_8\"](%/blocks.1/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_9\"](%/blocks.1/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.1/Div_4\"](%/blocks.1/Gather_5_output_0, %/blocks.1/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_10\"](%/blocks.1/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.1/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.1/Cast_11\"](%/blocks.1/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_881 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_9\"](%/blocks.1/Cast_11_output_0, %onnx::Unsqueeze_881), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_10\"](%/blocks.1/Cast_3_output_0, %onnx::Unsqueeze_883), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_11\"](%/blocks.1/Cast_5_output_0, %onnx::Unsqueeze_885), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.1/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_5\"](%/blocks.1/Unsqueeze_9_output_0, %/blocks.1/Unsqueeze_10_output_0, %/blocks.1/Unsqueeze_11_output_0, %/blocks.1/Constant_36_output_0, %/blocks.1/Constant_37_output_0, %/blocks.1/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.1/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_4\"](%/blocks.1/attn/proj/Add_output_0, %/blocks.1/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.1/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.1/Transpose_2\"](%/blocks.1/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_12\"](%/blocks.1/Cast_11_output_0, %onnx::Unsqueeze_896), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_13\"](%/blocks.1/Add_output_0, %onnx::Unsqueeze_898), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %onnx::Unsqueeze_900 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.1/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_14\"](%/blocks.1/Add_1_output_0, %onnx::Unsqueeze_900), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.1/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1\n",
            "  %/blocks.1/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.1/Concat_6\"](%/blocks.1/Unsqueeze_12_output_0, %/blocks.1/Unsqueeze_13_output_0, %/blocks.1/Unsqueeze_14_output_0, %/blocks.1/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.1/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.1/Reshape_5\"](%/blocks.1/Transpose_2_output_0, %/blocks.1/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.1/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_15\"](%/blocks.1/Gather_output_0, %/blocks.1/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice_1\"](%/blocks.1/Reshape_5_output_0, %/blocks.1/Constant_41_output_0, %/blocks.1/Unsqueeze_15_output_0, %/blocks.1/Constant_40_output_0, %/blocks.1/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.1/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.1/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.1/Unsqueeze_16\"](%/blocks.1/Gather_1_output_0, %/blocks.1/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.1/Slice_2\"](%/blocks.1/Slice_1_output_0, %/blocks.1/Constant_45_output_0, %/blocks.1/Unsqueeze_16_output_0, %/blocks.1/Constant_44_output_0, %/blocks.1/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.1/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_2\"](%/blocks.0/Add_3_output_0, %/blocks.1/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.1/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.1/norm2/LayerNormalization\"](%/blocks.1/Add_2_output_0, %blocks.1.norm2.weight, %blocks.1.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.1/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/mlp/lin1/MatMul\"](%/blocks.1/norm2/LayerNormalization_output_0, %onnx::MatMul_5670), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/lin1/Add\"](%blocks.1.mlp.lin1.bias, %/blocks.1/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.1/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.1/mlp/act/Div\"](%/blocks.1/mlp/lin1/Add_output_0, %/blocks.1/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.1/mlp/act/Erf\"](%/blocks.1/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.1/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/act/Add\"](%/blocks.1/mlp/act/Erf_output_0, %/blocks.1/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/mlp/act/Mul\"](%/blocks.1/mlp/lin1/Add_output_0, %/blocks.1/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.1/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.1/mlp/act/Mul_1\"](%/blocks.1/mlp/act/Mul_output_0, %/blocks.1/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.1/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.1/mlp/lin2/MatMul\"](%/blocks.1/mlp/act/Mul_1_output_0, %onnx::MatMul_5671), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/mlp/lin2/Add\"](%blocks.1.mlp.lin2.bias, %/blocks.1/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.1/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.1/Add_3\"](%/blocks.1/Add_2_output_0, %/blocks.1/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.1 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.2/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.2/norm1/LayerNormalization\"](%/blocks.1/Add_3_output_0, %blocks.2.norm1.weight, %blocks.2.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.2/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather\"](%/blocks.2/Shape_output_0, %/blocks.2/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_1\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_1\"](%/blocks.2/Shape_1_output_0, %/blocks.2/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.2/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_2\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_2\"](%/blocks.2/Shape_2_output_0, %/blocks.2/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_3\"](%/blocks.2/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_3\"](%/blocks.2/Shape_3_output_0, %/blocks.2/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.2/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod\"](%/blocks.2/Gather_output_0, %/blocks.2/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub\"](%/blocks.2/Constant_5_output_0, %/blocks.2/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_1\"](%/blocks.2/Sub_output_0, %/blocks.2/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.2/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_2\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub_1\"](%/blocks.2/Constant_8_output_0, %/blocks.2/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.2/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.2/Mod_3\"](%/blocks.2/Sub_1_output_0, %/blocks.2/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.2/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze\"](%/blocks.2/Mod_3_output_0, %onnx::Unsqueeze_972), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_1\"](%/blocks.2/Mod_1_output_0, %onnx::Unsqueeze_976), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat\"](%/blocks.2/Constant_10_output_0, %/blocks.2/Constant_11_output_0, %/blocks.2/Constant_12_output_0, %/blocks.2/Unsqueeze_output_0, %/blocks.2/Constant_13_output_0, %/blocks.2/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_2\"](%/blocks.2/Mod_3_output_0, %onnx::Unsqueeze_985), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_989 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_3\"](%/blocks.2/Mod_1_output_0, %onnx::Unsqueeze_989), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_1\"](%/blocks.2/Constant_14_output_0, %/blocks.2/Constant_15_output_0, %/blocks.2/Constant_16_output_0, %/blocks.2/Unsqueeze_2_output_0, %/blocks.2/Constant_17_output_0, %/blocks.2/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_4\"](%/blocks.2/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_4\"](%/blocks.2/Shape_4_output_0, %/blocks.2/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.2/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/Sub_2\"](%/blocks.2/Constant_19_output_0, %/blocks.2/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast\"](%/blocks.2/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.2/ConstantOfShape\"](%/blocks.2/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_2\"](%/blocks.2/Cast_output_0, %/blocks.2/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.2/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape\"](%/blocks.2/Concat_2_output_0, %/blocks.2/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.2/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice\"](%/blocks.2/Reshape_output_0, %/blocks.2/Constant_22_output_0, %/blocks.2/Constant_23_output_0, %/blocks.2/Constant_21_output_0, %/blocks.2/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.2/Transpose\"](%/blocks.2/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_1\"](%/blocks.2/Transpose_output_0, %/blocks.2/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_1\"](%/blocks.2/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.2/Pad\"](%/blocks.2/norm1/LayerNormalization_output_0, %/blocks.2/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.2/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add\"](%/blocks.2/Gather_output_0, %/blocks.2/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.2/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_1\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.2/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div\"](%/blocks.2/Add_output_0, %/blocks.2/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_2\"](%/blocks.2/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_3\"](%/blocks.2/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_1\"](%/blocks.2/Add_1_output_0, %/blocks.2/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_4\"](%/blocks.2/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_5\"](%/blocks.2/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_4\"](%/blocks.2/Gather_2_output_0, %onnx::Unsqueeze_1024), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1026 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_5\"](%/blocks.2/Cast_3_output_0, %onnx::Unsqueeze_1026), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1030 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_6\"](%/blocks.2/Cast_5_output_0, %onnx::Unsqueeze_1030), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1034 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_7\"](%/blocks.2/Gather_3_output_0, %onnx::Unsqueeze_1034), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_3\"](%/blocks.2/Unsqueeze_4_output_0, %/blocks.2/Unsqueeze_5_output_0, %/blocks.2/Constant_28_output_0, %/blocks.2/Unsqueeze_6_output_0, %/blocks.2/Constant_29_output_0, %/blocks.2/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.2/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_2\"](%/blocks.2/Pad_output_0, %/blocks.2/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.2/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.2/Transpose_1\"](%/blocks.2/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1045 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_8\"](%/blocks.2/Gather_3_output_0, %onnx::Unsqueeze_1045), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_4\"](%/blocks.2/Constant_30_output_0, %/blocks.2/Constant_31_output_0, %/blocks.2/Constant_32_output_0, %/blocks.2/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_3\"](%/blocks.2/Transpose_1_output_0, %/blocks.2/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.2/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather\"](%/blocks.2/attn/Shape_output_0, %/blocks.2/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_1\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_1\"](%/blocks.2/attn/Shape_1_output_0, %/blocks.2/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_2\"](%/blocks.2/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_2\"](%/blocks.2/attn/Shape_2_output_0, %/blocks.2/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.2/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/qkv/MatMul\"](%/blocks.2/Reshape_3_output_0, %onnx::MatMul_5686), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/qkv/Add\"](%blocks.2.attn.qkv.bias, %/blocks.2/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul\"](%/blocks.2/attn/Gather_1_output_0, %/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1062 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1062), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1064 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_1\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1064), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat\"](%/blocks.2/attn/Unsqueeze_output_0, %/blocks.2/attn/Unsqueeze_1_output_0, %/blocks.2/attn/Constant_3_output_0, %/blocks.2/attn/Constant_4_output_0, %/blocks.2/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape\"](%/blocks.2/attn/qkv/Add_output_0, %/blocks.2/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.2/attn/Transpose\"](%/blocks.2/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.2/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_1\"](%/blocks.2/attn/Gather_output_0, %/blocks.2/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1079 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_2\"](%/blocks.2/attn/Mul_1_output_0, %onnx::Unsqueeze_1079), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1081 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_3\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1081), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_1\"](%/blocks.2/attn/Constant_7_output_0, %/blocks.2/attn/Unsqueeze_2_output_0, %/blocks.2/attn/Unsqueeze_3_output_0, %/blocks.2/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_1\"](%/blocks.2/attn/Transpose_output_0, %/blocks.2/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.2/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.2/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.2/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.2/attn/Split\"](%/blocks.2/attn/Reshape_1_output_0, %/blocks.2/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze\"](%/blocks.2/attn/Split_output_0, %/blocks.2/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze_1\"](%/blocks.2/attn/Split_output_1, %/blocks.2/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.2/attn/Squeeze_2\"](%/blocks.2/attn/Split_output_2, %/blocks.2/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.2/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.2/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_2\"](%/blocks.2/attn/Squeeze_output_0, %/blocks.2/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.2/attn/Transpose_1\"](%/blocks.2/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/MatMul\"](%/blocks.2/attn/Mul_2_output_0, %/blocks.2/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.2/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.2/attn/Range\"](%/blocks.2/attn/Constant_14_output_0, %/blocks.2/attn/Cast_output_0, %/blocks.2/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_4\"](%/blocks.2/attn/Range_output_0, %/blocks.2/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_1\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_2\"](%/blocks.2/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/attn/Div\"](%/blocks.2/attn/Cast_1_output_0, %/blocks.2/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_3\"](%/blocks.2/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_3\"](%/blocks.2/attn/Cast_3_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_5\"](%/blocks.2/attn/Range_output_0, %/blocks.2/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_4\"](%/blocks.2/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_4\"](%/blocks.2/attn/Cast_4_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub\"](%/blocks.2/attn/Mul_3_output_0, %/blocks.2/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_1\"](%/blocks.2/attn/Gather_1_output_0, %/blocks.2/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_5\"](%/blocks.2/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_5\"](%/blocks.2/attn/Cast_5_output_0, %/blocks.2/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add\"](%/blocks.2/attn/Sub_output_0, %/blocks.2/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_6\"](%/blocks.2/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_3\"](%blocks.2.attn.rel_pos_h, %/blocks.2/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_7\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.2/attn/Range_1\"](%/blocks.2/attn/Constant_19_output_0, %/blocks.2/attn/Cast_7_output_0, %/blocks.2/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_6\"](%/blocks.2/attn/Range_1_output_0, %/blocks.2/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_8\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_9\"](%/blocks.2/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/attn/Div_1\"](%/blocks.2/attn/Cast_8_output_0, %/blocks.2/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_10\"](%/blocks.2/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_6\"](%/blocks.2/attn/Cast_10_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.2/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_7\"](%/blocks.2/attn/Range_1_output_0, %/blocks.2/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_11\"](%/blocks.2/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_7\"](%/blocks.2/attn/Cast_11_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.2/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_2\"](%/blocks.2/attn/Mul_6_output_0, %/blocks.2/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.2/attn/Sub_3\"](%/blocks.2/attn/Gather_2_output_0, %/blocks.2/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.2/attn/Cast_12\"](%/blocks.2/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/attn/Mul_8\"](%/blocks.2/attn/Cast_12_output_0, %/blocks.2/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_1\"](%/blocks.2/attn/Sub_2_output_0, %/blocks.2/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.2/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/attn/Cast_13\"](%/blocks.2/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_4\"](%blocks.2.attn.rel_pos_w, %/blocks.2/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.2/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_3\"](%/blocks.2/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_5\"](%/blocks.2/attn/Shape_3_output_0, %/blocks.2/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/attn/Shape_4\"](%/blocks.2/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.2/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/attn/Gather_6\"](%/blocks.2/attn/Shape_4_output_0, %/blocks.2/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_8\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1153), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_9\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1155), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_10\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1157), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_11\"](%/blocks.2/attn/Gather_6_output_0, %onnx::Unsqueeze_1159), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_2\"](%/blocks.2/attn/Unsqueeze_8_output_0, %/blocks.2/attn/Unsqueeze_9_output_0, %/blocks.2/attn/Unsqueeze_10_output_0, %/blocks.2/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.2/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_2\"](%/blocks.2/attn/Squeeze_output_0, %/blocks.2/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.2/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.2/attn/Einsum\"](%/blocks.2/attn/Reshape_2_output_0, %/blocks.2/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.2/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.2/attn/Einsum_1\"](%/blocks.2/attn/Reshape_2_output_0, %/blocks.2/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_12\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1165), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_13\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1167), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1169 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_14\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1169), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1171 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_15\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1171), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1173 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_16\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1173), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_3\"](%/blocks.2/attn/Unsqueeze_12_output_0, %/blocks.2/attn/Unsqueeze_13_output_0, %/blocks.2/attn/Unsqueeze_14_output_0, %/blocks.2/attn/Unsqueeze_15_output_0, %/blocks.2/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_3\"](%/blocks.2/attn/MatMul_output_0, %/blocks.2/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.2/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_17\"](%/blocks.2/attn/Einsum_output_0, %/blocks.2/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_2\"](%/blocks.2/attn/Reshape_3_output_0, %/blocks.2/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.2/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_18\"](%/blocks.2/attn/Einsum_1_output_0, %/blocks.2/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.2/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/Add_3\"](%/blocks.2/attn/Add_2_output_0, %/blocks.2/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_19\"](%/blocks.2/attn/Gather_5_output_0, %onnx::Unsqueeze_1183), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_20\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1185), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_21\"](%/blocks.2/attn/Mul_output_0, %onnx::Unsqueeze_1187), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_4\"](%/blocks.2/attn/Unsqueeze_19_output_0, %/blocks.2/attn/Unsqueeze_20_output_0, %/blocks.2/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.2/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_4\"](%/blocks.2/attn/Add_3_output_0, %/blocks.2/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.2/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.2/attn/Softmax\"](%/blocks.2/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.2/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/MatMul_1\"](%/blocks.2/attn/Softmax_output_0, %/blocks.2/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_22\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1193), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.2/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_23\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1197), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_24\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1199), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_5\"](%/blocks.2/attn/Unsqueeze_22_output_0, %/blocks.2/attn/Constant_28_output_0, %/blocks.2/attn/Unsqueeze_23_output_0, %/blocks.2/attn/Unsqueeze_24_output_0, %/blocks.2/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_5\"](%/blocks.2/attn/MatMul_1_output_0, %/blocks.2/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.2/attn/Transpose_2\"](%/blocks.2/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_25\"](%/blocks.2/attn/Gather_output_0, %onnx::Unsqueeze_1206), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1208 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_26\"](%/blocks.2/attn/Gather_1_output_0, %onnx::Unsqueeze_1208), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1210 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/attn/Unsqueeze_27\"](%/blocks.2/attn/Gather_2_output_0, %onnx::Unsqueeze_1210), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.2/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/attn/Concat_6\"](%/blocks.2/attn/Unsqueeze_25_output_0, %/blocks.2/attn/Unsqueeze_26_output_0, %/blocks.2/attn/Unsqueeze_27_output_0, %/blocks.2/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/attn/Reshape_6\"](%/blocks.2/attn/Transpose_2_output_0, %/blocks.2/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.2/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/attn/proj/MatMul\"](%/blocks.2/attn/Reshape_6_output_0, %onnx::MatMul_5695), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/attn/proj/Add\"](%blocks.2.attn.proj.bias, %/blocks.2/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.2/Shape_5\"](%/blocks.2/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.2/Gather_5\"](%/blocks.2/Shape_5_output_0, %/blocks.2/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/Mul\"](%/blocks.2/Add_output_0, %/blocks.2/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.2/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_2\"](%/blocks.2/Mul_output_0, %/blocks.2/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_6\"](%/blocks.2/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_7\"](%/blocks.2/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_3\"](%/blocks.2/Cast_7_output_0, %/blocks.2/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_8\"](%/blocks.2/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_9\"](%/blocks.2/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.2/Div_4\"](%/blocks.2/Gather_5_output_0, %/blocks.2/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_10\"](%/blocks.2/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.2/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.2/Cast_11\"](%/blocks.2/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_9\"](%/blocks.2/Cast_11_output_0, %onnx::Unsqueeze_1234), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_10\"](%/blocks.2/Cast_3_output_0, %onnx::Unsqueeze_1236), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_11\"](%/blocks.2/Cast_5_output_0, %onnx::Unsqueeze_1238), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.2/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_5\"](%/blocks.2/Unsqueeze_9_output_0, %/blocks.2/Unsqueeze_10_output_0, %/blocks.2/Unsqueeze_11_output_0, %/blocks.2/Constant_36_output_0, %/blocks.2/Constant_37_output_0, %/blocks.2/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.2/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_4\"](%/blocks.2/attn/proj/Add_output_0, %/blocks.2/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.2/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.2/Transpose_2\"](%/blocks.2/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_12\"](%/blocks.2/Cast_11_output_0, %onnx::Unsqueeze_1249), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_13\"](%/blocks.2/Add_output_0, %onnx::Unsqueeze_1251), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %onnx::Unsqueeze_1253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.2/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_14\"](%/blocks.2/Add_1_output_0, %onnx::Unsqueeze_1253), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.2/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2\n",
            "  %/blocks.2/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.2/Concat_6\"](%/blocks.2/Unsqueeze_12_output_0, %/blocks.2/Unsqueeze_13_output_0, %/blocks.2/Unsqueeze_14_output_0, %/blocks.2/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.2/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.2/Reshape_5\"](%/blocks.2/Transpose_2_output_0, %/blocks.2/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.2/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_15\"](%/blocks.2/Gather_output_0, %/blocks.2/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice_1\"](%/blocks.2/Reshape_5_output_0, %/blocks.2/Constant_41_output_0, %/blocks.2/Unsqueeze_15_output_0, %/blocks.2/Constant_40_output_0, %/blocks.2/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.2/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.2/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.2/Unsqueeze_16\"](%/blocks.2/Gather_1_output_0, %/blocks.2/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.2/Slice_2\"](%/blocks.2/Slice_1_output_0, %/blocks.2/Constant_45_output_0, %/blocks.2/Unsqueeze_16_output_0, %/blocks.2/Constant_44_output_0, %/blocks.2/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.2/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_2\"](%/blocks.1/Add_3_output_0, %/blocks.2/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.2/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.2/norm2/LayerNormalization\"](%/blocks.2/Add_2_output_0, %blocks.2.norm2.weight, %blocks.2.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.2/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/mlp/lin1/MatMul\"](%/blocks.2/norm2/LayerNormalization_output_0, %onnx::MatMul_5706), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/lin1/Add\"](%blocks.2.mlp.lin1.bias, %/blocks.2/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.2/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.2/mlp/act/Div\"](%/blocks.2/mlp/lin1/Add_output_0, %/blocks.2/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.2/mlp/act/Erf\"](%/blocks.2/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.2/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/act/Add\"](%/blocks.2/mlp/act/Erf_output_0, %/blocks.2/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/mlp/act/Mul\"](%/blocks.2/mlp/lin1/Add_output_0, %/blocks.2/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.2/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.2/mlp/act/Mul_1\"](%/blocks.2/mlp/act/Mul_output_0, %/blocks.2/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.2/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.2/mlp/lin2/MatMul\"](%/blocks.2/mlp/act/Mul_1_output_0, %onnx::MatMul_5707), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/mlp/lin2/Add\"](%blocks.2.mlp.lin2.bias, %/blocks.2/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.2/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.2/Add_3\"](%/blocks.2/Add_2_output_0, %/blocks.2/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.2 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.3/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.3/norm1/LayerNormalization\"](%/blocks.2/Add_3_output_0, %blocks.3.norm1.weight, %blocks.3.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.3/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather\"](%/blocks.3/Shape_output_0, %/blocks.3/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_1\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_1\"](%/blocks.3/Shape_1_output_0, %/blocks.3/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.3/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_2\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_2\"](%/blocks.3/Shape_2_output_0, %/blocks.3/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_3\"](%/blocks.3/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_3\"](%/blocks.3/Shape_3_output_0, %/blocks.3/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.3/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod\"](%/blocks.3/Gather_output_0, %/blocks.3/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub\"](%/blocks.3/Constant_5_output_0, %/blocks.3/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_1\"](%/blocks.3/Sub_output_0, %/blocks.3/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.3/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_2\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub_1\"](%/blocks.3/Constant_8_output_0, %/blocks.3/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.3/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.3/Mod_3\"](%/blocks.3/Sub_1_output_0, %/blocks.3/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.3/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1325 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze\"](%/blocks.3/Mod_3_output_0, %onnx::Unsqueeze_1325), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_1\"](%/blocks.3/Mod_1_output_0, %onnx::Unsqueeze_1329), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat\"](%/blocks.3/Constant_10_output_0, %/blocks.3/Constant_11_output_0, %/blocks.3/Constant_12_output_0, %/blocks.3/Unsqueeze_output_0, %/blocks.3/Constant_13_output_0, %/blocks.3/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1338 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_2\"](%/blocks.3/Mod_3_output_0, %onnx::Unsqueeze_1338), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_3\"](%/blocks.3/Mod_1_output_0, %onnx::Unsqueeze_1342), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_1\"](%/blocks.3/Constant_14_output_0, %/blocks.3/Constant_15_output_0, %/blocks.3/Constant_16_output_0, %/blocks.3/Unsqueeze_2_output_0, %/blocks.3/Constant_17_output_0, %/blocks.3/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_4\"](%/blocks.3/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_4\"](%/blocks.3/Shape_4_output_0, %/blocks.3/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.3/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/Sub_2\"](%/blocks.3/Constant_19_output_0, %/blocks.3/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast\"](%/blocks.3/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.3/ConstantOfShape\"](%/blocks.3/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_2\"](%/blocks.3/Cast_output_0, %/blocks.3/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.3/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape\"](%/blocks.3/Concat_2_output_0, %/blocks.3/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.3/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice\"](%/blocks.3/Reshape_output_0, %/blocks.3/Constant_22_output_0, %/blocks.3/Constant_23_output_0, %/blocks.3/Constant_21_output_0, %/blocks.3/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.3/Transpose\"](%/blocks.3/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_1\"](%/blocks.3/Transpose_output_0, %/blocks.3/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_1\"](%/blocks.3/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.3/Pad\"](%/blocks.3/norm1/LayerNormalization_output_0, %/blocks.3/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.3/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add\"](%/blocks.3/Gather_output_0, %/blocks.3/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.3/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_1\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.3/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div\"](%/blocks.3/Add_output_0, %/blocks.3/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_2\"](%/blocks.3/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_3\"](%/blocks.3/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_1\"](%/blocks.3/Add_1_output_0, %/blocks.3/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_4\"](%/blocks.3/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_5\"](%/blocks.3/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1377 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_4\"](%/blocks.3/Gather_2_output_0, %onnx::Unsqueeze_1377), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_5\"](%/blocks.3/Cast_3_output_0, %onnx::Unsqueeze_1379), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1383 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_6\"](%/blocks.3/Cast_5_output_0, %onnx::Unsqueeze_1383), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_7\"](%/blocks.3/Gather_3_output_0, %onnx::Unsqueeze_1387), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_3\"](%/blocks.3/Unsqueeze_4_output_0, %/blocks.3/Unsqueeze_5_output_0, %/blocks.3/Constant_28_output_0, %/blocks.3/Unsqueeze_6_output_0, %/blocks.3/Constant_29_output_0, %/blocks.3/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.3/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_2\"](%/blocks.3/Pad_output_0, %/blocks.3/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.3/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.3/Transpose_1\"](%/blocks.3/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1398 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_8\"](%/blocks.3/Gather_3_output_0, %onnx::Unsqueeze_1398), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_4\"](%/blocks.3/Constant_30_output_0, %/blocks.3/Constant_31_output_0, %/blocks.3/Constant_32_output_0, %/blocks.3/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_3\"](%/blocks.3/Transpose_1_output_0, %/blocks.3/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.3/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather\"](%/blocks.3/attn/Shape_output_0, %/blocks.3/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_1\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_1\"](%/blocks.3/attn/Shape_1_output_0, %/blocks.3/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_2\"](%/blocks.3/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_2\"](%/blocks.3/attn/Shape_2_output_0, %/blocks.3/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.3/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/qkv/MatMul\"](%/blocks.3/Reshape_3_output_0, %onnx::MatMul_5722), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/qkv/Add\"](%blocks.3.attn.qkv.bias, %/blocks.3/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul\"](%/blocks.3/attn/Gather_1_output_0, %/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1415 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1415), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1417 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_1\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1417), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat\"](%/blocks.3/attn/Unsqueeze_output_0, %/blocks.3/attn/Unsqueeze_1_output_0, %/blocks.3/attn/Constant_3_output_0, %/blocks.3/attn/Constant_4_output_0, %/blocks.3/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape\"](%/blocks.3/attn/qkv/Add_output_0, %/blocks.3/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.3/attn/Transpose\"](%/blocks.3/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.3/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_1\"](%/blocks.3/attn/Gather_output_0, %/blocks.3/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1432 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_2\"](%/blocks.3/attn/Mul_1_output_0, %onnx::Unsqueeze_1432), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1434 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_3\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1434), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_1\"](%/blocks.3/attn/Constant_7_output_0, %/blocks.3/attn/Unsqueeze_2_output_0, %/blocks.3/attn/Unsqueeze_3_output_0, %/blocks.3/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_1\"](%/blocks.3/attn/Transpose_output_0, %/blocks.3/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.3/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.3/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.3/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.3/attn/Split\"](%/blocks.3/attn/Reshape_1_output_0, %/blocks.3/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze\"](%/blocks.3/attn/Split_output_0, %/blocks.3/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze_1\"](%/blocks.3/attn/Split_output_1, %/blocks.3/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.3/attn/Squeeze_2\"](%/blocks.3/attn/Split_output_2, %/blocks.3/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.3/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.3/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_2\"](%/blocks.3/attn/Squeeze_output_0, %/blocks.3/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.3/attn/Transpose_1\"](%/blocks.3/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/MatMul\"](%/blocks.3/attn/Mul_2_output_0, %/blocks.3/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.3/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.3/attn/Range\"](%/blocks.3/attn/Constant_14_output_0, %/blocks.3/attn/Cast_output_0, %/blocks.3/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_4\"](%/blocks.3/attn/Range_output_0, %/blocks.3/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_1\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_2\"](%/blocks.3/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/attn/Div\"](%/blocks.3/attn/Cast_1_output_0, %/blocks.3/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_3\"](%/blocks.3/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_3\"](%/blocks.3/attn/Cast_3_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_5\"](%/blocks.3/attn/Range_output_0, %/blocks.3/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_4\"](%/blocks.3/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_4\"](%/blocks.3/attn/Cast_4_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub\"](%/blocks.3/attn/Mul_3_output_0, %/blocks.3/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_1\"](%/blocks.3/attn/Gather_1_output_0, %/blocks.3/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_5\"](%/blocks.3/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_5\"](%/blocks.3/attn/Cast_5_output_0, %/blocks.3/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add\"](%/blocks.3/attn/Sub_output_0, %/blocks.3/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_6\"](%/blocks.3/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_3\"](%blocks.3.attn.rel_pos_h, %/blocks.3/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_7\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.3/attn/Range_1\"](%/blocks.3/attn/Constant_19_output_0, %/blocks.3/attn/Cast_7_output_0, %/blocks.3/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_6\"](%/blocks.3/attn/Range_1_output_0, %/blocks.3/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_8\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_9\"](%/blocks.3/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/attn/Div_1\"](%/blocks.3/attn/Cast_8_output_0, %/blocks.3/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_10\"](%/blocks.3/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_6\"](%/blocks.3/attn/Cast_10_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.3/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_7\"](%/blocks.3/attn/Range_1_output_0, %/blocks.3/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_11\"](%/blocks.3/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_7\"](%/blocks.3/attn/Cast_11_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.3/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_2\"](%/blocks.3/attn/Mul_6_output_0, %/blocks.3/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.3/attn/Sub_3\"](%/blocks.3/attn/Gather_2_output_0, %/blocks.3/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.3/attn/Cast_12\"](%/blocks.3/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/attn/Mul_8\"](%/blocks.3/attn/Cast_12_output_0, %/blocks.3/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_1\"](%/blocks.3/attn/Sub_2_output_0, %/blocks.3/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.3/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/attn/Cast_13\"](%/blocks.3/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_4\"](%blocks.3.attn.rel_pos_w, %/blocks.3/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.3/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_3\"](%/blocks.3/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_5\"](%/blocks.3/attn/Shape_3_output_0, %/blocks.3/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/attn/Shape_4\"](%/blocks.3/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.3/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/attn/Gather_6\"](%/blocks.3/attn/Shape_4_output_0, %/blocks.3/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1506 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_8\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1506), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1508 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_9\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1508), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1510 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_10\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1510), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_11\"](%/blocks.3/attn/Gather_6_output_0, %onnx::Unsqueeze_1512), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_2\"](%/blocks.3/attn/Unsqueeze_8_output_0, %/blocks.3/attn/Unsqueeze_9_output_0, %/blocks.3/attn/Unsqueeze_10_output_0, %/blocks.3/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.3/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_2\"](%/blocks.3/attn/Squeeze_output_0, %/blocks.3/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.3/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.3/attn/Einsum\"](%/blocks.3/attn/Reshape_2_output_0, %/blocks.3/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.3/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.3/attn/Einsum_1\"](%/blocks.3/attn/Reshape_2_output_0, %/blocks.3/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1518 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_12\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1518), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_13\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1520), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_14\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1522), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1524 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_15\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1524), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1526 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_16\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1526), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_3\"](%/blocks.3/attn/Unsqueeze_12_output_0, %/blocks.3/attn/Unsqueeze_13_output_0, %/blocks.3/attn/Unsqueeze_14_output_0, %/blocks.3/attn/Unsqueeze_15_output_0, %/blocks.3/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_3\"](%/blocks.3/attn/MatMul_output_0, %/blocks.3/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.3/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_17\"](%/blocks.3/attn/Einsum_output_0, %/blocks.3/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_2\"](%/blocks.3/attn/Reshape_3_output_0, %/blocks.3/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.3/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_18\"](%/blocks.3/attn/Einsum_1_output_0, %/blocks.3/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.3/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/Add_3\"](%/blocks.3/attn/Add_2_output_0, %/blocks.3/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_19\"](%/blocks.3/attn/Gather_5_output_0, %onnx::Unsqueeze_1536), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_20\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1538), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_21\"](%/blocks.3/attn/Mul_output_0, %onnx::Unsqueeze_1540), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_4\"](%/blocks.3/attn/Unsqueeze_19_output_0, %/blocks.3/attn/Unsqueeze_20_output_0, %/blocks.3/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.3/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_4\"](%/blocks.3/attn/Add_3_output_0, %/blocks.3/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.3/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.3/attn/Softmax\"](%/blocks.3/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.3/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/MatMul_1\"](%/blocks.3/attn/Softmax_output_0, %/blocks.3/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1546 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_22\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1546), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.3/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_23\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1550), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_24\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1552), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_5\"](%/blocks.3/attn/Unsqueeze_22_output_0, %/blocks.3/attn/Constant_28_output_0, %/blocks.3/attn/Unsqueeze_23_output_0, %/blocks.3/attn/Unsqueeze_24_output_0, %/blocks.3/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_5\"](%/blocks.3/attn/MatMul_1_output_0, %/blocks.3/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.3/attn/Transpose_2\"](%/blocks.3/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_25\"](%/blocks.3/attn/Gather_output_0, %onnx::Unsqueeze_1559), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_26\"](%/blocks.3/attn/Gather_1_output_0, %onnx::Unsqueeze_1561), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1563 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/attn/Unsqueeze_27\"](%/blocks.3/attn/Gather_2_output_0, %onnx::Unsqueeze_1563), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.3/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/attn/Concat_6\"](%/blocks.3/attn/Unsqueeze_25_output_0, %/blocks.3/attn/Unsqueeze_26_output_0, %/blocks.3/attn/Unsqueeze_27_output_0, %/blocks.3/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/attn/Reshape_6\"](%/blocks.3/attn/Transpose_2_output_0, %/blocks.3/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.3/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/attn/proj/MatMul\"](%/blocks.3/attn/Reshape_6_output_0, %onnx::MatMul_5731), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/attn/proj/Add\"](%blocks.3.attn.proj.bias, %/blocks.3/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.3/Shape_5\"](%/blocks.3/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.3/Gather_5\"](%/blocks.3/Shape_5_output_0, %/blocks.3/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/Mul\"](%/blocks.3/Add_output_0, %/blocks.3/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.3/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_2\"](%/blocks.3/Mul_output_0, %/blocks.3/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_6\"](%/blocks.3/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_7\"](%/blocks.3/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_3\"](%/blocks.3/Cast_7_output_0, %/blocks.3/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_8\"](%/blocks.3/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_9\"](%/blocks.3/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.3/Div_4\"](%/blocks.3/Gather_5_output_0, %/blocks.3/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_10\"](%/blocks.3/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.3/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.3/Cast_11\"](%/blocks.3/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_9\"](%/blocks.3/Cast_11_output_0, %onnx::Unsqueeze_1587), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_10\"](%/blocks.3/Cast_3_output_0, %onnx::Unsqueeze_1589), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_11\"](%/blocks.3/Cast_5_output_0, %onnx::Unsqueeze_1591), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.3/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_5\"](%/blocks.3/Unsqueeze_9_output_0, %/blocks.3/Unsqueeze_10_output_0, %/blocks.3/Unsqueeze_11_output_0, %/blocks.3/Constant_36_output_0, %/blocks.3/Constant_37_output_0, %/blocks.3/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.3/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_4\"](%/blocks.3/attn/proj/Add_output_0, %/blocks.3/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.3/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.3/Transpose_2\"](%/blocks.3/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_12\"](%/blocks.3/Cast_11_output_0, %onnx::Unsqueeze_1602), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1604 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_13\"](%/blocks.3/Add_output_0, %onnx::Unsqueeze_1604), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %onnx::Unsqueeze_1606 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.3/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_14\"](%/blocks.3/Add_1_output_0, %onnx::Unsqueeze_1606), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.3/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3\n",
            "  %/blocks.3/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.3/Concat_6\"](%/blocks.3/Unsqueeze_12_output_0, %/blocks.3/Unsqueeze_13_output_0, %/blocks.3/Unsqueeze_14_output_0, %/blocks.3/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.3/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.3/Reshape_5\"](%/blocks.3/Transpose_2_output_0, %/blocks.3/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.3/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_15\"](%/blocks.3/Gather_output_0, %/blocks.3/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice_1\"](%/blocks.3/Reshape_5_output_0, %/blocks.3/Constant_41_output_0, %/blocks.3/Unsqueeze_15_output_0, %/blocks.3/Constant_40_output_0, %/blocks.3/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.3/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.3/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.3/Unsqueeze_16\"](%/blocks.3/Gather_1_output_0, %/blocks.3/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.3/Slice_2\"](%/blocks.3/Slice_1_output_0, %/blocks.3/Constant_45_output_0, %/blocks.3/Unsqueeze_16_output_0, %/blocks.3/Constant_44_output_0, %/blocks.3/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.3/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_2\"](%/blocks.2/Add_3_output_0, %/blocks.3/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.3/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.3/norm2/LayerNormalization\"](%/blocks.3/Add_2_output_0, %blocks.3.norm2.weight, %blocks.3.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.3/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/mlp/lin1/MatMul\"](%/blocks.3/norm2/LayerNormalization_output_0, %onnx::MatMul_5742), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/lin1/Add\"](%blocks.3.mlp.lin1.bias, %/blocks.3/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.3/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.3/mlp/act/Div\"](%/blocks.3/mlp/lin1/Add_output_0, %/blocks.3/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.3/mlp/act/Erf\"](%/blocks.3/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.3/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/act/Add\"](%/blocks.3/mlp/act/Erf_output_0, %/blocks.3/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/mlp/act/Mul\"](%/blocks.3/mlp/lin1/Add_output_0, %/blocks.3/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.3/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.3/mlp/act/Mul_1\"](%/blocks.3/mlp/act/Mul_output_0, %/blocks.3/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.3/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.3/mlp/lin2/MatMul\"](%/blocks.3/mlp/act/Mul_1_output_0, %onnx::MatMul_5743), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/mlp/lin2/Add\"](%blocks.3.mlp.lin2.bias, %/blocks.3/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.3/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.3/Add_3\"](%/blocks.3/Add_2_output_0, %/blocks.3/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.3 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.4/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.4/norm1/LayerNormalization\"](%/blocks.3/Add_3_output_0, %blocks.4.norm1.weight, %blocks.4.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.4/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather\"](%/blocks.4/Shape_output_0, %/blocks.4/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_1\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_1\"](%/blocks.4/Shape_1_output_0, %/blocks.4/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.4/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_2\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_2\"](%/blocks.4/Shape_2_output_0, %/blocks.4/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_3\"](%/blocks.4/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_3\"](%/blocks.4/Shape_3_output_0, %/blocks.4/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.4/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod\"](%/blocks.4/Gather_output_0, %/blocks.4/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub\"](%/blocks.4/Constant_5_output_0, %/blocks.4/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_1\"](%/blocks.4/Sub_output_0, %/blocks.4/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.4/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_2\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub_1\"](%/blocks.4/Constant_8_output_0, %/blocks.4/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.4/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.4/Mod_3\"](%/blocks.4/Sub_1_output_0, %/blocks.4/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.4/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze\"](%/blocks.4/Mod_3_output_0, %onnx::Unsqueeze_1678), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_1\"](%/blocks.4/Mod_1_output_0, %onnx::Unsqueeze_1682), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat\"](%/blocks.4/Constant_10_output_0, %/blocks.4/Constant_11_output_0, %/blocks.4/Constant_12_output_0, %/blocks.4/Unsqueeze_output_0, %/blocks.4/Constant_13_output_0, %/blocks.4/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1691 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_2\"](%/blocks.4/Mod_3_output_0, %onnx::Unsqueeze_1691), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1695 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_3\"](%/blocks.4/Mod_1_output_0, %onnx::Unsqueeze_1695), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_1\"](%/blocks.4/Constant_14_output_0, %/blocks.4/Constant_15_output_0, %/blocks.4/Constant_16_output_0, %/blocks.4/Unsqueeze_2_output_0, %/blocks.4/Constant_17_output_0, %/blocks.4/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_4\"](%/blocks.4/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_4\"](%/blocks.4/Shape_4_output_0, %/blocks.4/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.4/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/Sub_2\"](%/blocks.4/Constant_19_output_0, %/blocks.4/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast\"](%/blocks.4/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.4/ConstantOfShape\"](%/blocks.4/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_2\"](%/blocks.4/Cast_output_0, %/blocks.4/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.4/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape\"](%/blocks.4/Concat_2_output_0, %/blocks.4/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.4/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice\"](%/blocks.4/Reshape_output_0, %/blocks.4/Constant_22_output_0, %/blocks.4/Constant_23_output_0, %/blocks.4/Constant_21_output_0, %/blocks.4/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.4/Transpose\"](%/blocks.4/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_1\"](%/blocks.4/Transpose_output_0, %/blocks.4/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_1\"](%/blocks.4/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.4/Pad\"](%/blocks.4/norm1/LayerNormalization_output_0, %/blocks.4/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.4/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add\"](%/blocks.4/Gather_output_0, %/blocks.4/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.4/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_1\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.4/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div\"](%/blocks.4/Add_output_0, %/blocks.4/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_2\"](%/blocks.4/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_3\"](%/blocks.4/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_1\"](%/blocks.4/Add_1_output_0, %/blocks.4/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_4\"](%/blocks.4/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_5\"](%/blocks.4/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1730 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_4\"](%/blocks.4/Gather_2_output_0, %onnx::Unsqueeze_1730), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_5\"](%/blocks.4/Cast_3_output_0, %onnx::Unsqueeze_1732), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1736 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_6\"](%/blocks.4/Cast_5_output_0, %onnx::Unsqueeze_1736), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_7\"](%/blocks.4/Gather_3_output_0, %onnx::Unsqueeze_1740), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_3\"](%/blocks.4/Unsqueeze_4_output_0, %/blocks.4/Unsqueeze_5_output_0, %/blocks.4/Constant_28_output_0, %/blocks.4/Unsqueeze_6_output_0, %/blocks.4/Constant_29_output_0, %/blocks.4/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.4/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_2\"](%/blocks.4/Pad_output_0, %/blocks.4/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.4/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.4/Transpose_1\"](%/blocks.4/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1751 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_8\"](%/blocks.4/Gather_3_output_0, %onnx::Unsqueeze_1751), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_4\"](%/blocks.4/Constant_30_output_0, %/blocks.4/Constant_31_output_0, %/blocks.4/Constant_32_output_0, %/blocks.4/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_3\"](%/blocks.4/Transpose_1_output_0, %/blocks.4/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.4/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather\"](%/blocks.4/attn/Shape_output_0, %/blocks.4/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_1\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_1\"](%/blocks.4/attn/Shape_1_output_0, %/blocks.4/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_2\"](%/blocks.4/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_2\"](%/blocks.4/attn/Shape_2_output_0, %/blocks.4/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.4/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/qkv/MatMul\"](%/blocks.4/Reshape_3_output_0, %onnx::MatMul_5758), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/qkv/Add\"](%blocks.4.attn.qkv.bias, %/blocks.4/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul\"](%/blocks.4/attn/Gather_1_output_0, %/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_1768 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1768), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1770 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_1\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1770), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat\"](%/blocks.4/attn/Unsqueeze_output_0, %/blocks.4/attn/Unsqueeze_1_output_0, %/blocks.4/attn/Constant_3_output_0, %/blocks.4/attn/Constant_4_output_0, %/blocks.4/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape\"](%/blocks.4/attn/qkv/Add_output_0, %/blocks.4/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.4/attn/Transpose\"](%/blocks.4/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.4/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_1\"](%/blocks.4/attn/Gather_output_0, %/blocks.4/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1785 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_2\"](%/blocks.4/attn/Mul_1_output_0, %onnx::Unsqueeze_1785), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_3\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1787), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_1\"](%/blocks.4/attn/Constant_7_output_0, %/blocks.4/attn/Unsqueeze_2_output_0, %/blocks.4/attn/Unsqueeze_3_output_0, %/blocks.4/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_1\"](%/blocks.4/attn/Transpose_output_0, %/blocks.4/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.4/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.4/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.4/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.4/attn/Split\"](%/blocks.4/attn/Reshape_1_output_0, %/blocks.4/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze\"](%/blocks.4/attn/Split_output_0, %/blocks.4/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze_1\"](%/blocks.4/attn/Split_output_1, %/blocks.4/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.4/attn/Squeeze_2\"](%/blocks.4/attn/Split_output_2, %/blocks.4/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.4/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.4/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_2\"](%/blocks.4/attn/Squeeze_output_0, %/blocks.4/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.4/attn/Transpose_1\"](%/blocks.4/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/MatMul\"](%/blocks.4/attn/Mul_2_output_0, %/blocks.4/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.4/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.4/attn/Range\"](%/blocks.4/attn/Constant_14_output_0, %/blocks.4/attn/Cast_output_0, %/blocks.4/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_4\"](%/blocks.4/attn/Range_output_0, %/blocks.4/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_1\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_2\"](%/blocks.4/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/attn/Div\"](%/blocks.4/attn/Cast_1_output_0, %/blocks.4/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_3\"](%/blocks.4/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_3\"](%/blocks.4/attn/Cast_3_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_5\"](%/blocks.4/attn/Range_output_0, %/blocks.4/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_4\"](%/blocks.4/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_4\"](%/blocks.4/attn/Cast_4_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub\"](%/blocks.4/attn/Mul_3_output_0, %/blocks.4/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_1\"](%/blocks.4/attn/Gather_1_output_0, %/blocks.4/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_5\"](%/blocks.4/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_5\"](%/blocks.4/attn/Cast_5_output_0, %/blocks.4/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add\"](%/blocks.4/attn/Sub_output_0, %/blocks.4/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_6\"](%/blocks.4/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_3\"](%blocks.4.attn.rel_pos_h, %/blocks.4/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_7\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.4/attn/Range_1\"](%/blocks.4/attn/Constant_19_output_0, %/blocks.4/attn/Cast_7_output_0, %/blocks.4/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_6\"](%/blocks.4/attn/Range_1_output_0, %/blocks.4/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_8\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_9\"](%/blocks.4/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/attn/Div_1\"](%/blocks.4/attn/Cast_8_output_0, %/blocks.4/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_10\"](%/blocks.4/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_6\"](%/blocks.4/attn/Cast_10_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.4/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_7\"](%/blocks.4/attn/Range_1_output_0, %/blocks.4/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_11\"](%/blocks.4/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_7\"](%/blocks.4/attn/Cast_11_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.4/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_2\"](%/blocks.4/attn/Mul_6_output_0, %/blocks.4/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.4/attn/Sub_3\"](%/blocks.4/attn/Gather_2_output_0, %/blocks.4/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.4/attn/Cast_12\"](%/blocks.4/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/attn/Mul_8\"](%/blocks.4/attn/Cast_12_output_0, %/blocks.4/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_1\"](%/blocks.4/attn/Sub_2_output_0, %/blocks.4/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.4/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/attn/Cast_13\"](%/blocks.4/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_4\"](%blocks.4.attn.rel_pos_w, %/blocks.4/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.4/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_3\"](%/blocks.4/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_5\"](%/blocks.4/attn/Shape_3_output_0, %/blocks.4/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/attn/Shape_4\"](%/blocks.4/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.4/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/attn/Gather_6\"](%/blocks.4/attn/Shape_4_output_0, %/blocks.4/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_1859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_8\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1859), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_9\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1861), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_10\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1863), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_11\"](%/blocks.4/attn/Gather_6_output_0, %onnx::Unsqueeze_1865), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_2\"](%/blocks.4/attn/Unsqueeze_8_output_0, %/blocks.4/attn/Unsqueeze_9_output_0, %/blocks.4/attn/Unsqueeze_10_output_0, %/blocks.4/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.4/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_2\"](%/blocks.4/attn/Squeeze_output_0, %/blocks.4/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.4/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.4/attn/Einsum\"](%/blocks.4/attn/Reshape_2_output_0, %/blocks.4/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.4/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.4/attn/Einsum_1\"](%/blocks.4/attn/Reshape_2_output_0, %/blocks.4/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_1871 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_12\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1871), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1873 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_13\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1873), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_14\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1875), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_15\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1877), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1879 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_16\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1879), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_3\"](%/blocks.4/attn/Unsqueeze_12_output_0, %/blocks.4/attn/Unsqueeze_13_output_0, %/blocks.4/attn/Unsqueeze_14_output_0, %/blocks.4/attn/Unsqueeze_15_output_0, %/blocks.4/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_3\"](%/blocks.4/attn/MatMul_output_0, %/blocks.4/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.4/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_17\"](%/blocks.4/attn/Einsum_output_0, %/blocks.4/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_2\"](%/blocks.4/attn/Reshape_3_output_0, %/blocks.4/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.4/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_18\"](%/blocks.4/attn/Einsum_1_output_0, %/blocks.4/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.4/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/Add_3\"](%/blocks.4/attn/Add_2_output_0, %/blocks.4/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_1889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_19\"](%/blocks.4/attn/Gather_5_output_0, %onnx::Unsqueeze_1889), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_20\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1891), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_21\"](%/blocks.4/attn/Mul_output_0, %onnx::Unsqueeze_1893), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_4\"](%/blocks.4/attn/Unsqueeze_19_output_0, %/blocks.4/attn/Unsqueeze_20_output_0, %/blocks.4/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.4/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_4\"](%/blocks.4/attn/Add_3_output_0, %/blocks.4/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.4/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.4/attn/Softmax\"](%/blocks.4/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.4/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/MatMul_1\"](%/blocks.4/attn/Softmax_output_0, %/blocks.4/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_22\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1899), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.4/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_23\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1903), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_24\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1905), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_5\"](%/blocks.4/attn/Unsqueeze_22_output_0, %/blocks.4/attn/Constant_28_output_0, %/blocks.4/attn/Unsqueeze_23_output_0, %/blocks.4/attn/Unsqueeze_24_output_0, %/blocks.4/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_5\"](%/blocks.4/attn/MatMul_1_output_0, %/blocks.4/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.4/attn/Transpose_2\"](%/blocks.4/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_1912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_25\"](%/blocks.4/attn/Gather_output_0, %onnx::Unsqueeze_1912), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1914 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_26\"](%/blocks.4/attn/Gather_1_output_0, %onnx::Unsqueeze_1914), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_1916 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/attn/Unsqueeze_27\"](%/blocks.4/attn/Gather_2_output_0, %onnx::Unsqueeze_1916), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.4/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/attn/Concat_6\"](%/blocks.4/attn/Unsqueeze_25_output_0, %/blocks.4/attn/Unsqueeze_26_output_0, %/blocks.4/attn/Unsqueeze_27_output_0, %/blocks.4/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/attn/Reshape_6\"](%/blocks.4/attn/Transpose_2_output_0, %/blocks.4/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.4/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/attn/proj/MatMul\"](%/blocks.4/attn/Reshape_6_output_0, %onnx::MatMul_5767), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/attn/proj/Add\"](%blocks.4.attn.proj.bias, %/blocks.4/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.4/Shape_5\"](%/blocks.4/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.4/Gather_5\"](%/blocks.4/Shape_5_output_0, %/blocks.4/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/Mul\"](%/blocks.4/Add_output_0, %/blocks.4/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.4/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_2\"](%/blocks.4/Mul_output_0, %/blocks.4/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_6\"](%/blocks.4/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_7\"](%/blocks.4/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_3\"](%/blocks.4/Cast_7_output_0, %/blocks.4/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_8\"](%/blocks.4/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_9\"](%/blocks.4/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.4/Div_4\"](%/blocks.4/Gather_5_output_0, %/blocks.4/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_10\"](%/blocks.4/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.4/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.4/Cast_11\"](%/blocks.4/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_1940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_9\"](%/blocks.4/Cast_11_output_0, %onnx::Unsqueeze_1940), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_10\"](%/blocks.4/Cast_3_output_0, %onnx::Unsqueeze_1942), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_11\"](%/blocks.4/Cast_5_output_0, %onnx::Unsqueeze_1944), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.4/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_5\"](%/blocks.4/Unsqueeze_9_output_0, %/blocks.4/Unsqueeze_10_output_0, %/blocks.4/Unsqueeze_11_output_0, %/blocks.4/Constant_36_output_0, %/blocks.4/Constant_37_output_0, %/blocks.4/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.4/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_4\"](%/blocks.4/attn/proj/Add_output_0, %/blocks.4/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.4/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.4/Transpose_2\"](%/blocks.4/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_1955 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_12\"](%/blocks.4/Cast_11_output_0, %onnx::Unsqueeze_1955), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1957 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_13\"](%/blocks.4/Add_output_0, %onnx::Unsqueeze_1957), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %onnx::Unsqueeze_1959 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.4/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_14\"](%/blocks.4/Add_1_output_0, %onnx::Unsqueeze_1959), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.4/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4\n",
            "  %/blocks.4/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.4/Concat_6\"](%/blocks.4/Unsqueeze_12_output_0, %/blocks.4/Unsqueeze_13_output_0, %/blocks.4/Unsqueeze_14_output_0, %/blocks.4/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.4/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.4/Reshape_5\"](%/blocks.4/Transpose_2_output_0, %/blocks.4/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.4/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_15\"](%/blocks.4/Gather_output_0, %/blocks.4/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice_1\"](%/blocks.4/Reshape_5_output_0, %/blocks.4/Constant_41_output_0, %/blocks.4/Unsqueeze_15_output_0, %/blocks.4/Constant_40_output_0, %/blocks.4/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.4/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.4/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.4/Unsqueeze_16\"](%/blocks.4/Gather_1_output_0, %/blocks.4/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.4/Slice_2\"](%/blocks.4/Slice_1_output_0, %/blocks.4/Constant_45_output_0, %/blocks.4/Unsqueeze_16_output_0, %/blocks.4/Constant_44_output_0, %/blocks.4/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.4/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_2\"](%/blocks.3/Add_3_output_0, %/blocks.4/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.4/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.4/norm2/LayerNormalization\"](%/blocks.4/Add_2_output_0, %blocks.4.norm2.weight, %blocks.4.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.4/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/mlp/lin1/MatMul\"](%/blocks.4/norm2/LayerNormalization_output_0, %onnx::MatMul_5778), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/lin1/Add\"](%blocks.4.mlp.lin1.bias, %/blocks.4/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.4/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.4/mlp/act/Div\"](%/blocks.4/mlp/lin1/Add_output_0, %/blocks.4/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.4/mlp/act/Erf\"](%/blocks.4/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.4/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/act/Add\"](%/blocks.4/mlp/act/Erf_output_0, %/blocks.4/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/mlp/act/Mul\"](%/blocks.4/mlp/lin1/Add_output_0, %/blocks.4/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.4/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.4/mlp/act/Mul_1\"](%/blocks.4/mlp/act/Mul_output_0, %/blocks.4/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.4/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.4/mlp/lin2/MatMul\"](%/blocks.4/mlp/act/Mul_1_output_0, %onnx::MatMul_5779), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/mlp/lin2/Add\"](%blocks.4.mlp.lin2.bias, %/blocks.4/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.4/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.4/Add_3\"](%/blocks.4/Add_2_output_0, %/blocks.4/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.4 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.5/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.5/norm1/LayerNormalization\"](%/blocks.4/Add_3_output_0, %blocks.5.norm1.weight, %blocks.5.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.5/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather\"](%/blocks.5/Shape_output_0, %/blocks.5/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_1\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_1\"](%/blocks.5/Shape_1_output_0, %/blocks.5/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.5/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_2\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_2\"](%/blocks.5/Shape_2_output_0, %/blocks.5/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_3\"](%/blocks.5/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_3\"](%/blocks.5/Shape_3_output_0, %/blocks.5/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.5/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod\"](%/blocks.5/Gather_output_0, %/blocks.5/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub\"](%/blocks.5/Constant_5_output_0, %/blocks.5/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_1\"](%/blocks.5/Sub_output_0, %/blocks.5/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.5/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_2\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub_1\"](%/blocks.5/Constant_8_output_0, %/blocks.5/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.5/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.5/Mod_3\"](%/blocks.5/Sub_1_output_0, %/blocks.5/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.5/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze\"](%/blocks.5/Mod_3_output_0, %onnx::Unsqueeze_2031), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_1\"](%/blocks.5/Mod_1_output_0, %onnx::Unsqueeze_2035), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat\"](%/blocks.5/Constant_10_output_0, %/blocks.5/Constant_11_output_0, %/blocks.5/Constant_12_output_0, %/blocks.5/Unsqueeze_output_0, %/blocks.5/Constant_13_output_0, %/blocks.5/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2044 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_2\"](%/blocks.5/Mod_3_output_0, %onnx::Unsqueeze_2044), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2048 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_3\"](%/blocks.5/Mod_1_output_0, %onnx::Unsqueeze_2048), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_1\"](%/blocks.5/Constant_14_output_0, %/blocks.5/Constant_15_output_0, %/blocks.5/Constant_16_output_0, %/blocks.5/Unsqueeze_2_output_0, %/blocks.5/Constant_17_output_0, %/blocks.5/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_4\"](%/blocks.5/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_4\"](%/blocks.5/Shape_4_output_0, %/blocks.5/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.5/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/Sub_2\"](%/blocks.5/Constant_19_output_0, %/blocks.5/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast\"](%/blocks.5/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.5/ConstantOfShape\"](%/blocks.5/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_2\"](%/blocks.5/Cast_output_0, %/blocks.5/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.5/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape\"](%/blocks.5/Concat_2_output_0, %/blocks.5/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.5/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice\"](%/blocks.5/Reshape_output_0, %/blocks.5/Constant_22_output_0, %/blocks.5/Constant_23_output_0, %/blocks.5/Constant_21_output_0, %/blocks.5/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.5/Transpose\"](%/blocks.5/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_1\"](%/blocks.5/Transpose_output_0, %/blocks.5/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_1\"](%/blocks.5/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.5/Pad\"](%/blocks.5/norm1/LayerNormalization_output_0, %/blocks.5/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.5/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add\"](%/blocks.5/Gather_output_0, %/blocks.5/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.5/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_1\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.5/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div\"](%/blocks.5/Add_output_0, %/blocks.5/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_2\"](%/blocks.5/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_3\"](%/blocks.5/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_1\"](%/blocks.5/Add_1_output_0, %/blocks.5/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_4\"](%/blocks.5/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_5\"](%/blocks.5/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2083 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_4\"](%/blocks.5/Gather_2_output_0, %onnx::Unsqueeze_2083), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2085 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_5\"](%/blocks.5/Cast_3_output_0, %onnx::Unsqueeze_2085), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2089 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_6\"](%/blocks.5/Cast_5_output_0, %onnx::Unsqueeze_2089), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_7\"](%/blocks.5/Gather_3_output_0, %onnx::Unsqueeze_2093), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_3\"](%/blocks.5/Unsqueeze_4_output_0, %/blocks.5/Unsqueeze_5_output_0, %/blocks.5/Constant_28_output_0, %/blocks.5/Unsqueeze_6_output_0, %/blocks.5/Constant_29_output_0, %/blocks.5/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.5/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_2\"](%/blocks.5/Pad_output_0, %/blocks.5/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.5/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.5/Transpose_1\"](%/blocks.5/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2104 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_8\"](%/blocks.5/Gather_3_output_0, %onnx::Unsqueeze_2104), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_4\"](%/blocks.5/Constant_30_output_0, %/blocks.5/Constant_31_output_0, %/blocks.5/Constant_32_output_0, %/blocks.5/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_3\"](%/blocks.5/Transpose_1_output_0, %/blocks.5/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.5/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather\"](%/blocks.5/attn/Shape_output_0, %/blocks.5/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_1\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_1\"](%/blocks.5/attn/Shape_1_output_0, %/blocks.5/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_2\"](%/blocks.5/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_2\"](%/blocks.5/attn/Shape_2_output_0, %/blocks.5/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.5/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/qkv/MatMul\"](%/blocks.5/Reshape_3_output_0, %onnx::MatMul_5794), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/qkv/Add\"](%blocks.5.attn.qkv.bias, %/blocks.5/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul\"](%/blocks.5/attn/Gather_1_output_0, %/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2121 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2121), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2123 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_1\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2123), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat\"](%/blocks.5/attn/Unsqueeze_output_0, %/blocks.5/attn/Unsqueeze_1_output_0, %/blocks.5/attn/Constant_3_output_0, %/blocks.5/attn/Constant_4_output_0, %/blocks.5/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape\"](%/blocks.5/attn/qkv/Add_output_0, %/blocks.5/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.5/attn/Transpose\"](%/blocks.5/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.5/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_1\"](%/blocks.5/attn/Gather_output_0, %/blocks.5/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_2\"](%/blocks.5/attn/Mul_1_output_0, %onnx::Unsqueeze_2138), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_3\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2140), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_1\"](%/blocks.5/attn/Constant_7_output_0, %/blocks.5/attn/Unsqueeze_2_output_0, %/blocks.5/attn/Unsqueeze_3_output_0, %/blocks.5/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_1\"](%/blocks.5/attn/Transpose_output_0, %/blocks.5/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.5/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.5/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.5/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.5/attn/Split\"](%/blocks.5/attn/Reshape_1_output_0, %/blocks.5/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze\"](%/blocks.5/attn/Split_output_0, %/blocks.5/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze_1\"](%/blocks.5/attn/Split_output_1, %/blocks.5/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.5/attn/Squeeze_2\"](%/blocks.5/attn/Split_output_2, %/blocks.5/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.5/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.5/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_2\"](%/blocks.5/attn/Squeeze_output_0, %/blocks.5/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.5/attn/Transpose_1\"](%/blocks.5/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/MatMul\"](%/blocks.5/attn/Mul_2_output_0, %/blocks.5/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.5/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.5/attn/Range\"](%/blocks.5/attn/Constant_14_output_0, %/blocks.5/attn/Cast_output_0, %/blocks.5/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_4\"](%/blocks.5/attn/Range_output_0, %/blocks.5/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_1\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_2\"](%/blocks.5/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/attn/Div\"](%/blocks.5/attn/Cast_1_output_0, %/blocks.5/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_3\"](%/blocks.5/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_3\"](%/blocks.5/attn/Cast_3_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_5\"](%/blocks.5/attn/Range_output_0, %/blocks.5/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_4\"](%/blocks.5/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_4\"](%/blocks.5/attn/Cast_4_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub\"](%/blocks.5/attn/Mul_3_output_0, %/blocks.5/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_1\"](%/blocks.5/attn/Gather_1_output_0, %/blocks.5/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_5\"](%/blocks.5/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_5\"](%/blocks.5/attn/Cast_5_output_0, %/blocks.5/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add\"](%/blocks.5/attn/Sub_output_0, %/blocks.5/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_6\"](%/blocks.5/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_3\"](%blocks.5.attn.rel_pos_h, %/blocks.5/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_7\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.5/attn/Range_1\"](%/blocks.5/attn/Constant_19_output_0, %/blocks.5/attn/Cast_7_output_0, %/blocks.5/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_6\"](%/blocks.5/attn/Range_1_output_0, %/blocks.5/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_8\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_9\"](%/blocks.5/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/attn/Div_1\"](%/blocks.5/attn/Cast_8_output_0, %/blocks.5/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_10\"](%/blocks.5/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_6\"](%/blocks.5/attn/Cast_10_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.5/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_7\"](%/blocks.5/attn/Range_1_output_0, %/blocks.5/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_11\"](%/blocks.5/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_7\"](%/blocks.5/attn/Cast_11_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.5/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_2\"](%/blocks.5/attn/Mul_6_output_0, %/blocks.5/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.5/attn/Sub_3\"](%/blocks.5/attn/Gather_2_output_0, %/blocks.5/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.5/attn/Cast_12\"](%/blocks.5/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/attn/Mul_8\"](%/blocks.5/attn/Cast_12_output_0, %/blocks.5/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_1\"](%/blocks.5/attn/Sub_2_output_0, %/blocks.5/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.5/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/attn/Cast_13\"](%/blocks.5/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_4\"](%blocks.5.attn.rel_pos_w, %/blocks.5/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.5/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_3\"](%/blocks.5/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_5\"](%/blocks.5/attn/Shape_3_output_0, %/blocks.5/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/attn/Shape_4\"](%/blocks.5/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.5/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/attn/Gather_6\"](%/blocks.5/attn/Shape_4_output_0, %/blocks.5/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2212 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_8\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2212), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2214 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_9\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2214), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2216 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_10\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2216), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_11\"](%/blocks.5/attn/Gather_6_output_0, %onnx::Unsqueeze_2218), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_2\"](%/blocks.5/attn/Unsqueeze_8_output_0, %/blocks.5/attn/Unsqueeze_9_output_0, %/blocks.5/attn/Unsqueeze_10_output_0, %/blocks.5/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.5/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_2\"](%/blocks.5/attn/Squeeze_output_0, %/blocks.5/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.5/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.5/attn/Einsum\"](%/blocks.5/attn/Reshape_2_output_0, %/blocks.5/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.5/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.5/attn/Einsum_1\"](%/blocks.5/attn/Reshape_2_output_0, %/blocks.5/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_12\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2224), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_13\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2226), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_14\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2228), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_15\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2230), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_16\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2232), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_3\"](%/blocks.5/attn/Unsqueeze_12_output_0, %/blocks.5/attn/Unsqueeze_13_output_0, %/blocks.5/attn/Unsqueeze_14_output_0, %/blocks.5/attn/Unsqueeze_15_output_0, %/blocks.5/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_3\"](%/blocks.5/attn/MatMul_output_0, %/blocks.5/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.5/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_17\"](%/blocks.5/attn/Einsum_output_0, %/blocks.5/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_2\"](%/blocks.5/attn/Reshape_3_output_0, %/blocks.5/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.5/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_18\"](%/blocks.5/attn/Einsum_1_output_0, %/blocks.5/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.5/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/Add_3\"](%/blocks.5/attn/Add_2_output_0, %/blocks.5/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_19\"](%/blocks.5/attn/Gather_5_output_0, %onnx::Unsqueeze_2242), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_20\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2244), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2246 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_21\"](%/blocks.5/attn/Mul_output_0, %onnx::Unsqueeze_2246), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_4\"](%/blocks.5/attn/Unsqueeze_19_output_0, %/blocks.5/attn/Unsqueeze_20_output_0, %/blocks.5/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.5/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_4\"](%/blocks.5/attn/Add_3_output_0, %/blocks.5/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.5/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.5/attn/Softmax\"](%/blocks.5/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.5/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/MatMul_1\"](%/blocks.5/attn/Softmax_output_0, %/blocks.5/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_22\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2252), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.5/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_23\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2256), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2258 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_24\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2258), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_5\"](%/blocks.5/attn/Unsqueeze_22_output_0, %/blocks.5/attn/Constant_28_output_0, %/blocks.5/attn/Unsqueeze_23_output_0, %/blocks.5/attn/Unsqueeze_24_output_0, %/blocks.5/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_5\"](%/blocks.5/attn/MatMul_1_output_0, %/blocks.5/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.5/attn/Transpose_2\"](%/blocks.5/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_25\"](%/blocks.5/attn/Gather_output_0, %onnx::Unsqueeze_2265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_26\"](%/blocks.5/attn/Gather_1_output_0, %onnx::Unsqueeze_2267), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2269 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/attn/Unsqueeze_27\"](%/blocks.5/attn/Gather_2_output_0, %onnx::Unsqueeze_2269), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.5/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/attn/Concat_6\"](%/blocks.5/attn/Unsqueeze_25_output_0, %/blocks.5/attn/Unsqueeze_26_output_0, %/blocks.5/attn/Unsqueeze_27_output_0, %/blocks.5/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/attn/Reshape_6\"](%/blocks.5/attn/Transpose_2_output_0, %/blocks.5/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.5/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/attn/proj/MatMul\"](%/blocks.5/attn/Reshape_6_output_0, %onnx::MatMul_5803), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/attn/proj/Add\"](%blocks.5.attn.proj.bias, %/blocks.5/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.5/Shape_5\"](%/blocks.5/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.5/Gather_5\"](%/blocks.5/Shape_5_output_0, %/blocks.5/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/Mul\"](%/blocks.5/Add_output_0, %/blocks.5/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.5/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_2\"](%/blocks.5/Mul_output_0, %/blocks.5/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_6\"](%/blocks.5/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_7\"](%/blocks.5/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_3\"](%/blocks.5/Cast_7_output_0, %/blocks.5/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_8\"](%/blocks.5/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_9\"](%/blocks.5/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.5/Div_4\"](%/blocks.5/Gather_5_output_0, %/blocks.5/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_10\"](%/blocks.5/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.5/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.5/Cast_11\"](%/blocks.5/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_9\"](%/blocks.5/Cast_11_output_0, %onnx::Unsqueeze_2293), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_10\"](%/blocks.5/Cast_3_output_0, %onnx::Unsqueeze_2295), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_11\"](%/blocks.5/Cast_5_output_0, %onnx::Unsqueeze_2297), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.5/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_5\"](%/blocks.5/Unsqueeze_9_output_0, %/blocks.5/Unsqueeze_10_output_0, %/blocks.5/Unsqueeze_11_output_0, %/blocks.5/Constant_36_output_0, %/blocks.5/Constant_37_output_0, %/blocks.5/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.5/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_4\"](%/blocks.5/attn/proj/Add_output_0, %/blocks.5/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.5/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.5/Transpose_2\"](%/blocks.5/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_2308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_12\"](%/blocks.5/Cast_11_output_0, %onnx::Unsqueeze_2308), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2310 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_13\"](%/blocks.5/Add_output_0, %onnx::Unsqueeze_2310), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %onnx::Unsqueeze_2312 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.5/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_14\"](%/blocks.5/Add_1_output_0, %onnx::Unsqueeze_2312), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.5/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5\n",
            "  %/blocks.5/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.5/Concat_6\"](%/blocks.5/Unsqueeze_12_output_0, %/blocks.5/Unsqueeze_13_output_0, %/blocks.5/Unsqueeze_14_output_0, %/blocks.5/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.5/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.5/Reshape_5\"](%/blocks.5/Transpose_2_output_0, %/blocks.5/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.5/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_15\"](%/blocks.5/Gather_output_0, %/blocks.5/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice_1\"](%/blocks.5/Reshape_5_output_0, %/blocks.5/Constant_41_output_0, %/blocks.5/Unsqueeze_15_output_0, %/blocks.5/Constant_40_output_0, %/blocks.5/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.5/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.5/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.5/Unsqueeze_16\"](%/blocks.5/Gather_1_output_0, %/blocks.5/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.5/Slice_2\"](%/blocks.5/Slice_1_output_0, %/blocks.5/Constant_45_output_0, %/blocks.5/Unsqueeze_16_output_0, %/blocks.5/Constant_44_output_0, %/blocks.5/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.5/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_2\"](%/blocks.4/Add_3_output_0, %/blocks.5/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.5/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.5/norm2/LayerNormalization\"](%/blocks.5/Add_2_output_0, %blocks.5.norm2.weight, %blocks.5.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.5/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/mlp/lin1/MatMul\"](%/blocks.5/norm2/LayerNormalization_output_0, %onnx::MatMul_5814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/lin1/Add\"](%blocks.5.mlp.lin1.bias, %/blocks.5/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.5/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.5/mlp/act/Div\"](%/blocks.5/mlp/lin1/Add_output_0, %/blocks.5/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.5/mlp/act/Erf\"](%/blocks.5/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.5/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/act/Add\"](%/blocks.5/mlp/act/Erf_output_0, %/blocks.5/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/mlp/act/Mul\"](%/blocks.5/mlp/lin1/Add_output_0, %/blocks.5/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.5/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.5/mlp/act/Mul_1\"](%/blocks.5/mlp/act/Mul_output_0, %/blocks.5/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.5/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.5/mlp/lin2/MatMul\"](%/blocks.5/mlp/act/Mul_1_output_0, %onnx::MatMul_5815), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/mlp/lin2/Add\"](%blocks.5.mlp.lin2.bias, %/blocks.5/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.5/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.5/Add_3\"](%/blocks.5/Add_2_output_0, %/blocks.5/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.5 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.6/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.6/norm1/LayerNormalization\"](%/blocks.5/Add_3_output_0, %blocks.6.norm1.weight, %blocks.6.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.6/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather\"](%/blocks.6/Shape_output_0, %/blocks.6/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_1\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_1\"](%/blocks.6/Shape_1_output_0, %/blocks.6/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.6/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_2\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_2\"](%/blocks.6/Shape_2_output_0, %/blocks.6/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_3\"](%/blocks.6/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_3\"](%/blocks.6/Shape_3_output_0, %/blocks.6/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.6/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod\"](%/blocks.6/Gather_output_0, %/blocks.6/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub\"](%/blocks.6/Constant_5_output_0, %/blocks.6/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_1\"](%/blocks.6/Sub_output_0, %/blocks.6/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.6/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_2\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub_1\"](%/blocks.6/Constant_8_output_0, %/blocks.6/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.6/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.6/Mod_3\"](%/blocks.6/Sub_1_output_0, %/blocks.6/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.6/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze\"](%/blocks.6/Mod_3_output_0, %onnx::Unsqueeze_2384), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_1\"](%/blocks.6/Mod_1_output_0, %onnx::Unsqueeze_2388), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat\"](%/blocks.6/Constant_10_output_0, %/blocks.6/Constant_11_output_0, %/blocks.6/Constant_12_output_0, %/blocks.6/Unsqueeze_output_0, %/blocks.6/Constant_13_output_0, %/blocks.6/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2397 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_2\"](%/blocks.6/Mod_3_output_0, %onnx::Unsqueeze_2397), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2401 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_3\"](%/blocks.6/Mod_1_output_0, %onnx::Unsqueeze_2401), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_1\"](%/blocks.6/Constant_14_output_0, %/blocks.6/Constant_15_output_0, %/blocks.6/Constant_16_output_0, %/blocks.6/Unsqueeze_2_output_0, %/blocks.6/Constant_17_output_0, %/blocks.6/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_4\"](%/blocks.6/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_4\"](%/blocks.6/Shape_4_output_0, %/blocks.6/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.6/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/Sub_2\"](%/blocks.6/Constant_19_output_0, %/blocks.6/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast\"](%/blocks.6/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.6/ConstantOfShape\"](%/blocks.6/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_2\"](%/blocks.6/Cast_output_0, %/blocks.6/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.6/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape\"](%/blocks.6/Concat_2_output_0, %/blocks.6/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.6/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice\"](%/blocks.6/Reshape_output_0, %/blocks.6/Constant_22_output_0, %/blocks.6/Constant_23_output_0, %/blocks.6/Constant_21_output_0, %/blocks.6/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.6/Transpose\"](%/blocks.6/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_1\"](%/blocks.6/Transpose_output_0, %/blocks.6/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_1\"](%/blocks.6/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.6/Pad\"](%/blocks.6/norm1/LayerNormalization_output_0, %/blocks.6/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.6/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add\"](%/blocks.6/Gather_output_0, %/blocks.6/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.6/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_1\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.6/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div\"](%/blocks.6/Add_output_0, %/blocks.6/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_2\"](%/blocks.6/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_3\"](%/blocks.6/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_1\"](%/blocks.6/Add_1_output_0, %/blocks.6/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_4\"](%/blocks.6/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_5\"](%/blocks.6/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2436 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_4\"](%/blocks.6/Gather_2_output_0, %onnx::Unsqueeze_2436), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2438 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_5\"](%/blocks.6/Cast_3_output_0, %onnx::Unsqueeze_2438), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2442 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_6\"](%/blocks.6/Cast_5_output_0, %onnx::Unsqueeze_2442), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_7\"](%/blocks.6/Gather_3_output_0, %onnx::Unsqueeze_2446), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_3\"](%/blocks.6/Unsqueeze_4_output_0, %/blocks.6/Unsqueeze_5_output_0, %/blocks.6/Constant_28_output_0, %/blocks.6/Unsqueeze_6_output_0, %/blocks.6/Constant_29_output_0, %/blocks.6/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.6/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_2\"](%/blocks.6/Pad_output_0, %/blocks.6/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.6/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.6/Transpose_1\"](%/blocks.6/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_8\"](%/blocks.6/Gather_3_output_0, %onnx::Unsqueeze_2457), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_4\"](%/blocks.6/Constant_30_output_0, %/blocks.6/Constant_31_output_0, %/blocks.6/Constant_32_output_0, %/blocks.6/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_3\"](%/blocks.6/Transpose_1_output_0, %/blocks.6/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.6/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather\"](%/blocks.6/attn/Shape_output_0, %/blocks.6/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_1\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_1\"](%/blocks.6/attn/Shape_1_output_0, %/blocks.6/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_2\"](%/blocks.6/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_2\"](%/blocks.6/attn/Shape_2_output_0, %/blocks.6/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.6/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/qkv/MatMul\"](%/blocks.6/Reshape_3_output_0, %onnx::MatMul_5830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/qkv/Add\"](%blocks.6.attn.qkv.bias, %/blocks.6/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul\"](%/blocks.6/attn/Gather_1_output_0, %/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2474 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2474), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_1\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2476), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat\"](%/blocks.6/attn/Unsqueeze_output_0, %/blocks.6/attn/Unsqueeze_1_output_0, %/blocks.6/attn/Constant_3_output_0, %/blocks.6/attn/Constant_4_output_0, %/blocks.6/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape\"](%/blocks.6/attn/qkv/Add_output_0, %/blocks.6/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.6/attn/Transpose\"](%/blocks.6/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.6/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_1\"](%/blocks.6/attn/Gather_output_0, %/blocks.6/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_2\"](%/blocks.6/attn/Mul_1_output_0, %onnx::Unsqueeze_2491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_3\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_1\"](%/blocks.6/attn/Constant_7_output_0, %/blocks.6/attn/Unsqueeze_2_output_0, %/blocks.6/attn/Unsqueeze_3_output_0, %/blocks.6/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_1\"](%/blocks.6/attn/Transpose_output_0, %/blocks.6/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.6/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.6/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.6/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.6/attn/Split\"](%/blocks.6/attn/Reshape_1_output_0, %/blocks.6/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze\"](%/blocks.6/attn/Split_output_0, %/blocks.6/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze_1\"](%/blocks.6/attn/Split_output_1, %/blocks.6/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.6/attn/Squeeze_2\"](%/blocks.6/attn/Split_output_2, %/blocks.6/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.6/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.6/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_2\"](%/blocks.6/attn/Squeeze_output_0, %/blocks.6/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.6/attn/Transpose_1\"](%/blocks.6/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/MatMul\"](%/blocks.6/attn/Mul_2_output_0, %/blocks.6/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.6/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.6/attn/Range\"](%/blocks.6/attn/Constant_14_output_0, %/blocks.6/attn/Cast_output_0, %/blocks.6/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_4\"](%/blocks.6/attn/Range_output_0, %/blocks.6/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_1\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_2\"](%/blocks.6/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/attn/Div\"](%/blocks.6/attn/Cast_1_output_0, %/blocks.6/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_3\"](%/blocks.6/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_3\"](%/blocks.6/attn/Cast_3_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_5\"](%/blocks.6/attn/Range_output_0, %/blocks.6/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_4\"](%/blocks.6/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_4\"](%/blocks.6/attn/Cast_4_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub\"](%/blocks.6/attn/Mul_3_output_0, %/blocks.6/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_1\"](%/blocks.6/attn/Gather_1_output_0, %/blocks.6/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_5\"](%/blocks.6/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_5\"](%/blocks.6/attn/Cast_5_output_0, %/blocks.6/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add\"](%/blocks.6/attn/Sub_output_0, %/blocks.6/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_6\"](%/blocks.6/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_3\"](%blocks.6.attn.rel_pos_h, %/blocks.6/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_7\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.6/attn/Range_1\"](%/blocks.6/attn/Constant_19_output_0, %/blocks.6/attn/Cast_7_output_0, %/blocks.6/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_6\"](%/blocks.6/attn/Range_1_output_0, %/blocks.6/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_8\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_9\"](%/blocks.6/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/attn/Div_1\"](%/blocks.6/attn/Cast_8_output_0, %/blocks.6/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_10\"](%/blocks.6/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_6\"](%/blocks.6/attn/Cast_10_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.6/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_7\"](%/blocks.6/attn/Range_1_output_0, %/blocks.6/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_11\"](%/blocks.6/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_7\"](%/blocks.6/attn/Cast_11_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.6/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_2\"](%/blocks.6/attn/Mul_6_output_0, %/blocks.6/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.6/attn/Sub_3\"](%/blocks.6/attn/Gather_2_output_0, %/blocks.6/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.6/attn/Cast_12\"](%/blocks.6/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/attn/Mul_8\"](%/blocks.6/attn/Cast_12_output_0, %/blocks.6/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_1\"](%/blocks.6/attn/Sub_2_output_0, %/blocks.6/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.6/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/attn/Cast_13\"](%/blocks.6/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_4\"](%blocks.6.attn.rel_pos_w, %/blocks.6/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.6/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_3\"](%/blocks.6/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_5\"](%/blocks.6/attn/Shape_3_output_0, %/blocks.6/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/attn/Shape_4\"](%/blocks.6/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.6/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/attn/Gather_6\"](%/blocks.6/attn/Shape_4_output_0, %/blocks.6/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2565 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_8\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2565), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2567 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_9\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2567), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2569 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_10\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2569), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_11\"](%/blocks.6/attn/Gather_6_output_0, %onnx::Unsqueeze_2571), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_2\"](%/blocks.6/attn/Unsqueeze_8_output_0, %/blocks.6/attn/Unsqueeze_9_output_0, %/blocks.6/attn/Unsqueeze_10_output_0, %/blocks.6/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.6/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_2\"](%/blocks.6/attn/Squeeze_output_0, %/blocks.6/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.6/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.6/attn/Einsum\"](%/blocks.6/attn/Reshape_2_output_0, %/blocks.6/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.6/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.6/attn/Einsum_1\"](%/blocks.6/attn/Reshape_2_output_0, %/blocks.6/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_12\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2577), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_13\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2579), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2581 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_14\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2581), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_15\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2583), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_16\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2585), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_3\"](%/blocks.6/attn/Unsqueeze_12_output_0, %/blocks.6/attn/Unsqueeze_13_output_0, %/blocks.6/attn/Unsqueeze_14_output_0, %/blocks.6/attn/Unsqueeze_15_output_0, %/blocks.6/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_3\"](%/blocks.6/attn/MatMul_output_0, %/blocks.6/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.6/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_17\"](%/blocks.6/attn/Einsum_output_0, %/blocks.6/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_2\"](%/blocks.6/attn/Reshape_3_output_0, %/blocks.6/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.6/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_18\"](%/blocks.6/attn/Einsum_1_output_0, %/blocks.6/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.6/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/Add_3\"](%/blocks.6/attn/Add_2_output_0, %/blocks.6/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_19\"](%/blocks.6/attn/Gather_5_output_0, %onnx::Unsqueeze_2595), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_20\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2597), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_21\"](%/blocks.6/attn/Mul_output_0, %onnx::Unsqueeze_2599), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_4\"](%/blocks.6/attn/Unsqueeze_19_output_0, %/blocks.6/attn/Unsqueeze_20_output_0, %/blocks.6/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.6/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_4\"](%/blocks.6/attn/Add_3_output_0, %/blocks.6/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.6/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.6/attn/Softmax\"](%/blocks.6/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.6/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/MatMul_1\"](%/blocks.6/attn/Softmax_output_0, %/blocks.6/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2605 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_22\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2605), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.6/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2609 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_23\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2609), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2611 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_24\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2611), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_5\"](%/blocks.6/attn/Unsqueeze_22_output_0, %/blocks.6/attn/Constant_28_output_0, %/blocks.6/attn/Unsqueeze_23_output_0, %/blocks.6/attn/Unsqueeze_24_output_0, %/blocks.6/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_5\"](%/blocks.6/attn/MatMul_1_output_0, %/blocks.6/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.6/attn/Transpose_2\"](%/blocks.6/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_25\"](%/blocks.6/attn/Gather_output_0, %onnx::Unsqueeze_2618), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2620 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_26\"](%/blocks.6/attn/Gather_1_output_0, %onnx::Unsqueeze_2620), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2622 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/attn/Unsqueeze_27\"](%/blocks.6/attn/Gather_2_output_0, %onnx::Unsqueeze_2622), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.6/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/attn/Concat_6\"](%/blocks.6/attn/Unsqueeze_25_output_0, %/blocks.6/attn/Unsqueeze_26_output_0, %/blocks.6/attn/Unsqueeze_27_output_0, %/blocks.6/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/attn/Reshape_6\"](%/blocks.6/attn/Transpose_2_output_0, %/blocks.6/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.6/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/attn/proj/MatMul\"](%/blocks.6/attn/Reshape_6_output_0, %onnx::MatMul_5839), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/attn/proj/Add\"](%blocks.6.attn.proj.bias, %/blocks.6/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.6/Shape_5\"](%/blocks.6/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.6/Gather_5\"](%/blocks.6/Shape_5_output_0, %/blocks.6/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/Mul\"](%/blocks.6/Add_output_0, %/blocks.6/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.6/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_2\"](%/blocks.6/Mul_output_0, %/blocks.6/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_6\"](%/blocks.6/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_7\"](%/blocks.6/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_3\"](%/blocks.6/Cast_7_output_0, %/blocks.6/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_8\"](%/blocks.6/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_9\"](%/blocks.6/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.6/Div_4\"](%/blocks.6/Gather_5_output_0, %/blocks.6/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_10\"](%/blocks.6/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.6/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.6/Cast_11\"](%/blocks.6/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_9\"](%/blocks.6/Cast_11_output_0, %onnx::Unsqueeze_2646), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_10\"](%/blocks.6/Cast_3_output_0, %onnx::Unsqueeze_2648), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2650 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_11\"](%/blocks.6/Cast_5_output_0, %onnx::Unsqueeze_2650), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.6/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_5\"](%/blocks.6/Unsqueeze_9_output_0, %/blocks.6/Unsqueeze_10_output_0, %/blocks.6/Unsqueeze_11_output_0, %/blocks.6/Constant_36_output_0, %/blocks.6/Constant_37_output_0, %/blocks.6/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.6/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_4\"](%/blocks.6/attn/proj/Add_output_0, %/blocks.6/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.6/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.6/Transpose_2\"](%/blocks.6/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_2661 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_12\"](%/blocks.6/Cast_11_output_0, %onnx::Unsqueeze_2661), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2663 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_13\"](%/blocks.6/Add_output_0, %onnx::Unsqueeze_2663), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %onnx::Unsqueeze_2665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.6/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_14\"](%/blocks.6/Add_1_output_0, %onnx::Unsqueeze_2665), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.6/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6\n",
            "  %/blocks.6/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.6/Concat_6\"](%/blocks.6/Unsqueeze_12_output_0, %/blocks.6/Unsqueeze_13_output_0, %/blocks.6/Unsqueeze_14_output_0, %/blocks.6/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.6/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.6/Reshape_5\"](%/blocks.6/Transpose_2_output_0, %/blocks.6/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.6/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_15\"](%/blocks.6/Gather_output_0, %/blocks.6/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice_1\"](%/blocks.6/Reshape_5_output_0, %/blocks.6/Constant_41_output_0, %/blocks.6/Unsqueeze_15_output_0, %/blocks.6/Constant_40_output_0, %/blocks.6/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.6/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.6/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.6/Unsqueeze_16\"](%/blocks.6/Gather_1_output_0, %/blocks.6/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.6/Slice_2\"](%/blocks.6/Slice_1_output_0, %/blocks.6/Constant_45_output_0, %/blocks.6/Unsqueeze_16_output_0, %/blocks.6/Constant_44_output_0, %/blocks.6/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.6/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_2\"](%/blocks.5/Add_3_output_0, %/blocks.6/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.6/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.6/norm2/LayerNormalization\"](%/blocks.6/Add_2_output_0, %blocks.6.norm2.weight, %blocks.6.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.6/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/mlp/lin1/MatMul\"](%/blocks.6/norm2/LayerNormalization_output_0, %onnx::MatMul_5850), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/lin1/Add\"](%blocks.6.mlp.lin1.bias, %/blocks.6/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.6/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.6/mlp/act/Div\"](%/blocks.6/mlp/lin1/Add_output_0, %/blocks.6/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.6/mlp/act/Erf\"](%/blocks.6/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.6/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/act/Add\"](%/blocks.6/mlp/act/Erf_output_0, %/blocks.6/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/mlp/act/Mul\"](%/blocks.6/mlp/lin1/Add_output_0, %/blocks.6/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.6/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.6/mlp/act/Mul_1\"](%/blocks.6/mlp/act/Mul_output_0, %/blocks.6/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.6/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.6/mlp/lin2/MatMul\"](%/blocks.6/mlp/act/Mul_1_output_0, %onnx::MatMul_5851), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/mlp/lin2/Add\"](%blocks.6.mlp.lin2.bias, %/blocks.6/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.6/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.6/Add_3\"](%/blocks.6/Add_2_output_0, %/blocks.6/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.6 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.7/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.7/norm1/LayerNormalization\"](%/blocks.6/Add_3_output_0, %blocks.7.norm1.weight, %blocks.7.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.7/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather\"](%/blocks.7/attn/Shape_output_0, %/blocks.7/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_1\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_1\"](%/blocks.7/attn/Shape_1_output_0, %/blocks.7/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_2\"](%/blocks.7/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.7/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_2\"](%/blocks.7/attn/Shape_2_output_0, %/blocks.7/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.7/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/qkv/MatMul\"](%/blocks.7/norm1/LayerNormalization_output_0, %onnx::MatMul_5852), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[15728640, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/qkv/Add\"](%blocks.7.attn.qkv.bias, %/blocks.7/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul\"](%/blocks.7/attn/Gather_1_output_0, %/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_2720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2720), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2722 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_1\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2722), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat\"](%/blocks.7/attn/Unsqueeze_output_0, %/blocks.7/attn/Unsqueeze_1_output_0, %/blocks.7/attn/Constant_3_output_0, %/blocks.7/attn/Constant_4_output_0, %/blocks.7/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[15728640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape\"](%/blocks.7/attn/qkv/Add_output_0, %/blocks.7/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 15728640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.7/attn/Transpose\"](%/blocks.7/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.7/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_1\"](%/blocks.7/attn/Gather_output_0, %/blocks.7/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_2\"](%/blocks.7/attn/Mul_1_output_0, %onnx::Unsqueeze_2737), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_3\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2739), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_1\"](%/blocks.7/attn/Constant_7_output_0, %/blocks.7/attn/Unsqueeze_2_output_0, %/blocks.7/attn/Unsqueeze_3_output_0, %/blocks.7/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[1280, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_1\"](%/blocks.7/attn/Transpose_output_0, %/blocks.7/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.7/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.7/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.7/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.7/attn/Split\"](%/blocks.7/attn/Reshape_1_output_0, %/blocks.7/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze\"](%/blocks.7/attn/Split_output_0, %/blocks.7/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze_1\"](%/blocks.7/attn/Split_output_1, %/blocks.7/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.7/attn/Squeeze_2\"](%/blocks.7/attn/Split_output_2, %/blocks.7/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.7/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.7/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Mul_2_output_0 : Float(*, *, *, strides=[80, 1280, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_2\"](%/blocks.7/attn/Squeeze_output_0, %/blocks.7/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Transpose_1_output_0 : Float(*, *, *, strides=[80, 1, 3840], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.7/attn/Transpose_1\"](%/blocks.7/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/MatMul_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/MatMul\"](%/blocks.7/attn/Mul_2_output_0, %/blocks.7/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.7/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.7/attn/Range\"](%/blocks.7/attn/Constant_14_output_0, %/blocks.7/attn/Cast_output_0, %/blocks.7/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_4\"](%/blocks.7/attn/Range_output_0, %/blocks.7/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_1\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_2\"](%/blocks.7/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/attn/Div\"](%/blocks.7/attn/Cast_1_output_0, %/blocks.7/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_3\"](%/blocks.7/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_3\"](%/blocks.7/attn/Cast_3_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_5\"](%/blocks.7/attn/Range_output_0, %/blocks.7/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Cast_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_4\"](%/blocks.7/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Mul_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_4\"](%/blocks.7/attn/Cast_4_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Sub_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub\"](%/blocks.7/attn/Mul_3_output_0, %/blocks.7/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_1\"](%/blocks.7/attn/Gather_1_output_0, %/blocks.7/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_5\"](%/blocks.7/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_5\"](%/blocks.7/attn/Cast_5_output_0, %/blocks.7/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Add_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add\"](%/blocks.7/attn/Sub_output_0, %/blocks.7/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_6_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_6\"](%/blocks.7/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Gather_3_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_3\"](%blocks.7.attn.rel_pos_h, %/blocks.7/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_7\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.7/attn/Range_1\"](%/blocks.7/attn/Constant_19_output_0, %/blocks.7/attn/Cast_7_output_0, %/blocks.7/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_6\"](%/blocks.7/attn/Range_1_output_0, %/blocks.7/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_8\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_9\"](%/blocks.7/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/attn/Div_1\"](%/blocks.7/attn/Cast_8_output_0, %/blocks.7/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_10\"](%/blocks.7/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_6\"](%/blocks.7/attn/Cast_10_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.7/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_7\"](%/blocks.7/attn/Range_1_output_0, %/blocks.7/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Cast_11_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_11\"](%/blocks.7/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Mul_7_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_7\"](%/blocks.7/attn/Cast_11_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.7/attn/Sub_2_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_2\"](%/blocks.7/attn/Mul_6_output_0, %/blocks.7/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.7/attn/Sub_3\"](%/blocks.7/attn/Gather_2_output_0, %/blocks.7/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.7/attn/Cast_12\"](%/blocks.7/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/attn/Mul_8\"](%/blocks.7/attn/Cast_12_output_0, %/blocks.7/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Add_1_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_1\"](%/blocks.7/attn/Sub_2_output_0, %/blocks.7/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.7/attn/Cast_13_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.7/attn/Cast_13\"](%/blocks.7/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Gather_4_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_4\"](%blocks.7.attn.rel_pos_w, %/blocks.7/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.7/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_3\"](%/blocks.7/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.7/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_5\"](%/blocks.7/attn/Shape_3_output_0, %/blocks.7/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.7/attn/Shape_4\"](%/blocks.7/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.7/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.7/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.7/attn/Gather_6\"](%/blocks.7/attn/Shape_4_output_0, %/blocks.7/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_2811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_8\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2811), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_9\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2813), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_10\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2815), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_11\"](%/blocks.7/attn/Gather_6_output_0, %onnx::Unsqueeze_2817), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_2\"](%/blocks.7/attn/Unsqueeze_8_output_0, %/blocks.7/attn/Unsqueeze_9_output_0, %/blocks.7/attn/Unsqueeze_10_output_0, %/blocks.7/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.7/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[80, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_2\"](%/blocks.7/attn/Squeeze_output_0, %/blocks.7/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.7/attn/Einsum_output_0 : Float(*, *, *, *, strides=[4096, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.7/attn/Einsum\"](%/blocks.7/attn/Reshape_2_output_0, %/blocks.7/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.7/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[4096, 64, 65536, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.7/attn/Einsum_1\"](%/blocks.7/attn/Reshape_2_output_0, %/blocks.7/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_2823 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_12\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2823), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2825 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_13\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2825), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2827 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_14\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2827), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2829 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_15\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2829), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2831 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_16\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2831), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_3\"](%/blocks.7/attn/Unsqueeze_12_output_0, %/blocks.7/attn/Unsqueeze_13_output_0, %/blocks.7/attn/Unsqueeze_14_output_0, %/blocks.7/attn/Unsqueeze_15_output_0, %/blocks.7/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_3\"](%/blocks.7/attn/MatMul_output_0, %/blocks.7/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.7/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[4096, 65536, 64, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_17\"](%/blocks.7/attn/Einsum_output_0, %/blocks.7/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_2\"](%/blocks.7/attn/Reshape_3_output_0, %/blocks.7/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.7/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[4096, 64, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_18\"](%/blocks.7/attn/Einsum_1_output_0, %/blocks.7/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.7/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/Add_3\"](%/blocks.7/attn/Add_2_output_0, %/blocks.7/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_2841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_19\"](%/blocks.7/attn/Gather_5_output_0, %onnx::Unsqueeze_2841), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2843 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_20\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2843), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_21\"](%/blocks.7/attn/Mul_output_0, %onnx::Unsqueeze_2845), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_4\"](%/blocks.7/attn/Unsqueeze_19_output_0, %/blocks.7/attn/Unsqueeze_20_output_0, %/blocks.7/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.7/attn/Reshape_4_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_4\"](%/blocks.7/attn/Add_3_output_0, %/blocks.7/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.7/attn/Softmax_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.7/attn/Softmax\"](%/blocks.7/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.7/attn/MatMul_1_output_0 : Float(*, *, *, strides=[327680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/MatMul_1\"](%/blocks.7/attn/Softmax_output_0, %/blocks.7/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_22\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2851), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.7/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_23\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2855), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_24\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2857), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_5\"](%/blocks.7/attn/Unsqueeze_22_output_0, %/blocks.7/attn/Constant_28_output_0, %/blocks.7/attn/Unsqueeze_23_output_0, %/blocks.7/attn/Unsqueeze_24_output_0, %/blocks.7/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[5242880, 327680, 5120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_5\"](%/blocks.7/attn/MatMul_1_output_0, %/blocks.7/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[5242880, 5120, 80, 327680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.7/attn/Transpose_2\"](%/blocks.7/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_2864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_25\"](%/blocks.7/attn/Gather_output_0, %onnx::Unsqueeze_2864), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_26\"](%/blocks.7/attn/Gather_1_output_0, %onnx::Unsqueeze_2866), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_2868 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.7/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.7/attn/Unsqueeze_27\"](%/blocks.7/attn/Gather_2_output_0, %onnx::Unsqueeze_2868), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.7/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.7/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.7/attn/Concat_6\"](%/blocks.7/attn/Unsqueeze_25_output_0, %/blocks.7/attn/Unsqueeze_26_output_0, %/blocks.7/attn/Unsqueeze_27_output_0, %/blocks.7/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.7/attn/Reshape_6\"](%/blocks.7/attn/Transpose_2_output_0, %/blocks.7/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.7/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/attn/proj/MatMul\"](%/blocks.7/attn/Reshape_6_output_0, %onnx::MatMul_5861), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/attn/proj/Add\"](%blocks.7.attn.proj.bias, %/blocks.7/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/Add_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/Add\"](%/blocks.6/Add_3_output_0, %/blocks.7/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.7/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.7/norm2/LayerNormalization\"](%/blocks.7/Add_output_0, %blocks.7.norm2.weight, %blocks.7.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.7/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/mlp/lin1/MatMul\"](%/blocks.7/norm2/LayerNormalization_output_0, %onnx::MatMul_5862), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/lin1/Add\"](%blocks.7.mlp.lin1.bias, %/blocks.7/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.7/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.7/mlp/act/Div\"](%/blocks.7/mlp/lin1/Add_output_0, %/blocks.7/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.7/mlp/act/Erf\"](%/blocks.7/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.7/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/act/Add\"](%/blocks.7/mlp/act/Erf_output_0, %/blocks.7/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/mlp/act/Mul\"](%/blocks.7/mlp/lin1/Add_output_0, %/blocks.7/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.7/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.7/mlp/act/Mul_1\"](%/blocks.7/mlp/act/Mul_output_0, %/blocks.7/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.7/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.7/mlp/lin2/MatMul\"](%/blocks.7/mlp/act/Mul_1_output_0, %onnx::MatMul_5863), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/mlp/lin2/Add\"](%blocks.7.mlp.lin2.bias, %/blocks.7/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.7/Add_1_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.7/Add_1\"](%/blocks.7/Add_output_0, %/blocks.7/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.7 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.8/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.8/norm1/LayerNormalization\"](%/blocks.7/Add_1_output_0, %blocks.8.norm1.weight, %blocks.8.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.8/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather\"](%/blocks.8/Shape_output_0, %/blocks.8/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_1\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_1\"](%/blocks.8/Shape_1_output_0, %/blocks.8/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.8/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_2\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_2\"](%/blocks.8/Shape_2_output_0, %/blocks.8/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_3\"](%/blocks.8/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_3\"](%/blocks.8/Shape_3_output_0, %/blocks.8/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.8/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod\"](%/blocks.8/Gather_output_0, %/blocks.8/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub\"](%/blocks.8/Constant_5_output_0, %/blocks.8/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_1\"](%/blocks.8/Sub_output_0, %/blocks.8/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.8/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_2\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub_1\"](%/blocks.8/Constant_8_output_0, %/blocks.8/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.8/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.8/Mod_3\"](%/blocks.8/Sub_1_output_0, %/blocks.8/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.8/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze\"](%/blocks.8/Mod_3_output_0, %onnx::Unsqueeze_2925), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_1\"](%/blocks.8/Mod_1_output_0, %onnx::Unsqueeze_2929), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat\"](%/blocks.8/Constant_10_output_0, %/blocks.8/Constant_11_output_0, %/blocks.8/Constant_12_output_0, %/blocks.8/Unsqueeze_output_0, %/blocks.8/Constant_13_output_0, %/blocks.8/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_2\"](%/blocks.8/Mod_3_output_0, %onnx::Unsqueeze_2938), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_3\"](%/blocks.8/Mod_1_output_0, %onnx::Unsqueeze_2942), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_1\"](%/blocks.8/Constant_14_output_0, %/blocks.8/Constant_15_output_0, %/blocks.8/Constant_16_output_0, %/blocks.8/Unsqueeze_2_output_0, %/blocks.8/Constant_17_output_0, %/blocks.8/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_4\"](%/blocks.8/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_4\"](%/blocks.8/Shape_4_output_0, %/blocks.8/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.8/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/Sub_2\"](%/blocks.8/Constant_19_output_0, %/blocks.8/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast\"](%/blocks.8/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.8/ConstantOfShape\"](%/blocks.8/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_2\"](%/blocks.8/Cast_output_0, %/blocks.8/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.8/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape\"](%/blocks.8/Concat_2_output_0, %/blocks.8/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.8/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice\"](%/blocks.8/Reshape_output_0, %/blocks.8/Constant_22_output_0, %/blocks.8/Constant_23_output_0, %/blocks.8/Constant_21_output_0, %/blocks.8/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.8/Transpose\"](%/blocks.8/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_1\"](%/blocks.8/Transpose_output_0, %/blocks.8/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_1\"](%/blocks.8/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.8/Pad\"](%/blocks.8/norm1/LayerNormalization_output_0, %/blocks.8/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.8/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add\"](%/blocks.8/Gather_output_0, %/blocks.8/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.8/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_1\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.8/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div\"](%/blocks.8/Add_output_0, %/blocks.8/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_2\"](%/blocks.8/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_3\"](%/blocks.8/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_1\"](%/blocks.8/Add_1_output_0, %/blocks.8/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_4\"](%/blocks.8/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_5\"](%/blocks.8/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_2977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_4\"](%/blocks.8/Gather_2_output_0, %onnx::Unsqueeze_2977), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2979 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_5\"](%/blocks.8/Cast_3_output_0, %onnx::Unsqueeze_2979), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_6\"](%/blocks.8/Cast_5_output_0, %onnx::Unsqueeze_2983), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_7\"](%/blocks.8/Gather_3_output_0, %onnx::Unsqueeze_2987), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_3\"](%/blocks.8/Unsqueeze_4_output_0, %/blocks.8/Unsqueeze_5_output_0, %/blocks.8/Constant_28_output_0, %/blocks.8/Unsqueeze_6_output_0, %/blocks.8/Constant_29_output_0, %/blocks.8/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.8/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_2\"](%/blocks.8/Pad_output_0, %/blocks.8/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.8/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.8/Transpose_1\"](%/blocks.8/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_2998 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_8\"](%/blocks.8/Gather_3_output_0, %onnx::Unsqueeze_2998), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_4\"](%/blocks.8/Constant_30_output_0, %/blocks.8/Constant_31_output_0, %/blocks.8/Constant_32_output_0, %/blocks.8/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_3\"](%/blocks.8/Transpose_1_output_0, %/blocks.8/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.8/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather\"](%/blocks.8/attn/Shape_output_0, %/blocks.8/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_1\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_1\"](%/blocks.8/attn/Shape_1_output_0, %/blocks.8/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_2\"](%/blocks.8/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_2\"](%/blocks.8/attn/Shape_2_output_0, %/blocks.8/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.8/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/qkv/MatMul\"](%/blocks.8/Reshape_3_output_0, %onnx::MatMul_5878), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/qkv/Add\"](%blocks.8.attn.qkv.bias, %/blocks.8/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul\"](%/blocks.8/attn/Gather_1_output_0, %/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3015 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3015), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3017 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_1\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3017), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat\"](%/blocks.8/attn/Unsqueeze_output_0, %/blocks.8/attn/Unsqueeze_1_output_0, %/blocks.8/attn/Constant_3_output_0, %/blocks.8/attn/Constant_4_output_0, %/blocks.8/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape\"](%/blocks.8/attn/qkv/Add_output_0, %/blocks.8/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.8/attn/Transpose\"](%/blocks.8/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.8/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_1\"](%/blocks.8/attn/Gather_output_0, %/blocks.8/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3032 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_2\"](%/blocks.8/attn/Mul_1_output_0, %onnx::Unsqueeze_3032), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3034 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_3\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3034), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_1\"](%/blocks.8/attn/Constant_7_output_0, %/blocks.8/attn/Unsqueeze_2_output_0, %/blocks.8/attn/Unsqueeze_3_output_0, %/blocks.8/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_1\"](%/blocks.8/attn/Transpose_output_0, %/blocks.8/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.8/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.8/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.8/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.8/attn/Split\"](%/blocks.8/attn/Reshape_1_output_0, %/blocks.8/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze\"](%/blocks.8/attn/Split_output_0, %/blocks.8/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze_1\"](%/blocks.8/attn/Split_output_1, %/blocks.8/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.8/attn/Squeeze_2\"](%/blocks.8/attn/Split_output_2, %/blocks.8/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.8/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.8/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_2\"](%/blocks.8/attn/Squeeze_output_0, %/blocks.8/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.8/attn/Transpose_1\"](%/blocks.8/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/MatMul\"](%/blocks.8/attn/Mul_2_output_0, %/blocks.8/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.8/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.8/attn/Range\"](%/blocks.8/attn/Constant_14_output_0, %/blocks.8/attn/Cast_output_0, %/blocks.8/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_4\"](%/blocks.8/attn/Range_output_0, %/blocks.8/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_1\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_2\"](%/blocks.8/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/attn/Div\"](%/blocks.8/attn/Cast_1_output_0, %/blocks.8/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_3\"](%/blocks.8/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_3\"](%/blocks.8/attn/Cast_3_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_5\"](%/blocks.8/attn/Range_output_0, %/blocks.8/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_4\"](%/blocks.8/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_4\"](%/blocks.8/attn/Cast_4_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub\"](%/blocks.8/attn/Mul_3_output_0, %/blocks.8/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_1\"](%/blocks.8/attn/Gather_1_output_0, %/blocks.8/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_5\"](%/blocks.8/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_5\"](%/blocks.8/attn/Cast_5_output_0, %/blocks.8/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add\"](%/blocks.8/attn/Sub_output_0, %/blocks.8/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_6\"](%/blocks.8/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_3\"](%blocks.8.attn.rel_pos_h, %/blocks.8/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_7\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.8/attn/Range_1\"](%/blocks.8/attn/Constant_19_output_0, %/blocks.8/attn/Cast_7_output_0, %/blocks.8/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_6\"](%/blocks.8/attn/Range_1_output_0, %/blocks.8/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_8\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_9\"](%/blocks.8/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/attn/Div_1\"](%/blocks.8/attn/Cast_8_output_0, %/blocks.8/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_10\"](%/blocks.8/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_6\"](%/blocks.8/attn/Cast_10_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.8/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_7\"](%/blocks.8/attn/Range_1_output_0, %/blocks.8/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_11\"](%/blocks.8/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_7\"](%/blocks.8/attn/Cast_11_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.8/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_2\"](%/blocks.8/attn/Mul_6_output_0, %/blocks.8/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.8/attn/Sub_3\"](%/blocks.8/attn/Gather_2_output_0, %/blocks.8/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.8/attn/Cast_12\"](%/blocks.8/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/attn/Mul_8\"](%/blocks.8/attn/Cast_12_output_0, %/blocks.8/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_1\"](%/blocks.8/attn/Sub_2_output_0, %/blocks.8/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.8/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/attn/Cast_13\"](%/blocks.8/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_4\"](%blocks.8.attn.rel_pos_w, %/blocks.8/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.8/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_3\"](%/blocks.8/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_5\"](%/blocks.8/attn/Shape_3_output_0, %/blocks.8/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/attn/Shape_4\"](%/blocks.8/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.8/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/attn/Gather_6\"](%/blocks.8/attn/Shape_4_output_0, %/blocks.8/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_8\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3106), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3108 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_9\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3108), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3110 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_10\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3110), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3112 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_11\"](%/blocks.8/attn/Gather_6_output_0, %onnx::Unsqueeze_3112), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_2\"](%/blocks.8/attn/Unsqueeze_8_output_0, %/blocks.8/attn/Unsqueeze_9_output_0, %/blocks.8/attn/Unsqueeze_10_output_0, %/blocks.8/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.8/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_2\"](%/blocks.8/attn/Squeeze_output_0, %/blocks.8/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.8/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.8/attn/Einsum\"](%/blocks.8/attn/Reshape_2_output_0, %/blocks.8/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.8/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.8/attn/Einsum_1\"](%/blocks.8/attn/Reshape_2_output_0, %/blocks.8/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_12\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3118), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3120 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_13\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3120), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_14\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3122), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_15\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3124), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3126 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_16\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3126), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_3\"](%/blocks.8/attn/Unsqueeze_12_output_0, %/blocks.8/attn/Unsqueeze_13_output_0, %/blocks.8/attn/Unsqueeze_14_output_0, %/blocks.8/attn/Unsqueeze_15_output_0, %/blocks.8/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_3\"](%/blocks.8/attn/MatMul_output_0, %/blocks.8/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.8/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_17\"](%/blocks.8/attn/Einsum_output_0, %/blocks.8/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_2\"](%/blocks.8/attn/Reshape_3_output_0, %/blocks.8/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.8/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_18\"](%/blocks.8/attn/Einsum_1_output_0, %/blocks.8/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.8/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/Add_3\"](%/blocks.8/attn/Add_2_output_0, %/blocks.8/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_19\"](%/blocks.8/attn/Gather_5_output_0, %onnx::Unsqueeze_3136), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_20\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3138), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_21\"](%/blocks.8/attn/Mul_output_0, %onnx::Unsqueeze_3140), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_4\"](%/blocks.8/attn/Unsqueeze_19_output_0, %/blocks.8/attn/Unsqueeze_20_output_0, %/blocks.8/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.8/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_4\"](%/blocks.8/attn/Add_3_output_0, %/blocks.8/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.8/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.8/attn/Softmax\"](%/blocks.8/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.8/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/MatMul_1\"](%/blocks.8/attn/Softmax_output_0, %/blocks.8/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_22\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3146), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.8/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_23\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3150), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_24\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3152), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_5\"](%/blocks.8/attn/Unsqueeze_22_output_0, %/blocks.8/attn/Constant_28_output_0, %/blocks.8/attn/Unsqueeze_23_output_0, %/blocks.8/attn/Unsqueeze_24_output_0, %/blocks.8/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_5\"](%/blocks.8/attn/MatMul_1_output_0, %/blocks.8/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.8/attn/Transpose_2\"](%/blocks.8/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_25\"](%/blocks.8/attn/Gather_output_0, %onnx::Unsqueeze_3159), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3161 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_26\"](%/blocks.8/attn/Gather_1_output_0, %onnx::Unsqueeze_3161), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3163 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/attn/Unsqueeze_27\"](%/blocks.8/attn/Gather_2_output_0, %onnx::Unsqueeze_3163), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.8/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/attn/Concat_6\"](%/blocks.8/attn/Unsqueeze_25_output_0, %/blocks.8/attn/Unsqueeze_26_output_0, %/blocks.8/attn/Unsqueeze_27_output_0, %/blocks.8/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/attn/Reshape_6\"](%/blocks.8/attn/Transpose_2_output_0, %/blocks.8/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.8/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/attn/proj/MatMul\"](%/blocks.8/attn/Reshape_6_output_0, %onnx::MatMul_5887), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/attn/proj/Add\"](%blocks.8.attn.proj.bias, %/blocks.8/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.8/Shape_5\"](%/blocks.8/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.8/Gather_5\"](%/blocks.8/Shape_5_output_0, %/blocks.8/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/Mul\"](%/blocks.8/Add_output_0, %/blocks.8/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.8/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_2\"](%/blocks.8/Mul_output_0, %/blocks.8/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_6\"](%/blocks.8/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_7\"](%/blocks.8/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_3\"](%/blocks.8/Cast_7_output_0, %/blocks.8/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_8\"](%/blocks.8/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_9\"](%/blocks.8/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.8/Div_4\"](%/blocks.8/Gather_5_output_0, %/blocks.8/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_10\"](%/blocks.8/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.8/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.8/Cast_11\"](%/blocks.8/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_9\"](%/blocks.8/Cast_11_output_0, %onnx::Unsqueeze_3187), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_10\"](%/blocks.8/Cast_3_output_0, %onnx::Unsqueeze_3189), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_11\"](%/blocks.8/Cast_5_output_0, %onnx::Unsqueeze_3191), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.8/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_5\"](%/blocks.8/Unsqueeze_9_output_0, %/blocks.8/Unsqueeze_10_output_0, %/blocks.8/Unsqueeze_11_output_0, %/blocks.8/Constant_36_output_0, %/blocks.8/Constant_37_output_0, %/blocks.8/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.8/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_4\"](%/blocks.8/attn/proj/Add_output_0, %/blocks.8/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.8/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.8/Transpose_2\"](%/blocks.8/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3202 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_12\"](%/blocks.8/Cast_11_output_0, %onnx::Unsqueeze_3202), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3204 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_13\"](%/blocks.8/Add_output_0, %onnx::Unsqueeze_3204), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %onnx::Unsqueeze_3206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.8/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_14\"](%/blocks.8/Add_1_output_0, %onnx::Unsqueeze_3206), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.8/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8\n",
            "  %/blocks.8/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.8/Concat_6\"](%/blocks.8/Unsqueeze_12_output_0, %/blocks.8/Unsqueeze_13_output_0, %/blocks.8/Unsqueeze_14_output_0, %/blocks.8/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.8/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.8/Reshape_5\"](%/blocks.8/Transpose_2_output_0, %/blocks.8/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.8/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_15\"](%/blocks.8/Gather_output_0, %/blocks.8/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice_1\"](%/blocks.8/Reshape_5_output_0, %/blocks.8/Constant_41_output_0, %/blocks.8/Unsqueeze_15_output_0, %/blocks.8/Constant_40_output_0, %/blocks.8/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.8/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.8/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.8/Unsqueeze_16\"](%/blocks.8/Gather_1_output_0, %/blocks.8/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.8/Slice_2\"](%/blocks.8/Slice_1_output_0, %/blocks.8/Constant_45_output_0, %/blocks.8/Unsqueeze_16_output_0, %/blocks.8/Constant_44_output_0, %/blocks.8/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.8/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_2\"](%/blocks.7/Add_1_output_0, %/blocks.8/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.8/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.8/norm2/LayerNormalization\"](%/blocks.8/Add_2_output_0, %blocks.8.norm2.weight, %blocks.8.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.8/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/mlp/lin1/MatMul\"](%/blocks.8/norm2/LayerNormalization_output_0, %onnx::MatMul_5898), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/lin1/Add\"](%blocks.8.mlp.lin1.bias, %/blocks.8/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.8/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.8/mlp/act/Div\"](%/blocks.8/mlp/lin1/Add_output_0, %/blocks.8/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.8/mlp/act/Erf\"](%/blocks.8/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.8/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/act/Add\"](%/blocks.8/mlp/act/Erf_output_0, %/blocks.8/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/mlp/act/Mul\"](%/blocks.8/mlp/lin1/Add_output_0, %/blocks.8/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.8/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.8/mlp/act/Mul_1\"](%/blocks.8/mlp/act/Mul_output_0, %/blocks.8/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.8/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.8/mlp/lin2/MatMul\"](%/blocks.8/mlp/act/Mul_1_output_0, %onnx::MatMul_5899), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/mlp/lin2/Add\"](%blocks.8.mlp.lin2.bias, %/blocks.8/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.8/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.8/Add_3\"](%/blocks.8/Add_2_output_0, %/blocks.8/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.8 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.9/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.9/norm1/LayerNormalization\"](%/blocks.8/Add_3_output_0, %blocks.9.norm1.weight, %blocks.9.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.9/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather\"](%/blocks.9/Shape_output_0, %/blocks.9/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_1\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_1\"](%/blocks.9/Shape_1_output_0, %/blocks.9/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.9/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_2\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_2\"](%/blocks.9/Shape_2_output_0, %/blocks.9/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_3\"](%/blocks.9/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_3\"](%/blocks.9/Shape_3_output_0, %/blocks.9/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.9/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod\"](%/blocks.9/Gather_output_0, %/blocks.9/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub\"](%/blocks.9/Constant_5_output_0, %/blocks.9/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_1\"](%/blocks.9/Sub_output_0, %/blocks.9/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.9/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_2\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub_1\"](%/blocks.9/Constant_8_output_0, %/blocks.9/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.9/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.9/Mod_3\"](%/blocks.9/Sub_1_output_0, %/blocks.9/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.9/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze\"](%/blocks.9/Mod_3_output_0, %onnx::Unsqueeze_3278), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3282 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_1\"](%/blocks.9/Mod_1_output_0, %onnx::Unsqueeze_3282), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat\"](%/blocks.9/Constant_10_output_0, %/blocks.9/Constant_11_output_0, %/blocks.9/Constant_12_output_0, %/blocks.9/Unsqueeze_output_0, %/blocks.9/Constant_13_output_0, %/blocks.9/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_2\"](%/blocks.9/Mod_3_output_0, %onnx::Unsqueeze_3291), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_3\"](%/blocks.9/Mod_1_output_0, %onnx::Unsqueeze_3295), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_1\"](%/blocks.9/Constant_14_output_0, %/blocks.9/Constant_15_output_0, %/blocks.9/Constant_16_output_0, %/blocks.9/Unsqueeze_2_output_0, %/blocks.9/Constant_17_output_0, %/blocks.9/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_4\"](%/blocks.9/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_4\"](%/blocks.9/Shape_4_output_0, %/blocks.9/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.9/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/Sub_2\"](%/blocks.9/Constant_19_output_0, %/blocks.9/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast\"](%/blocks.9/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.9/ConstantOfShape\"](%/blocks.9/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_2\"](%/blocks.9/Cast_output_0, %/blocks.9/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.9/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape\"](%/blocks.9/Concat_2_output_0, %/blocks.9/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.9/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice\"](%/blocks.9/Reshape_output_0, %/blocks.9/Constant_22_output_0, %/blocks.9/Constant_23_output_0, %/blocks.9/Constant_21_output_0, %/blocks.9/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.9/Transpose\"](%/blocks.9/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_1\"](%/blocks.9/Transpose_output_0, %/blocks.9/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_1\"](%/blocks.9/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.9/Pad\"](%/blocks.9/norm1/LayerNormalization_output_0, %/blocks.9/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.9/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add\"](%/blocks.9/Gather_output_0, %/blocks.9/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.9/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_1\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.9/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div\"](%/blocks.9/Add_output_0, %/blocks.9/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_2\"](%/blocks.9/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_3\"](%/blocks.9/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_1\"](%/blocks.9/Add_1_output_0, %/blocks.9/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_4\"](%/blocks.9/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_5\"](%/blocks.9/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3330 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_4\"](%/blocks.9/Gather_2_output_0, %onnx::Unsqueeze_3330), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3332 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_5\"](%/blocks.9/Cast_3_output_0, %onnx::Unsqueeze_3332), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3336 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_6\"](%/blocks.9/Cast_5_output_0, %onnx::Unsqueeze_3336), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3340 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_7\"](%/blocks.9/Gather_3_output_0, %onnx::Unsqueeze_3340), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_3\"](%/blocks.9/Unsqueeze_4_output_0, %/blocks.9/Unsqueeze_5_output_0, %/blocks.9/Constant_28_output_0, %/blocks.9/Unsqueeze_6_output_0, %/blocks.9/Constant_29_output_0, %/blocks.9/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.9/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_2\"](%/blocks.9/Pad_output_0, %/blocks.9/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.9/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.9/Transpose_1\"](%/blocks.9/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3351 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_8\"](%/blocks.9/Gather_3_output_0, %onnx::Unsqueeze_3351), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_4\"](%/blocks.9/Constant_30_output_0, %/blocks.9/Constant_31_output_0, %/blocks.9/Constant_32_output_0, %/blocks.9/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_3\"](%/blocks.9/Transpose_1_output_0, %/blocks.9/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.9/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather\"](%/blocks.9/attn/Shape_output_0, %/blocks.9/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_1\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_1\"](%/blocks.9/attn/Shape_1_output_0, %/blocks.9/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_2\"](%/blocks.9/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_2\"](%/blocks.9/attn/Shape_2_output_0, %/blocks.9/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.9/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/qkv/MatMul\"](%/blocks.9/Reshape_3_output_0, %onnx::MatMul_5914), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/qkv/Add\"](%blocks.9.attn.qkv.bias, %/blocks.9/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul\"](%/blocks.9/attn/Gather_1_output_0, %/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3368 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3368), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3370 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_1\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3370), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat\"](%/blocks.9/attn/Unsqueeze_output_0, %/blocks.9/attn/Unsqueeze_1_output_0, %/blocks.9/attn/Constant_3_output_0, %/blocks.9/attn/Constant_4_output_0, %/blocks.9/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape\"](%/blocks.9/attn/qkv/Add_output_0, %/blocks.9/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.9/attn/Transpose\"](%/blocks.9/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.9/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_1\"](%/blocks.9/attn/Gather_output_0, %/blocks.9/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3385 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_2\"](%/blocks.9/attn/Mul_1_output_0, %onnx::Unsqueeze_3385), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_3\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3387), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_1\"](%/blocks.9/attn/Constant_7_output_0, %/blocks.9/attn/Unsqueeze_2_output_0, %/blocks.9/attn/Unsqueeze_3_output_0, %/blocks.9/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_1\"](%/blocks.9/attn/Transpose_output_0, %/blocks.9/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.9/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.9/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.9/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.9/attn/Split\"](%/blocks.9/attn/Reshape_1_output_0, %/blocks.9/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze\"](%/blocks.9/attn/Split_output_0, %/blocks.9/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze_1\"](%/blocks.9/attn/Split_output_1, %/blocks.9/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.9/attn/Squeeze_2\"](%/blocks.9/attn/Split_output_2, %/blocks.9/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.9/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.9/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_2\"](%/blocks.9/attn/Squeeze_output_0, %/blocks.9/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.9/attn/Transpose_1\"](%/blocks.9/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/MatMul\"](%/blocks.9/attn/Mul_2_output_0, %/blocks.9/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.9/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.9/attn/Range\"](%/blocks.9/attn/Constant_14_output_0, %/blocks.9/attn/Cast_output_0, %/blocks.9/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_4\"](%/blocks.9/attn/Range_output_0, %/blocks.9/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_1\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_2\"](%/blocks.9/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/attn/Div\"](%/blocks.9/attn/Cast_1_output_0, %/blocks.9/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_3\"](%/blocks.9/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_3\"](%/blocks.9/attn/Cast_3_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_5\"](%/blocks.9/attn/Range_output_0, %/blocks.9/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_4\"](%/blocks.9/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_4\"](%/blocks.9/attn/Cast_4_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub\"](%/blocks.9/attn/Mul_3_output_0, %/blocks.9/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_1\"](%/blocks.9/attn/Gather_1_output_0, %/blocks.9/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_5\"](%/blocks.9/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_5\"](%/blocks.9/attn/Cast_5_output_0, %/blocks.9/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add\"](%/blocks.9/attn/Sub_output_0, %/blocks.9/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_6\"](%/blocks.9/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_3\"](%blocks.9.attn.rel_pos_h, %/blocks.9/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_7\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.9/attn/Range_1\"](%/blocks.9/attn/Constant_19_output_0, %/blocks.9/attn/Cast_7_output_0, %/blocks.9/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_6\"](%/blocks.9/attn/Range_1_output_0, %/blocks.9/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_8\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_9\"](%/blocks.9/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/attn/Div_1\"](%/blocks.9/attn/Cast_8_output_0, %/blocks.9/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_10\"](%/blocks.9/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_6\"](%/blocks.9/attn/Cast_10_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.9/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_7\"](%/blocks.9/attn/Range_1_output_0, %/blocks.9/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_11\"](%/blocks.9/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_7\"](%/blocks.9/attn/Cast_11_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.9/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_2\"](%/blocks.9/attn/Mul_6_output_0, %/blocks.9/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.9/attn/Sub_3\"](%/blocks.9/attn/Gather_2_output_0, %/blocks.9/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.9/attn/Cast_12\"](%/blocks.9/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/attn/Mul_8\"](%/blocks.9/attn/Cast_12_output_0, %/blocks.9/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_1\"](%/blocks.9/attn/Sub_2_output_0, %/blocks.9/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.9/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/attn/Cast_13\"](%/blocks.9/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_4\"](%blocks.9.attn.rel_pos_w, %/blocks.9/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.9/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_3\"](%/blocks.9/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_5\"](%/blocks.9/attn/Shape_3_output_0, %/blocks.9/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/attn/Shape_4\"](%/blocks.9/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.9/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/attn/Gather_6\"](%/blocks.9/attn/Shape_4_output_0, %/blocks.9/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_8\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3459), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_9\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3461), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_10\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3463), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_11\"](%/blocks.9/attn/Gather_6_output_0, %onnx::Unsqueeze_3465), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_2\"](%/blocks.9/attn/Unsqueeze_8_output_0, %/blocks.9/attn/Unsqueeze_9_output_0, %/blocks.9/attn/Unsqueeze_10_output_0, %/blocks.9/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.9/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_2\"](%/blocks.9/attn/Squeeze_output_0, %/blocks.9/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.9/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.9/attn/Einsum\"](%/blocks.9/attn/Reshape_2_output_0, %/blocks.9/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.9/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.9/attn/Einsum_1\"](%/blocks.9/attn/Reshape_2_output_0, %/blocks.9/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3471 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_12\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3471), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3473 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_13\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3473), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3475 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_14\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3475), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_15\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3477), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_16\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3479), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_3\"](%/blocks.9/attn/Unsqueeze_12_output_0, %/blocks.9/attn/Unsqueeze_13_output_0, %/blocks.9/attn/Unsqueeze_14_output_0, %/blocks.9/attn/Unsqueeze_15_output_0, %/blocks.9/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_3\"](%/blocks.9/attn/MatMul_output_0, %/blocks.9/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.9/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_17\"](%/blocks.9/attn/Einsum_output_0, %/blocks.9/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_2\"](%/blocks.9/attn/Reshape_3_output_0, %/blocks.9/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.9/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_18\"](%/blocks.9/attn/Einsum_1_output_0, %/blocks.9/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.9/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/Add_3\"](%/blocks.9/attn/Add_2_output_0, %/blocks.9/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3489 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_19\"](%/blocks.9/attn/Gather_5_output_0, %onnx::Unsqueeze_3489), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_20\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3491), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_21\"](%/blocks.9/attn/Mul_output_0, %onnx::Unsqueeze_3493), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_4\"](%/blocks.9/attn/Unsqueeze_19_output_0, %/blocks.9/attn/Unsqueeze_20_output_0, %/blocks.9/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.9/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_4\"](%/blocks.9/attn/Add_3_output_0, %/blocks.9/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.9/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.9/attn/Softmax\"](%/blocks.9/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.9/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/MatMul_1\"](%/blocks.9/attn/Softmax_output_0, %/blocks.9/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_22\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3499), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.9/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_23\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3503), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_24\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3505), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_5\"](%/blocks.9/attn/Unsqueeze_22_output_0, %/blocks.9/attn/Constant_28_output_0, %/blocks.9/attn/Unsqueeze_23_output_0, %/blocks.9/attn/Unsqueeze_24_output_0, %/blocks.9/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_5\"](%/blocks.9/attn/MatMul_1_output_0, %/blocks.9/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.9/attn/Transpose_2\"](%/blocks.9/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_25\"](%/blocks.9/attn/Gather_output_0, %onnx::Unsqueeze_3512), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_26\"](%/blocks.9/attn/Gather_1_output_0, %onnx::Unsqueeze_3514), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/attn/Unsqueeze_27\"](%/blocks.9/attn/Gather_2_output_0, %onnx::Unsqueeze_3516), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.9/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/attn/Concat_6\"](%/blocks.9/attn/Unsqueeze_25_output_0, %/blocks.9/attn/Unsqueeze_26_output_0, %/blocks.9/attn/Unsqueeze_27_output_0, %/blocks.9/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/attn/Reshape_6\"](%/blocks.9/attn/Transpose_2_output_0, %/blocks.9/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.9/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/attn/proj/MatMul\"](%/blocks.9/attn/Reshape_6_output_0, %onnx::MatMul_5923), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/attn/proj/Add\"](%blocks.9.attn.proj.bias, %/blocks.9/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.9/Shape_5\"](%/blocks.9/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.9/Gather_5\"](%/blocks.9/Shape_5_output_0, %/blocks.9/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/Mul\"](%/blocks.9/Add_output_0, %/blocks.9/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.9/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_2\"](%/blocks.9/Mul_output_0, %/blocks.9/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_6\"](%/blocks.9/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_7\"](%/blocks.9/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_3\"](%/blocks.9/Cast_7_output_0, %/blocks.9/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_8\"](%/blocks.9/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_9\"](%/blocks.9/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.9/Div_4\"](%/blocks.9/Gather_5_output_0, %/blocks.9/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_10\"](%/blocks.9/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.9/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.9/Cast_11\"](%/blocks.9/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_9\"](%/blocks.9/Cast_11_output_0, %onnx::Unsqueeze_3540), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3542 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_10\"](%/blocks.9/Cast_3_output_0, %onnx::Unsqueeze_3542), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3544 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_11\"](%/blocks.9/Cast_5_output_0, %onnx::Unsqueeze_3544), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.9/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_5\"](%/blocks.9/Unsqueeze_9_output_0, %/blocks.9/Unsqueeze_10_output_0, %/blocks.9/Unsqueeze_11_output_0, %/blocks.9/Constant_36_output_0, %/blocks.9/Constant_37_output_0, %/blocks.9/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.9/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_4\"](%/blocks.9/attn/proj/Add_output_0, %/blocks.9/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.9/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.9/Transpose_2\"](%/blocks.9/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_12\"](%/blocks.9/Cast_11_output_0, %onnx::Unsqueeze_3555), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_13\"](%/blocks.9/Add_output_0, %onnx::Unsqueeze_3557), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %onnx::Unsqueeze_3559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.9/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_14\"](%/blocks.9/Add_1_output_0, %onnx::Unsqueeze_3559), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.9/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9\n",
            "  %/blocks.9/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.9/Concat_6\"](%/blocks.9/Unsqueeze_12_output_0, %/blocks.9/Unsqueeze_13_output_0, %/blocks.9/Unsqueeze_14_output_0, %/blocks.9/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.9/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.9/Reshape_5\"](%/blocks.9/Transpose_2_output_0, %/blocks.9/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.9/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_15\"](%/blocks.9/Gather_output_0, %/blocks.9/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice_1\"](%/blocks.9/Reshape_5_output_0, %/blocks.9/Constant_41_output_0, %/blocks.9/Unsqueeze_15_output_0, %/blocks.9/Constant_40_output_0, %/blocks.9/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.9/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.9/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.9/Unsqueeze_16\"](%/blocks.9/Gather_1_output_0, %/blocks.9/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.9/Slice_2\"](%/blocks.9/Slice_1_output_0, %/blocks.9/Constant_45_output_0, %/blocks.9/Unsqueeze_16_output_0, %/blocks.9/Constant_44_output_0, %/blocks.9/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.9/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_2\"](%/blocks.8/Add_3_output_0, %/blocks.9/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.9/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.9/norm2/LayerNormalization\"](%/blocks.9/Add_2_output_0, %blocks.9.norm2.weight, %blocks.9.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.9/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/mlp/lin1/MatMul\"](%/blocks.9/norm2/LayerNormalization_output_0, %onnx::MatMul_5934), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/lin1/Add\"](%blocks.9.mlp.lin1.bias, %/blocks.9/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.9/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.9/mlp/act/Div\"](%/blocks.9/mlp/lin1/Add_output_0, %/blocks.9/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.9/mlp/act/Erf\"](%/blocks.9/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.9/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/act/Add\"](%/blocks.9/mlp/act/Erf_output_0, %/blocks.9/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/mlp/act/Mul\"](%/blocks.9/mlp/lin1/Add_output_0, %/blocks.9/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.9/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.9/mlp/act/Mul_1\"](%/blocks.9/mlp/act/Mul_output_0, %/blocks.9/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.9/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.9/mlp/lin2/MatMul\"](%/blocks.9/mlp/act/Mul_1_output_0, %onnx::MatMul_5935), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/mlp/lin2/Add\"](%blocks.9.mlp.lin2.bias, %/blocks.9/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.9/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.9/Add_3\"](%/blocks.9/Add_2_output_0, %/blocks.9/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.9 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.10/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.10/norm1/LayerNormalization\"](%/blocks.9/Add_3_output_0, %blocks.10.norm1.weight, %blocks.10.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.10/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather\"](%/blocks.10/Shape_output_0, %/blocks.10/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_1\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_1\"](%/blocks.10/Shape_1_output_0, %/blocks.10/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.10/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_2\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_2\"](%/blocks.10/Shape_2_output_0, %/blocks.10/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_3\"](%/blocks.10/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_3\"](%/blocks.10/Shape_3_output_0, %/blocks.10/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.10/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod\"](%/blocks.10/Gather_output_0, %/blocks.10/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub\"](%/blocks.10/Constant_5_output_0, %/blocks.10/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_1\"](%/blocks.10/Sub_output_0, %/blocks.10/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.10/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_2\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub_1\"](%/blocks.10/Constant_8_output_0, %/blocks.10/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.10/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.10/Mod_3\"](%/blocks.10/Sub_1_output_0, %/blocks.10/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.10/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze\"](%/blocks.10/Mod_3_output_0, %onnx::Unsqueeze_3631), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_1\"](%/blocks.10/Mod_1_output_0, %onnx::Unsqueeze_3635), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat\"](%/blocks.10/Constant_10_output_0, %/blocks.10/Constant_11_output_0, %/blocks.10/Constant_12_output_0, %/blocks.10/Unsqueeze_output_0, %/blocks.10/Constant_13_output_0, %/blocks.10/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_2\"](%/blocks.10/Mod_3_output_0, %onnx::Unsqueeze_3644), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_3\"](%/blocks.10/Mod_1_output_0, %onnx::Unsqueeze_3648), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_1\"](%/blocks.10/Constant_14_output_0, %/blocks.10/Constant_15_output_0, %/blocks.10/Constant_16_output_0, %/blocks.10/Unsqueeze_2_output_0, %/blocks.10/Constant_17_output_0, %/blocks.10/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_4\"](%/blocks.10/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_4\"](%/blocks.10/Shape_4_output_0, %/blocks.10/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.10/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/Sub_2\"](%/blocks.10/Constant_19_output_0, %/blocks.10/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast\"](%/blocks.10/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.10/ConstantOfShape\"](%/blocks.10/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_2\"](%/blocks.10/Cast_output_0, %/blocks.10/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.10/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape\"](%/blocks.10/Concat_2_output_0, %/blocks.10/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.10/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice\"](%/blocks.10/Reshape_output_0, %/blocks.10/Constant_22_output_0, %/blocks.10/Constant_23_output_0, %/blocks.10/Constant_21_output_0, %/blocks.10/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.10/Transpose\"](%/blocks.10/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_1\"](%/blocks.10/Transpose_output_0, %/blocks.10/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_1\"](%/blocks.10/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.10/Pad\"](%/blocks.10/norm1/LayerNormalization_output_0, %/blocks.10/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.10/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add\"](%/blocks.10/Gather_output_0, %/blocks.10/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.10/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_1\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.10/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div\"](%/blocks.10/Add_output_0, %/blocks.10/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_2\"](%/blocks.10/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_3\"](%/blocks.10/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_1\"](%/blocks.10/Add_1_output_0, %/blocks.10/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_4\"](%/blocks.10/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_5\"](%/blocks.10/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_4\"](%/blocks.10/Gather_2_output_0, %onnx::Unsqueeze_3683), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_5\"](%/blocks.10/Cast_3_output_0, %onnx::Unsqueeze_3685), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3689 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_6\"](%/blocks.10/Cast_5_output_0, %onnx::Unsqueeze_3689), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3693 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_7\"](%/blocks.10/Gather_3_output_0, %onnx::Unsqueeze_3693), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_3\"](%/blocks.10/Unsqueeze_4_output_0, %/blocks.10/Unsqueeze_5_output_0, %/blocks.10/Constant_28_output_0, %/blocks.10/Unsqueeze_6_output_0, %/blocks.10/Constant_29_output_0, %/blocks.10/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.10/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_2\"](%/blocks.10/Pad_output_0, %/blocks.10/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.10/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.10/Transpose_1\"](%/blocks.10/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3704 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_8\"](%/blocks.10/Gather_3_output_0, %onnx::Unsqueeze_3704), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_4\"](%/blocks.10/Constant_30_output_0, %/blocks.10/Constant_31_output_0, %/blocks.10/Constant_32_output_0, %/blocks.10/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_3\"](%/blocks.10/Transpose_1_output_0, %/blocks.10/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.10/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather\"](%/blocks.10/attn/Shape_output_0, %/blocks.10/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_1\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_1\"](%/blocks.10/attn/Shape_1_output_0, %/blocks.10/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_2\"](%/blocks.10/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_2\"](%/blocks.10/attn/Shape_2_output_0, %/blocks.10/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.10/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/qkv/MatMul\"](%/blocks.10/Reshape_3_output_0, %onnx::MatMul_5950), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/qkv/Add\"](%blocks.10.attn.qkv.bias, %/blocks.10/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul\"](%/blocks.10/attn/Gather_1_output_0, %/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_3721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3721), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_1\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3723), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat\"](%/blocks.10/attn/Unsqueeze_output_0, %/blocks.10/attn/Unsqueeze_1_output_0, %/blocks.10/attn/Constant_3_output_0, %/blocks.10/attn/Constant_4_output_0, %/blocks.10/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape\"](%/blocks.10/attn/qkv/Add_output_0, %/blocks.10/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.10/attn/Transpose\"](%/blocks.10/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.10/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_1\"](%/blocks.10/attn/Gather_output_0, %/blocks.10/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_2\"](%/blocks.10/attn/Mul_1_output_0, %onnx::Unsqueeze_3738), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_3\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3740), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_1\"](%/blocks.10/attn/Constant_7_output_0, %/blocks.10/attn/Unsqueeze_2_output_0, %/blocks.10/attn/Unsqueeze_3_output_0, %/blocks.10/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_1\"](%/blocks.10/attn/Transpose_output_0, %/blocks.10/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.10/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.10/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.10/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.10/attn/Split\"](%/blocks.10/attn/Reshape_1_output_0, %/blocks.10/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze\"](%/blocks.10/attn/Split_output_0, %/blocks.10/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze_1\"](%/blocks.10/attn/Split_output_1, %/blocks.10/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.10/attn/Squeeze_2\"](%/blocks.10/attn/Split_output_2, %/blocks.10/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.10/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.10/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_2\"](%/blocks.10/attn/Squeeze_output_0, %/blocks.10/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.10/attn/Transpose_1\"](%/blocks.10/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/MatMul\"](%/blocks.10/attn/Mul_2_output_0, %/blocks.10/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.10/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.10/attn/Range\"](%/blocks.10/attn/Constant_14_output_0, %/blocks.10/attn/Cast_output_0, %/blocks.10/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_4\"](%/blocks.10/attn/Range_output_0, %/blocks.10/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_1\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_2\"](%/blocks.10/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/attn/Div\"](%/blocks.10/attn/Cast_1_output_0, %/blocks.10/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_3\"](%/blocks.10/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_3\"](%/blocks.10/attn/Cast_3_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_5\"](%/blocks.10/attn/Range_output_0, %/blocks.10/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_4\"](%/blocks.10/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_4\"](%/blocks.10/attn/Cast_4_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub\"](%/blocks.10/attn/Mul_3_output_0, %/blocks.10/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_1\"](%/blocks.10/attn/Gather_1_output_0, %/blocks.10/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_5\"](%/blocks.10/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_5\"](%/blocks.10/attn/Cast_5_output_0, %/blocks.10/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add\"](%/blocks.10/attn/Sub_output_0, %/blocks.10/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_6\"](%/blocks.10/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_3\"](%blocks.10.attn.rel_pos_h, %/blocks.10/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_7\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.10/attn/Range_1\"](%/blocks.10/attn/Constant_19_output_0, %/blocks.10/attn/Cast_7_output_0, %/blocks.10/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_6\"](%/blocks.10/attn/Range_1_output_0, %/blocks.10/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_8\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_9\"](%/blocks.10/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/attn/Div_1\"](%/blocks.10/attn/Cast_8_output_0, %/blocks.10/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_10\"](%/blocks.10/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_6\"](%/blocks.10/attn/Cast_10_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.10/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_7\"](%/blocks.10/attn/Range_1_output_0, %/blocks.10/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_11\"](%/blocks.10/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_7\"](%/blocks.10/attn/Cast_11_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.10/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_2\"](%/blocks.10/attn/Mul_6_output_0, %/blocks.10/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.10/attn/Sub_3\"](%/blocks.10/attn/Gather_2_output_0, %/blocks.10/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.10/attn/Cast_12\"](%/blocks.10/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/attn/Mul_8\"](%/blocks.10/attn/Cast_12_output_0, %/blocks.10/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_1\"](%/blocks.10/attn/Sub_2_output_0, %/blocks.10/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.10/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/attn/Cast_13\"](%/blocks.10/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_4\"](%blocks.10.attn.rel_pos_w, %/blocks.10/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.10/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_3\"](%/blocks.10/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_5\"](%/blocks.10/attn/Shape_3_output_0, %/blocks.10/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/attn/Shape_4\"](%/blocks.10/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.10/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/attn/Gather_6\"](%/blocks.10/attn/Shape_4_output_0, %/blocks.10/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_3812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_8\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3812), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_9\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3814), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_10\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3816), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_11\"](%/blocks.10/attn/Gather_6_output_0, %onnx::Unsqueeze_3818), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_2\"](%/blocks.10/attn/Unsqueeze_8_output_0, %/blocks.10/attn/Unsqueeze_9_output_0, %/blocks.10/attn/Unsqueeze_10_output_0, %/blocks.10/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.10/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_2\"](%/blocks.10/attn/Squeeze_output_0, %/blocks.10/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.10/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.10/attn/Einsum\"](%/blocks.10/attn/Reshape_2_output_0, %/blocks.10/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.10/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.10/attn/Einsum_1\"](%/blocks.10/attn/Reshape_2_output_0, %/blocks.10/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_3824 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_12\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3824), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_13\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3826), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_14\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3828), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_15\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3830), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_16\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3832), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_3\"](%/blocks.10/attn/Unsqueeze_12_output_0, %/blocks.10/attn/Unsqueeze_13_output_0, %/blocks.10/attn/Unsqueeze_14_output_0, %/blocks.10/attn/Unsqueeze_15_output_0, %/blocks.10/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_3\"](%/blocks.10/attn/MatMul_output_0, %/blocks.10/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.10/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_17\"](%/blocks.10/attn/Einsum_output_0, %/blocks.10/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_2\"](%/blocks.10/attn/Reshape_3_output_0, %/blocks.10/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.10/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_18\"](%/blocks.10/attn/Einsum_1_output_0, %/blocks.10/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.10/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/Add_3\"](%/blocks.10/attn/Add_2_output_0, %/blocks.10/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_3842 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_19\"](%/blocks.10/attn/Gather_5_output_0, %onnx::Unsqueeze_3842), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3844 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_20\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3844), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_21\"](%/blocks.10/attn/Mul_output_0, %onnx::Unsqueeze_3846), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_4\"](%/blocks.10/attn/Unsqueeze_19_output_0, %/blocks.10/attn/Unsqueeze_20_output_0, %/blocks.10/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.10/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_4\"](%/blocks.10/attn/Add_3_output_0, %/blocks.10/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.10/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.10/attn/Softmax\"](%/blocks.10/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.10/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/MatMul_1\"](%/blocks.10/attn/Softmax_output_0, %/blocks.10/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3852 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_22\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3852), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.10/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3856 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_23\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3856), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_24\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3858), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_5\"](%/blocks.10/attn/Unsqueeze_22_output_0, %/blocks.10/attn/Constant_28_output_0, %/blocks.10/attn/Unsqueeze_23_output_0, %/blocks.10/attn/Unsqueeze_24_output_0, %/blocks.10/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_5\"](%/blocks.10/attn/MatMul_1_output_0, %/blocks.10/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.10/attn/Transpose_2\"](%/blocks.10/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_3865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_25\"](%/blocks.10/attn/Gather_output_0, %onnx::Unsqueeze_3865), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3867 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_26\"](%/blocks.10/attn/Gather_1_output_0, %onnx::Unsqueeze_3867), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_3869 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/attn/Unsqueeze_27\"](%/blocks.10/attn/Gather_2_output_0, %onnx::Unsqueeze_3869), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.10/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/attn/Concat_6\"](%/blocks.10/attn/Unsqueeze_25_output_0, %/blocks.10/attn/Unsqueeze_26_output_0, %/blocks.10/attn/Unsqueeze_27_output_0, %/blocks.10/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/attn/Reshape_6\"](%/blocks.10/attn/Transpose_2_output_0, %/blocks.10/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.10/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/attn/proj/MatMul\"](%/blocks.10/attn/Reshape_6_output_0, %onnx::MatMul_5959), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/attn/proj/Add\"](%blocks.10.attn.proj.bias, %/blocks.10/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.10/Shape_5\"](%/blocks.10/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.10/Gather_5\"](%/blocks.10/Shape_5_output_0, %/blocks.10/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/Mul\"](%/blocks.10/Add_output_0, %/blocks.10/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.10/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_2\"](%/blocks.10/Mul_output_0, %/blocks.10/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_6\"](%/blocks.10/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_7\"](%/blocks.10/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_3\"](%/blocks.10/Cast_7_output_0, %/blocks.10/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_8\"](%/blocks.10/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_9\"](%/blocks.10/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.10/Div_4\"](%/blocks.10/Gather_5_output_0, %/blocks.10/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_10\"](%/blocks.10/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.10/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.10/Cast_11\"](%/blocks.10/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_3893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_9\"](%/blocks.10/Cast_11_output_0, %onnx::Unsqueeze_3893), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_10\"](%/blocks.10/Cast_3_output_0, %onnx::Unsqueeze_3895), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_11\"](%/blocks.10/Cast_5_output_0, %onnx::Unsqueeze_3897), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.10/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_5\"](%/blocks.10/Unsqueeze_9_output_0, %/blocks.10/Unsqueeze_10_output_0, %/blocks.10/Unsqueeze_11_output_0, %/blocks.10/Constant_36_output_0, %/blocks.10/Constant_37_output_0, %/blocks.10/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.10/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_4\"](%/blocks.10/attn/proj/Add_output_0, %/blocks.10/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.10/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.10/Transpose_2\"](%/blocks.10/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_3908 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_12\"](%/blocks.10/Cast_11_output_0, %onnx::Unsqueeze_3908), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3910 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_13\"](%/blocks.10/Add_output_0, %onnx::Unsqueeze_3910), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %onnx::Unsqueeze_3912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.10/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_14\"](%/blocks.10/Add_1_output_0, %onnx::Unsqueeze_3912), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.10/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10\n",
            "  %/blocks.10/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.10/Concat_6\"](%/blocks.10/Unsqueeze_12_output_0, %/blocks.10/Unsqueeze_13_output_0, %/blocks.10/Unsqueeze_14_output_0, %/blocks.10/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.10/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.10/Reshape_5\"](%/blocks.10/Transpose_2_output_0, %/blocks.10/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.10/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_15\"](%/blocks.10/Gather_output_0, %/blocks.10/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice_1\"](%/blocks.10/Reshape_5_output_0, %/blocks.10/Constant_41_output_0, %/blocks.10/Unsqueeze_15_output_0, %/blocks.10/Constant_40_output_0, %/blocks.10/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.10/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.10/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.10/Unsqueeze_16\"](%/blocks.10/Gather_1_output_0, %/blocks.10/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.10/Slice_2\"](%/blocks.10/Slice_1_output_0, %/blocks.10/Constant_45_output_0, %/blocks.10/Unsqueeze_16_output_0, %/blocks.10/Constant_44_output_0, %/blocks.10/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.10/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_2\"](%/blocks.9/Add_3_output_0, %/blocks.10/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.10/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.10/norm2/LayerNormalization\"](%/blocks.10/Add_2_output_0, %blocks.10.norm2.weight, %blocks.10.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.10/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/mlp/lin1/MatMul\"](%/blocks.10/norm2/LayerNormalization_output_0, %onnx::MatMul_5970), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/lin1/Add\"](%blocks.10.mlp.lin1.bias, %/blocks.10/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.10/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.10/mlp/act/Div\"](%/blocks.10/mlp/lin1/Add_output_0, %/blocks.10/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.10/mlp/act/Erf\"](%/blocks.10/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.10/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/act/Add\"](%/blocks.10/mlp/act/Erf_output_0, %/blocks.10/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/mlp/act/Mul\"](%/blocks.10/mlp/lin1/Add_output_0, %/blocks.10/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.10/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.10/mlp/act/Mul_1\"](%/blocks.10/mlp/act/Mul_output_0, %/blocks.10/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.10/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.10/mlp/lin2/MatMul\"](%/blocks.10/mlp/act/Mul_1_output_0, %onnx::MatMul_5971), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/mlp/lin2/Add\"](%blocks.10.mlp.lin2.bias, %/blocks.10/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.10/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.10/Add_3\"](%/blocks.10/Add_2_output_0, %/blocks.10/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.10 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.11/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.11/norm1/LayerNormalization\"](%/blocks.10/Add_3_output_0, %blocks.11.norm1.weight, %blocks.11.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.11/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather\"](%/blocks.11/Shape_output_0, %/blocks.11/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_1\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_1\"](%/blocks.11/Shape_1_output_0, %/blocks.11/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.11/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_2\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_2\"](%/blocks.11/Shape_2_output_0, %/blocks.11/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_3\"](%/blocks.11/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_3\"](%/blocks.11/Shape_3_output_0, %/blocks.11/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.11/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod\"](%/blocks.11/Gather_output_0, %/blocks.11/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub\"](%/blocks.11/Constant_5_output_0, %/blocks.11/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_1\"](%/blocks.11/Sub_output_0, %/blocks.11/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.11/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_2\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub_1\"](%/blocks.11/Constant_8_output_0, %/blocks.11/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.11/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.11/Mod_3\"](%/blocks.11/Sub_1_output_0, %/blocks.11/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.11/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze\"](%/blocks.11/Mod_3_output_0, %onnx::Unsqueeze_3984), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3988 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_1\"](%/blocks.11/Mod_1_output_0, %onnx::Unsqueeze_3988), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat\"](%/blocks.11/Constant_10_output_0, %/blocks.11/Constant_11_output_0, %/blocks.11/Constant_12_output_0, %/blocks.11/Unsqueeze_output_0, %/blocks.11/Constant_13_output_0, %/blocks.11/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_3997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_2\"](%/blocks.11/Mod_3_output_0, %onnx::Unsqueeze_3997), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_3\"](%/blocks.11/Mod_1_output_0, %onnx::Unsqueeze_4001), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_1\"](%/blocks.11/Constant_14_output_0, %/blocks.11/Constant_15_output_0, %/blocks.11/Constant_16_output_0, %/blocks.11/Unsqueeze_2_output_0, %/blocks.11/Constant_17_output_0, %/blocks.11/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_4\"](%/blocks.11/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_4\"](%/blocks.11/Shape_4_output_0, %/blocks.11/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.11/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/Sub_2\"](%/blocks.11/Constant_19_output_0, %/blocks.11/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast\"](%/blocks.11/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.11/ConstantOfShape\"](%/blocks.11/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_2\"](%/blocks.11/Cast_output_0, %/blocks.11/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.11/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape\"](%/blocks.11/Concat_2_output_0, %/blocks.11/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.11/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice\"](%/blocks.11/Reshape_output_0, %/blocks.11/Constant_22_output_0, %/blocks.11/Constant_23_output_0, %/blocks.11/Constant_21_output_0, %/blocks.11/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.11/Transpose\"](%/blocks.11/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_1\"](%/blocks.11/Transpose_output_0, %/blocks.11/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_1\"](%/blocks.11/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.11/Pad\"](%/blocks.11/norm1/LayerNormalization_output_0, %/blocks.11/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.11/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add\"](%/blocks.11/Gather_output_0, %/blocks.11/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.11/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_1\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.11/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div\"](%/blocks.11/Add_output_0, %/blocks.11/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_2\"](%/blocks.11/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_3\"](%/blocks.11/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_1\"](%/blocks.11/Add_1_output_0, %/blocks.11/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_4\"](%/blocks.11/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_5\"](%/blocks.11/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4036 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_4\"](%/blocks.11/Gather_2_output_0, %onnx::Unsqueeze_4036), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4038 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_5\"](%/blocks.11/Cast_3_output_0, %onnx::Unsqueeze_4038), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4042 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_6\"](%/blocks.11/Cast_5_output_0, %onnx::Unsqueeze_4042), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4046 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_7\"](%/blocks.11/Gather_3_output_0, %onnx::Unsqueeze_4046), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_3\"](%/blocks.11/Unsqueeze_4_output_0, %/blocks.11/Unsqueeze_5_output_0, %/blocks.11/Constant_28_output_0, %/blocks.11/Unsqueeze_6_output_0, %/blocks.11/Constant_29_output_0, %/blocks.11/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.11/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_2\"](%/blocks.11/Pad_output_0, %/blocks.11/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.11/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.11/Transpose_1\"](%/blocks.11/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_8\"](%/blocks.11/Gather_3_output_0, %onnx::Unsqueeze_4057), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_4\"](%/blocks.11/Constant_30_output_0, %/blocks.11/Constant_31_output_0, %/blocks.11/Constant_32_output_0, %/blocks.11/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_3\"](%/blocks.11/Transpose_1_output_0, %/blocks.11/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.11/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather\"](%/blocks.11/attn/Shape_output_0, %/blocks.11/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_1\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_1\"](%/blocks.11/attn/Shape_1_output_0, %/blocks.11/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_2\"](%/blocks.11/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_2\"](%/blocks.11/attn/Shape_2_output_0, %/blocks.11/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.11/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/qkv/MatMul\"](%/blocks.11/Reshape_3_output_0, %onnx::MatMul_5986), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/qkv/Add\"](%blocks.11.attn.qkv.bias, %/blocks.11/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul\"](%/blocks.11/attn/Gather_1_output_0, %/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4074), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4076 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_1\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4076), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat\"](%/blocks.11/attn/Unsqueeze_output_0, %/blocks.11/attn/Unsqueeze_1_output_0, %/blocks.11/attn/Constant_3_output_0, %/blocks.11/attn/Constant_4_output_0, %/blocks.11/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape\"](%/blocks.11/attn/qkv/Add_output_0, %/blocks.11/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.11/attn/Transpose\"](%/blocks.11/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.11/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_1\"](%/blocks.11/attn/Gather_output_0, %/blocks.11/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4091 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_2\"](%/blocks.11/attn/Mul_1_output_0, %onnx::Unsqueeze_4091), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_3\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4093), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_1\"](%/blocks.11/attn/Constant_7_output_0, %/blocks.11/attn/Unsqueeze_2_output_0, %/blocks.11/attn/Unsqueeze_3_output_0, %/blocks.11/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_1\"](%/blocks.11/attn/Transpose_output_0, %/blocks.11/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.11/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.11/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.11/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.11/attn/Split\"](%/blocks.11/attn/Reshape_1_output_0, %/blocks.11/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze\"](%/blocks.11/attn/Split_output_0, %/blocks.11/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze_1\"](%/blocks.11/attn/Split_output_1, %/blocks.11/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.11/attn/Squeeze_2\"](%/blocks.11/attn/Split_output_2, %/blocks.11/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.11/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.11/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_2\"](%/blocks.11/attn/Squeeze_output_0, %/blocks.11/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.11/attn/Transpose_1\"](%/blocks.11/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/MatMul\"](%/blocks.11/attn/Mul_2_output_0, %/blocks.11/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.11/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.11/attn/Range\"](%/blocks.11/attn/Constant_14_output_0, %/blocks.11/attn/Cast_output_0, %/blocks.11/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_4\"](%/blocks.11/attn/Range_output_0, %/blocks.11/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_1\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_2\"](%/blocks.11/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/attn/Div\"](%/blocks.11/attn/Cast_1_output_0, %/blocks.11/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_3\"](%/blocks.11/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_3\"](%/blocks.11/attn/Cast_3_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_5\"](%/blocks.11/attn/Range_output_0, %/blocks.11/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_4\"](%/blocks.11/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_4\"](%/blocks.11/attn/Cast_4_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub\"](%/blocks.11/attn/Mul_3_output_0, %/blocks.11/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_1\"](%/blocks.11/attn/Gather_1_output_0, %/blocks.11/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_5\"](%/blocks.11/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_5\"](%/blocks.11/attn/Cast_5_output_0, %/blocks.11/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add\"](%/blocks.11/attn/Sub_output_0, %/blocks.11/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_6\"](%/blocks.11/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_3\"](%blocks.11.attn.rel_pos_h, %/blocks.11/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_7\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.11/attn/Range_1\"](%/blocks.11/attn/Constant_19_output_0, %/blocks.11/attn/Cast_7_output_0, %/blocks.11/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_6\"](%/blocks.11/attn/Range_1_output_0, %/blocks.11/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_8\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_9\"](%/blocks.11/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/attn/Div_1\"](%/blocks.11/attn/Cast_8_output_0, %/blocks.11/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_10\"](%/blocks.11/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_6\"](%/blocks.11/attn/Cast_10_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.11/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_7\"](%/blocks.11/attn/Range_1_output_0, %/blocks.11/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_11\"](%/blocks.11/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_7\"](%/blocks.11/attn/Cast_11_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.11/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_2\"](%/blocks.11/attn/Mul_6_output_0, %/blocks.11/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.11/attn/Sub_3\"](%/blocks.11/attn/Gather_2_output_0, %/blocks.11/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.11/attn/Cast_12\"](%/blocks.11/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/attn/Mul_8\"](%/blocks.11/attn/Cast_12_output_0, %/blocks.11/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_1\"](%/blocks.11/attn/Sub_2_output_0, %/blocks.11/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.11/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/attn/Cast_13\"](%/blocks.11/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_4\"](%blocks.11.attn.rel_pos_w, %/blocks.11/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.11/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_3\"](%/blocks.11/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_5\"](%/blocks.11/attn/Shape_3_output_0, %/blocks.11/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/attn/Shape_4\"](%/blocks.11/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.11/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/attn/Gather_6\"](%/blocks.11/attn/Shape_4_output_0, %/blocks.11/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_8\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4165), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_9\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4167), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4169 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_10\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4169), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4171 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_11\"](%/blocks.11/attn/Gather_6_output_0, %onnx::Unsqueeze_4171), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_2\"](%/blocks.11/attn/Unsqueeze_8_output_0, %/blocks.11/attn/Unsqueeze_9_output_0, %/blocks.11/attn/Unsqueeze_10_output_0, %/blocks.11/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.11/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_2\"](%/blocks.11/attn/Squeeze_output_0, %/blocks.11/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.11/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.11/attn/Einsum\"](%/blocks.11/attn/Reshape_2_output_0, %/blocks.11/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.11/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.11/attn/Einsum_1\"](%/blocks.11/attn/Reshape_2_output_0, %/blocks.11/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4177 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_12\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4177), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_13\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4179), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4181 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_14\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4181), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_15\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4183), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_16\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4185), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_3\"](%/blocks.11/attn/Unsqueeze_12_output_0, %/blocks.11/attn/Unsqueeze_13_output_0, %/blocks.11/attn/Unsqueeze_14_output_0, %/blocks.11/attn/Unsqueeze_15_output_0, %/blocks.11/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_3\"](%/blocks.11/attn/MatMul_output_0, %/blocks.11/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.11/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_17\"](%/blocks.11/attn/Einsum_output_0, %/blocks.11/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_2\"](%/blocks.11/attn/Reshape_3_output_0, %/blocks.11/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.11/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_18\"](%/blocks.11/attn/Einsum_1_output_0, %/blocks.11/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.11/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/Add_3\"](%/blocks.11/attn/Add_2_output_0, %/blocks.11/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4195 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_19\"](%/blocks.11/attn/Gather_5_output_0, %onnx::Unsqueeze_4195), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_20\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4197), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_21\"](%/blocks.11/attn/Mul_output_0, %onnx::Unsqueeze_4199), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_4\"](%/blocks.11/attn/Unsqueeze_19_output_0, %/blocks.11/attn/Unsqueeze_20_output_0, %/blocks.11/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.11/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_4\"](%/blocks.11/attn/Add_3_output_0, %/blocks.11/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.11/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.11/attn/Softmax\"](%/blocks.11/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.11/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/MatMul_1\"](%/blocks.11/attn/Softmax_output_0, %/blocks.11/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4205 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_22\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4205), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.11/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4209 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_23\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4209), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4211 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_24\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4211), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_5\"](%/blocks.11/attn/Unsqueeze_22_output_0, %/blocks.11/attn/Constant_28_output_0, %/blocks.11/attn/Unsqueeze_23_output_0, %/blocks.11/attn/Unsqueeze_24_output_0, %/blocks.11/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_5\"](%/blocks.11/attn/MatMul_1_output_0, %/blocks.11/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.11/attn/Transpose_2\"](%/blocks.11/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_25\"](%/blocks.11/attn/Gather_output_0, %onnx::Unsqueeze_4218), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4220 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_26\"](%/blocks.11/attn/Gather_1_output_0, %onnx::Unsqueeze_4220), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4222 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/attn/Unsqueeze_27\"](%/blocks.11/attn/Gather_2_output_0, %onnx::Unsqueeze_4222), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.11/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/attn/Concat_6\"](%/blocks.11/attn/Unsqueeze_25_output_0, %/blocks.11/attn/Unsqueeze_26_output_0, %/blocks.11/attn/Unsqueeze_27_output_0, %/blocks.11/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/attn/Reshape_6\"](%/blocks.11/attn/Transpose_2_output_0, %/blocks.11/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.11/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/attn/proj/MatMul\"](%/blocks.11/attn/Reshape_6_output_0, %onnx::MatMul_5995), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/attn/proj/Add\"](%blocks.11.attn.proj.bias, %/blocks.11/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.11/Shape_5\"](%/blocks.11/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.11/Gather_5\"](%/blocks.11/Shape_5_output_0, %/blocks.11/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/Mul\"](%/blocks.11/Add_output_0, %/blocks.11/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.11/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_2\"](%/blocks.11/Mul_output_0, %/blocks.11/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_6\"](%/blocks.11/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_7\"](%/blocks.11/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_3\"](%/blocks.11/Cast_7_output_0, %/blocks.11/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_8\"](%/blocks.11/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_9\"](%/blocks.11/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.11/Div_4\"](%/blocks.11/Gather_5_output_0, %/blocks.11/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_10\"](%/blocks.11/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.11/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.11/Cast_11\"](%/blocks.11/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4246 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_9\"](%/blocks.11/Cast_11_output_0, %onnx::Unsqueeze_4246), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4248 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_10\"](%/blocks.11/Cast_3_output_0, %onnx::Unsqueeze_4248), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4250 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_11\"](%/blocks.11/Cast_5_output_0, %onnx::Unsqueeze_4250), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.11/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_5\"](%/blocks.11/Unsqueeze_9_output_0, %/blocks.11/Unsqueeze_10_output_0, %/blocks.11/Unsqueeze_11_output_0, %/blocks.11/Constant_36_output_0, %/blocks.11/Constant_37_output_0, %/blocks.11/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.11/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_4\"](%/blocks.11/attn/proj/Add_output_0, %/blocks.11/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.11/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.11/Transpose_2\"](%/blocks.11/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_12\"](%/blocks.11/Cast_11_output_0, %onnx::Unsqueeze_4261), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_13\"](%/blocks.11/Add_output_0, %onnx::Unsqueeze_4263), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %onnx::Unsqueeze_4265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.11/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_14\"](%/blocks.11/Add_1_output_0, %onnx::Unsqueeze_4265), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.11/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11\n",
            "  %/blocks.11/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.11/Concat_6\"](%/blocks.11/Unsqueeze_12_output_0, %/blocks.11/Unsqueeze_13_output_0, %/blocks.11/Unsqueeze_14_output_0, %/blocks.11/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.11/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.11/Reshape_5\"](%/blocks.11/Transpose_2_output_0, %/blocks.11/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.11/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_15\"](%/blocks.11/Gather_output_0, %/blocks.11/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice_1\"](%/blocks.11/Reshape_5_output_0, %/blocks.11/Constant_41_output_0, %/blocks.11/Unsqueeze_15_output_0, %/blocks.11/Constant_40_output_0, %/blocks.11/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.11/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.11/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.11/Unsqueeze_16\"](%/blocks.11/Gather_1_output_0, %/blocks.11/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.11/Slice_2\"](%/blocks.11/Slice_1_output_0, %/blocks.11/Constant_45_output_0, %/blocks.11/Unsqueeze_16_output_0, %/blocks.11/Constant_44_output_0, %/blocks.11/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.11/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_2\"](%/blocks.10/Add_3_output_0, %/blocks.11/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.11/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.11/norm2/LayerNormalization\"](%/blocks.11/Add_2_output_0, %blocks.11.norm2.weight, %blocks.11.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.11/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/mlp/lin1/MatMul\"](%/blocks.11/norm2/LayerNormalization_output_0, %onnx::MatMul_6006), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/lin1/Add\"](%blocks.11.mlp.lin1.bias, %/blocks.11/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.11/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.11/mlp/act/Div\"](%/blocks.11/mlp/lin1/Add_output_0, %/blocks.11/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.11/mlp/act/Erf\"](%/blocks.11/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.11/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/act/Add\"](%/blocks.11/mlp/act/Erf_output_0, %/blocks.11/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/mlp/act/Mul\"](%/blocks.11/mlp/lin1/Add_output_0, %/blocks.11/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.11/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.11/mlp/act/Mul_1\"](%/blocks.11/mlp/act/Mul_output_0, %/blocks.11/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.11/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.11/mlp/lin2/MatMul\"](%/blocks.11/mlp/act/Mul_1_output_0, %onnx::MatMul_6007), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/mlp/lin2/Add\"](%blocks.11.mlp.lin2.bias, %/blocks.11/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.11/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.11/Add_3\"](%/blocks.11/Add_2_output_0, %/blocks.11/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.11 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.12/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.12/norm1/LayerNormalization\"](%/blocks.11/Add_3_output_0, %blocks.12.norm1.weight, %blocks.12.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.12/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather\"](%/blocks.12/Shape_output_0, %/blocks.12/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_1\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_1\"](%/blocks.12/Shape_1_output_0, %/blocks.12/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.12/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_2\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_2\"](%/blocks.12/Shape_2_output_0, %/blocks.12/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_3\"](%/blocks.12/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_3\"](%/blocks.12/Shape_3_output_0, %/blocks.12/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.12/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod\"](%/blocks.12/Gather_output_0, %/blocks.12/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub\"](%/blocks.12/Constant_5_output_0, %/blocks.12/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_1\"](%/blocks.12/Sub_output_0, %/blocks.12/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.12/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_2\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub_1\"](%/blocks.12/Constant_8_output_0, %/blocks.12/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.12/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.12/Mod_3\"](%/blocks.12/Sub_1_output_0, %/blocks.12/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.12/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze\"](%/blocks.12/Mod_3_output_0, %onnx::Unsqueeze_4337), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4341 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_1\"](%/blocks.12/Mod_1_output_0, %onnx::Unsqueeze_4341), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat\"](%/blocks.12/Constant_10_output_0, %/blocks.12/Constant_11_output_0, %/blocks.12/Constant_12_output_0, %/blocks.12/Unsqueeze_output_0, %/blocks.12/Constant_13_output_0, %/blocks.12/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4350 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_2\"](%/blocks.12/Mod_3_output_0, %onnx::Unsqueeze_4350), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_3\"](%/blocks.12/Mod_1_output_0, %onnx::Unsqueeze_4354), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_1\"](%/blocks.12/Constant_14_output_0, %/blocks.12/Constant_15_output_0, %/blocks.12/Constant_16_output_0, %/blocks.12/Unsqueeze_2_output_0, %/blocks.12/Constant_17_output_0, %/blocks.12/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_4\"](%/blocks.12/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_4\"](%/blocks.12/Shape_4_output_0, %/blocks.12/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.12/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/Sub_2\"](%/blocks.12/Constant_19_output_0, %/blocks.12/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast\"](%/blocks.12/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.12/ConstantOfShape\"](%/blocks.12/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_2\"](%/blocks.12/Cast_output_0, %/blocks.12/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.12/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape\"](%/blocks.12/Concat_2_output_0, %/blocks.12/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.12/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice\"](%/blocks.12/Reshape_output_0, %/blocks.12/Constant_22_output_0, %/blocks.12/Constant_23_output_0, %/blocks.12/Constant_21_output_0, %/blocks.12/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.12/Transpose\"](%/blocks.12/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_1\"](%/blocks.12/Transpose_output_0, %/blocks.12/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_1\"](%/blocks.12/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.12/Pad\"](%/blocks.12/norm1/LayerNormalization_output_0, %/blocks.12/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.12/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add\"](%/blocks.12/Gather_output_0, %/blocks.12/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.12/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_1\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.12/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div\"](%/blocks.12/Add_output_0, %/blocks.12/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_2\"](%/blocks.12/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_3\"](%/blocks.12/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_1\"](%/blocks.12/Add_1_output_0, %/blocks.12/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_4\"](%/blocks.12/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_5\"](%/blocks.12/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4389 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_4\"](%/blocks.12/Gather_2_output_0, %onnx::Unsqueeze_4389), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4391 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_5\"](%/blocks.12/Cast_3_output_0, %onnx::Unsqueeze_4391), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4395 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_6\"](%/blocks.12/Cast_5_output_0, %onnx::Unsqueeze_4395), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4399 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_7\"](%/blocks.12/Gather_3_output_0, %onnx::Unsqueeze_4399), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_3\"](%/blocks.12/Unsqueeze_4_output_0, %/blocks.12/Unsqueeze_5_output_0, %/blocks.12/Constant_28_output_0, %/blocks.12/Unsqueeze_6_output_0, %/blocks.12/Constant_29_output_0, %/blocks.12/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.12/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_2\"](%/blocks.12/Pad_output_0, %/blocks.12/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.12/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.12/Transpose_1\"](%/blocks.12/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_8\"](%/blocks.12/Gather_3_output_0, %onnx::Unsqueeze_4410), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_4\"](%/blocks.12/Constant_30_output_0, %/blocks.12/Constant_31_output_0, %/blocks.12/Constant_32_output_0, %/blocks.12/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_3\"](%/blocks.12/Transpose_1_output_0, %/blocks.12/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.12/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather\"](%/blocks.12/attn/Shape_output_0, %/blocks.12/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_1\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_1\"](%/blocks.12/attn/Shape_1_output_0, %/blocks.12/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_2\"](%/blocks.12/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_2\"](%/blocks.12/attn/Shape_2_output_0, %/blocks.12/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.12/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/qkv/MatMul\"](%/blocks.12/Reshape_3_output_0, %onnx::MatMul_6022), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/qkv/Add\"](%blocks.12.attn.qkv.bias, %/blocks.12/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul\"](%/blocks.12/attn/Gather_1_output_0, %/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4427 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4427), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4429 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_1\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4429), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat\"](%/blocks.12/attn/Unsqueeze_output_0, %/blocks.12/attn/Unsqueeze_1_output_0, %/blocks.12/attn/Constant_3_output_0, %/blocks.12/attn/Constant_4_output_0, %/blocks.12/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape\"](%/blocks.12/attn/qkv/Add_output_0, %/blocks.12/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.12/attn/Transpose\"](%/blocks.12/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.12/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_1\"](%/blocks.12/attn/Gather_output_0, %/blocks.12/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4444 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_2\"](%/blocks.12/attn/Mul_1_output_0, %onnx::Unsqueeze_4444), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_3\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4446), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_1\"](%/blocks.12/attn/Constant_7_output_0, %/blocks.12/attn/Unsqueeze_2_output_0, %/blocks.12/attn/Unsqueeze_3_output_0, %/blocks.12/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_1\"](%/blocks.12/attn/Transpose_output_0, %/blocks.12/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.12/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.12/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.12/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.12/attn/Split\"](%/blocks.12/attn/Reshape_1_output_0, %/blocks.12/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze\"](%/blocks.12/attn/Split_output_0, %/blocks.12/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze_1\"](%/blocks.12/attn/Split_output_1, %/blocks.12/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.12/attn/Squeeze_2\"](%/blocks.12/attn/Split_output_2, %/blocks.12/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.12/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.12/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_2\"](%/blocks.12/attn/Squeeze_output_0, %/blocks.12/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.12/attn/Transpose_1\"](%/blocks.12/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/MatMul\"](%/blocks.12/attn/Mul_2_output_0, %/blocks.12/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.12/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.12/attn/Range\"](%/blocks.12/attn/Constant_14_output_0, %/blocks.12/attn/Cast_output_0, %/blocks.12/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_4\"](%/blocks.12/attn/Range_output_0, %/blocks.12/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_1\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_2\"](%/blocks.12/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/attn/Div\"](%/blocks.12/attn/Cast_1_output_0, %/blocks.12/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_3\"](%/blocks.12/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_3\"](%/blocks.12/attn/Cast_3_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_5\"](%/blocks.12/attn/Range_output_0, %/blocks.12/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_4\"](%/blocks.12/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_4\"](%/blocks.12/attn/Cast_4_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub\"](%/blocks.12/attn/Mul_3_output_0, %/blocks.12/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_1\"](%/blocks.12/attn/Gather_1_output_0, %/blocks.12/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_5\"](%/blocks.12/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_5\"](%/blocks.12/attn/Cast_5_output_0, %/blocks.12/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add\"](%/blocks.12/attn/Sub_output_0, %/blocks.12/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_6\"](%/blocks.12/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_3\"](%blocks.12.attn.rel_pos_h, %/blocks.12/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_7\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.12/attn/Range_1\"](%/blocks.12/attn/Constant_19_output_0, %/blocks.12/attn/Cast_7_output_0, %/blocks.12/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_6\"](%/blocks.12/attn/Range_1_output_0, %/blocks.12/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_8\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_9\"](%/blocks.12/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/attn/Div_1\"](%/blocks.12/attn/Cast_8_output_0, %/blocks.12/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_10\"](%/blocks.12/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_6\"](%/blocks.12/attn/Cast_10_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.12/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_7\"](%/blocks.12/attn/Range_1_output_0, %/blocks.12/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_11\"](%/blocks.12/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_7\"](%/blocks.12/attn/Cast_11_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.12/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_2\"](%/blocks.12/attn/Mul_6_output_0, %/blocks.12/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.12/attn/Sub_3\"](%/blocks.12/attn/Gather_2_output_0, %/blocks.12/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.12/attn/Cast_12\"](%/blocks.12/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/attn/Mul_8\"](%/blocks.12/attn/Cast_12_output_0, %/blocks.12/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_1\"](%/blocks.12/attn/Sub_2_output_0, %/blocks.12/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.12/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/attn/Cast_13\"](%/blocks.12/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_4\"](%blocks.12.attn.rel_pos_w, %/blocks.12/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.12/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_3\"](%/blocks.12/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_5\"](%/blocks.12/attn/Shape_3_output_0, %/blocks.12/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/attn/Shape_4\"](%/blocks.12/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.12/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/attn/Gather_6\"](%/blocks.12/attn/Shape_4_output_0, %/blocks.12/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4518 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_8\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4518), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_9\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4520), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_10\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4522), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4524 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_11\"](%/blocks.12/attn/Gather_6_output_0, %onnx::Unsqueeze_4524), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_2\"](%/blocks.12/attn/Unsqueeze_8_output_0, %/blocks.12/attn/Unsqueeze_9_output_0, %/blocks.12/attn/Unsqueeze_10_output_0, %/blocks.12/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.12/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_2\"](%/blocks.12/attn/Squeeze_output_0, %/blocks.12/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.12/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.12/attn/Einsum\"](%/blocks.12/attn/Reshape_2_output_0, %/blocks.12/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.12/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.12/attn/Einsum_1\"](%/blocks.12/attn/Reshape_2_output_0, %/blocks.12/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_12\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4530), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_13\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4532), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_14\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4534), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_15\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4536), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_16\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4538), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_3\"](%/blocks.12/attn/Unsqueeze_12_output_0, %/blocks.12/attn/Unsqueeze_13_output_0, %/blocks.12/attn/Unsqueeze_14_output_0, %/blocks.12/attn/Unsqueeze_15_output_0, %/blocks.12/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_3\"](%/blocks.12/attn/MatMul_output_0, %/blocks.12/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.12/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_17\"](%/blocks.12/attn/Einsum_output_0, %/blocks.12/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_2\"](%/blocks.12/attn/Reshape_3_output_0, %/blocks.12/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.12/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_18\"](%/blocks.12/attn/Einsum_1_output_0, %/blocks.12/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.12/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/Add_3\"](%/blocks.12/attn/Add_2_output_0, %/blocks.12/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4548 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_19\"](%/blocks.12/attn/Gather_5_output_0, %onnx::Unsqueeze_4548), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_20\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4550), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_21\"](%/blocks.12/attn/Mul_output_0, %onnx::Unsqueeze_4552), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_4\"](%/blocks.12/attn/Unsqueeze_19_output_0, %/blocks.12/attn/Unsqueeze_20_output_0, %/blocks.12/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.12/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_4\"](%/blocks.12/attn/Add_3_output_0, %/blocks.12/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.12/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.12/attn/Softmax\"](%/blocks.12/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.12/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/MatMul_1\"](%/blocks.12/attn/Softmax_output_0, %/blocks.12/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4558 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_22\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4558), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.12/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_23\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4562), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_24\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4564), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_5\"](%/blocks.12/attn/Unsqueeze_22_output_0, %/blocks.12/attn/Constant_28_output_0, %/blocks.12/attn/Unsqueeze_23_output_0, %/blocks.12/attn/Unsqueeze_24_output_0, %/blocks.12/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_5\"](%/blocks.12/attn/MatMul_1_output_0, %/blocks.12/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.12/attn/Transpose_2\"](%/blocks.12/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_25\"](%/blocks.12/attn/Gather_output_0, %onnx::Unsqueeze_4571), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_26\"](%/blocks.12/attn/Gather_1_output_0, %onnx::Unsqueeze_4573), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/attn/Unsqueeze_27\"](%/blocks.12/attn/Gather_2_output_0, %onnx::Unsqueeze_4575), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.12/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/attn/Concat_6\"](%/blocks.12/attn/Unsqueeze_25_output_0, %/blocks.12/attn/Unsqueeze_26_output_0, %/blocks.12/attn/Unsqueeze_27_output_0, %/blocks.12/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/attn/Reshape_6\"](%/blocks.12/attn/Transpose_2_output_0, %/blocks.12/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.12/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/attn/proj/MatMul\"](%/blocks.12/attn/Reshape_6_output_0, %onnx::MatMul_6031), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/attn/proj/Add\"](%blocks.12.attn.proj.bias, %/blocks.12/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.12/Shape_5\"](%/blocks.12/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.12/Gather_5\"](%/blocks.12/Shape_5_output_0, %/blocks.12/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/Mul\"](%/blocks.12/Add_output_0, %/blocks.12/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.12/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_2\"](%/blocks.12/Mul_output_0, %/blocks.12/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_6\"](%/blocks.12/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_7\"](%/blocks.12/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_3\"](%/blocks.12/Cast_7_output_0, %/blocks.12/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_8\"](%/blocks.12/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_9\"](%/blocks.12/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.12/Div_4\"](%/blocks.12/Gather_5_output_0, %/blocks.12/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_10\"](%/blocks.12/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.12/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.12/Cast_11\"](%/blocks.12/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_9\"](%/blocks.12/Cast_11_output_0, %onnx::Unsqueeze_4599), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_10\"](%/blocks.12/Cast_3_output_0, %onnx::Unsqueeze_4601), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4603 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_11\"](%/blocks.12/Cast_5_output_0, %onnx::Unsqueeze_4603), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.12/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_5\"](%/blocks.12/Unsqueeze_9_output_0, %/blocks.12/Unsqueeze_10_output_0, %/blocks.12/Unsqueeze_11_output_0, %/blocks.12/Constant_36_output_0, %/blocks.12/Constant_37_output_0, %/blocks.12/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.12/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_4\"](%/blocks.12/attn/proj/Add_output_0, %/blocks.12/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.12/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.12/Transpose_2\"](%/blocks.12/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4614 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_12\"](%/blocks.12/Cast_11_output_0, %onnx::Unsqueeze_4614), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4616 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_13\"](%/blocks.12/Add_output_0, %onnx::Unsqueeze_4616), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %onnx::Unsqueeze_4618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.12/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_14\"](%/blocks.12/Add_1_output_0, %onnx::Unsqueeze_4618), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.12/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12\n",
            "  %/blocks.12/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.12/Concat_6\"](%/blocks.12/Unsqueeze_12_output_0, %/blocks.12/Unsqueeze_13_output_0, %/blocks.12/Unsqueeze_14_output_0, %/blocks.12/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.12/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.12/Reshape_5\"](%/blocks.12/Transpose_2_output_0, %/blocks.12/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.12/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_15\"](%/blocks.12/Gather_output_0, %/blocks.12/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice_1\"](%/blocks.12/Reshape_5_output_0, %/blocks.12/Constant_41_output_0, %/blocks.12/Unsqueeze_15_output_0, %/blocks.12/Constant_40_output_0, %/blocks.12/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.12/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.12/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.12/Unsqueeze_16\"](%/blocks.12/Gather_1_output_0, %/blocks.12/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.12/Slice_2\"](%/blocks.12/Slice_1_output_0, %/blocks.12/Constant_45_output_0, %/blocks.12/Unsqueeze_16_output_0, %/blocks.12/Constant_44_output_0, %/blocks.12/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.12/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_2\"](%/blocks.11/Add_3_output_0, %/blocks.12/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.12/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.12/norm2/LayerNormalization\"](%/blocks.12/Add_2_output_0, %blocks.12.norm2.weight, %blocks.12.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.12/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/mlp/lin1/MatMul\"](%/blocks.12/norm2/LayerNormalization_output_0, %onnx::MatMul_6042), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/lin1/Add\"](%blocks.12.mlp.lin1.bias, %/blocks.12/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.12/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.12/mlp/act/Div\"](%/blocks.12/mlp/lin1/Add_output_0, %/blocks.12/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.12/mlp/act/Erf\"](%/blocks.12/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.12/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/act/Add\"](%/blocks.12/mlp/act/Erf_output_0, %/blocks.12/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/mlp/act/Mul\"](%/blocks.12/mlp/lin1/Add_output_0, %/blocks.12/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.12/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.12/mlp/act/Mul_1\"](%/blocks.12/mlp/act/Mul_output_0, %/blocks.12/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.12/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.12/mlp/lin2/MatMul\"](%/blocks.12/mlp/act/Mul_1_output_0, %onnx::MatMul_6043), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/mlp/lin2/Add\"](%blocks.12.mlp.lin2.bias, %/blocks.12/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.12/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.12/Add_3\"](%/blocks.12/Add_2_output_0, %/blocks.12/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.12 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.13/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.13/norm1/LayerNormalization\"](%/blocks.12/Add_3_output_0, %blocks.13.norm1.weight, %blocks.13.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.13/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather\"](%/blocks.13/Shape_output_0, %/blocks.13/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_1\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_1\"](%/blocks.13/Shape_1_output_0, %/blocks.13/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.13/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_2\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_2\"](%/blocks.13/Shape_2_output_0, %/blocks.13/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_3\"](%/blocks.13/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_3\"](%/blocks.13/Shape_3_output_0, %/blocks.13/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.13/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod\"](%/blocks.13/Gather_output_0, %/blocks.13/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub\"](%/blocks.13/Constant_5_output_0, %/blocks.13/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_1\"](%/blocks.13/Sub_output_0, %/blocks.13/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.13/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_2\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub_1\"](%/blocks.13/Constant_8_output_0, %/blocks.13/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.13/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.13/Mod_3\"](%/blocks.13/Sub_1_output_0, %/blocks.13/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.13/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze\"](%/blocks.13/Mod_3_output_0, %onnx::Unsqueeze_4690), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4694 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_1\"](%/blocks.13/Mod_1_output_0, %onnx::Unsqueeze_4694), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat\"](%/blocks.13/Constant_10_output_0, %/blocks.13/Constant_11_output_0, %/blocks.13/Constant_12_output_0, %/blocks.13/Unsqueeze_output_0, %/blocks.13/Constant_13_output_0, %/blocks.13/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_2\"](%/blocks.13/Mod_3_output_0, %onnx::Unsqueeze_4703), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_3\"](%/blocks.13/Mod_1_output_0, %onnx::Unsqueeze_4707), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_1\"](%/blocks.13/Constant_14_output_0, %/blocks.13/Constant_15_output_0, %/blocks.13/Constant_16_output_0, %/blocks.13/Unsqueeze_2_output_0, %/blocks.13/Constant_17_output_0, %/blocks.13/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_4\"](%/blocks.13/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_4\"](%/blocks.13/Shape_4_output_0, %/blocks.13/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.13/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/Sub_2\"](%/blocks.13/Constant_19_output_0, %/blocks.13/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast\"](%/blocks.13/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.13/ConstantOfShape\"](%/blocks.13/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_2\"](%/blocks.13/Cast_output_0, %/blocks.13/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.13/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape\"](%/blocks.13/Concat_2_output_0, %/blocks.13/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.13/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice\"](%/blocks.13/Reshape_output_0, %/blocks.13/Constant_22_output_0, %/blocks.13/Constant_23_output_0, %/blocks.13/Constant_21_output_0, %/blocks.13/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.13/Transpose\"](%/blocks.13/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_1\"](%/blocks.13/Transpose_output_0, %/blocks.13/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_1\"](%/blocks.13/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.13/Pad\"](%/blocks.13/norm1/LayerNormalization_output_0, %/blocks.13/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.13/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add\"](%/blocks.13/Gather_output_0, %/blocks.13/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.13/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_1\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.13/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div\"](%/blocks.13/Add_output_0, %/blocks.13/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_2\"](%/blocks.13/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_3\"](%/blocks.13/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_1\"](%/blocks.13/Add_1_output_0, %/blocks.13/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_4\"](%/blocks.13/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_5\"](%/blocks.13/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4742 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_4\"](%/blocks.13/Gather_2_output_0, %onnx::Unsqueeze_4742), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4744 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_5\"](%/blocks.13/Cast_3_output_0, %onnx::Unsqueeze_4744), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4748 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_6\"](%/blocks.13/Cast_5_output_0, %onnx::Unsqueeze_4748), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4752 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_7\"](%/blocks.13/Gather_3_output_0, %onnx::Unsqueeze_4752), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_3\"](%/blocks.13/Unsqueeze_4_output_0, %/blocks.13/Unsqueeze_5_output_0, %/blocks.13/Constant_28_output_0, %/blocks.13/Unsqueeze_6_output_0, %/blocks.13/Constant_29_output_0, %/blocks.13/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.13/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_2\"](%/blocks.13/Pad_output_0, %/blocks.13/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.13/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.13/Transpose_1\"](%/blocks.13/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_8\"](%/blocks.13/Gather_3_output_0, %onnx::Unsqueeze_4763), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_4\"](%/blocks.13/Constant_30_output_0, %/blocks.13/Constant_31_output_0, %/blocks.13/Constant_32_output_0, %/blocks.13/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_3\"](%/blocks.13/Transpose_1_output_0, %/blocks.13/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.13/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather\"](%/blocks.13/attn/Shape_output_0, %/blocks.13/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_1\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_1\"](%/blocks.13/attn/Shape_1_output_0, %/blocks.13/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_2\"](%/blocks.13/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_2\"](%/blocks.13/attn/Shape_2_output_0, %/blocks.13/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.13/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/qkv/MatMul\"](%/blocks.13/Reshape_3_output_0, %onnx::MatMul_6058), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/qkv/Add\"](%blocks.13.attn.qkv.bias, %/blocks.13/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul\"](%/blocks.13/attn/Gather_1_output_0, %/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_4780 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4780), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4782 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_1\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4782), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat\"](%/blocks.13/attn/Unsqueeze_output_0, %/blocks.13/attn/Unsqueeze_1_output_0, %/blocks.13/attn/Constant_3_output_0, %/blocks.13/attn/Constant_4_output_0, %/blocks.13/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape\"](%/blocks.13/attn/qkv/Add_output_0, %/blocks.13/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.13/attn/Transpose\"](%/blocks.13/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.13/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_1\"](%/blocks.13/attn/Gather_output_0, %/blocks.13/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4797 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_2\"](%/blocks.13/attn/Mul_1_output_0, %onnx::Unsqueeze_4797), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4799 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_3\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4799), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_1\"](%/blocks.13/attn/Constant_7_output_0, %/blocks.13/attn/Unsqueeze_2_output_0, %/blocks.13/attn/Unsqueeze_3_output_0, %/blocks.13/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_1\"](%/blocks.13/attn/Transpose_output_0, %/blocks.13/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.13/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.13/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.13/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.13/attn/Split\"](%/blocks.13/attn/Reshape_1_output_0, %/blocks.13/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze\"](%/blocks.13/attn/Split_output_0, %/blocks.13/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze_1\"](%/blocks.13/attn/Split_output_1, %/blocks.13/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.13/attn/Squeeze_2\"](%/blocks.13/attn/Split_output_2, %/blocks.13/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.13/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.13/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_2\"](%/blocks.13/attn/Squeeze_output_0, %/blocks.13/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.13/attn/Transpose_1\"](%/blocks.13/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/MatMul\"](%/blocks.13/attn/Mul_2_output_0, %/blocks.13/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.13/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.13/attn/Range\"](%/blocks.13/attn/Constant_14_output_0, %/blocks.13/attn/Cast_output_0, %/blocks.13/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_4\"](%/blocks.13/attn/Range_output_0, %/blocks.13/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_1\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_2\"](%/blocks.13/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/attn/Div\"](%/blocks.13/attn/Cast_1_output_0, %/blocks.13/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_3\"](%/blocks.13/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_3\"](%/blocks.13/attn/Cast_3_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_5\"](%/blocks.13/attn/Range_output_0, %/blocks.13/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_4\"](%/blocks.13/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_4\"](%/blocks.13/attn/Cast_4_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub\"](%/blocks.13/attn/Mul_3_output_0, %/blocks.13/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_1\"](%/blocks.13/attn/Gather_1_output_0, %/blocks.13/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_5\"](%/blocks.13/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_5\"](%/blocks.13/attn/Cast_5_output_0, %/blocks.13/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add\"](%/blocks.13/attn/Sub_output_0, %/blocks.13/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_6\"](%/blocks.13/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_3\"](%blocks.13.attn.rel_pos_h, %/blocks.13/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_7\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.13/attn/Range_1\"](%/blocks.13/attn/Constant_19_output_0, %/blocks.13/attn/Cast_7_output_0, %/blocks.13/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_6\"](%/blocks.13/attn/Range_1_output_0, %/blocks.13/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_8\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_9\"](%/blocks.13/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/attn/Div_1\"](%/blocks.13/attn/Cast_8_output_0, %/blocks.13/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_10\"](%/blocks.13/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_6\"](%/blocks.13/attn/Cast_10_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.13/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_7\"](%/blocks.13/attn/Range_1_output_0, %/blocks.13/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_11\"](%/blocks.13/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_7\"](%/blocks.13/attn/Cast_11_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.13/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_2\"](%/blocks.13/attn/Mul_6_output_0, %/blocks.13/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.13/attn/Sub_3\"](%/blocks.13/attn/Gather_2_output_0, %/blocks.13/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.13/attn/Cast_12\"](%/blocks.13/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/attn/Mul_8\"](%/blocks.13/attn/Cast_12_output_0, %/blocks.13/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_1\"](%/blocks.13/attn/Sub_2_output_0, %/blocks.13/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.13/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/attn/Cast_13\"](%/blocks.13/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_4\"](%blocks.13.attn.rel_pos_w, %/blocks.13/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.13/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_3\"](%/blocks.13/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_5\"](%/blocks.13/attn/Shape_3_output_0, %/blocks.13/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/attn/Shape_4\"](%/blocks.13/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.13/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/attn/Gather_6\"](%/blocks.13/attn/Shape_4_output_0, %/blocks.13/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_4871 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_8\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4871), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4873 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_9\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4873), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_10\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4875), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_11\"](%/blocks.13/attn/Gather_6_output_0, %onnx::Unsqueeze_4877), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_2\"](%/blocks.13/attn/Unsqueeze_8_output_0, %/blocks.13/attn/Unsqueeze_9_output_0, %/blocks.13/attn/Unsqueeze_10_output_0, %/blocks.13/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.13/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_2\"](%/blocks.13/attn/Squeeze_output_0, %/blocks.13/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.13/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.13/attn/Einsum\"](%/blocks.13/attn/Reshape_2_output_0, %/blocks.13/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.13/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.13/attn/Einsum_1\"](%/blocks.13/attn/Reshape_2_output_0, %/blocks.13/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_4883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_12\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4883), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_13\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4885), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_14\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4887), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_15\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4889), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_16\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4891), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_3\"](%/blocks.13/attn/Unsqueeze_12_output_0, %/blocks.13/attn/Unsqueeze_13_output_0, %/blocks.13/attn/Unsqueeze_14_output_0, %/blocks.13/attn/Unsqueeze_15_output_0, %/blocks.13/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_3\"](%/blocks.13/attn/MatMul_output_0, %/blocks.13/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.13/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_17\"](%/blocks.13/attn/Einsum_output_0, %/blocks.13/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_2\"](%/blocks.13/attn/Reshape_3_output_0, %/blocks.13/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.13/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_18\"](%/blocks.13/attn/Einsum_1_output_0, %/blocks.13/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.13/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/Add_3\"](%/blocks.13/attn/Add_2_output_0, %/blocks.13/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_4901 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_19\"](%/blocks.13/attn/Gather_5_output_0, %onnx::Unsqueeze_4901), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_20\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4903), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_21\"](%/blocks.13/attn/Mul_output_0, %onnx::Unsqueeze_4905), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_4\"](%/blocks.13/attn/Unsqueeze_19_output_0, %/blocks.13/attn/Unsqueeze_20_output_0, %/blocks.13/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.13/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_4\"](%/blocks.13/attn/Add_3_output_0, %/blocks.13/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.13/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.13/attn/Softmax\"](%/blocks.13/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.13/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/MatMul_1\"](%/blocks.13/attn/Softmax_output_0, %/blocks.13/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4911 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_22\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4911), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.13/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4915 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_23\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4915), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4917 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_24\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4917), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_5\"](%/blocks.13/attn/Unsqueeze_22_output_0, %/blocks.13/attn/Constant_28_output_0, %/blocks.13/attn/Unsqueeze_23_output_0, %/blocks.13/attn/Unsqueeze_24_output_0, %/blocks.13/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_5\"](%/blocks.13/attn/MatMul_1_output_0, %/blocks.13/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.13/attn/Transpose_2\"](%/blocks.13/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_4924 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_25\"](%/blocks.13/attn/Gather_output_0, %onnx::Unsqueeze_4924), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4926 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_26\"](%/blocks.13/attn/Gather_1_output_0, %onnx::Unsqueeze_4926), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_4928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/attn/Unsqueeze_27\"](%/blocks.13/attn/Gather_2_output_0, %onnx::Unsqueeze_4928), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.13/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/attn/Concat_6\"](%/blocks.13/attn/Unsqueeze_25_output_0, %/blocks.13/attn/Unsqueeze_26_output_0, %/blocks.13/attn/Unsqueeze_27_output_0, %/blocks.13/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/attn/Reshape_6\"](%/blocks.13/attn/Transpose_2_output_0, %/blocks.13/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.13/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/attn/proj/MatMul\"](%/blocks.13/attn/Reshape_6_output_0, %onnx::MatMul_6067), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/attn/proj/Add\"](%blocks.13.attn.proj.bias, %/blocks.13/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.13/Shape_5\"](%/blocks.13/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.13/Gather_5\"](%/blocks.13/Shape_5_output_0, %/blocks.13/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/Mul\"](%/blocks.13/Add_output_0, %/blocks.13/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.13/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_2\"](%/blocks.13/Mul_output_0, %/blocks.13/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_6\"](%/blocks.13/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_7\"](%/blocks.13/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_3\"](%/blocks.13/Cast_7_output_0, %/blocks.13/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_8\"](%/blocks.13/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_9\"](%/blocks.13/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.13/Div_4\"](%/blocks.13/Gather_5_output_0, %/blocks.13/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_10\"](%/blocks.13/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.13/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.13/Cast_11\"](%/blocks.13/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_4952 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_9\"](%/blocks.13/Cast_11_output_0, %onnx::Unsqueeze_4952), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4954 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_10\"](%/blocks.13/Cast_3_output_0, %onnx::Unsqueeze_4954), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4956 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_11\"](%/blocks.13/Cast_5_output_0, %onnx::Unsqueeze_4956), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.13/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_5\"](%/blocks.13/Unsqueeze_9_output_0, %/blocks.13/Unsqueeze_10_output_0, %/blocks.13/Unsqueeze_11_output_0, %/blocks.13/Constant_36_output_0, %/blocks.13/Constant_37_output_0, %/blocks.13/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.13/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_4\"](%/blocks.13/attn/proj/Add_output_0, %/blocks.13/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.13/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.13/Transpose_2\"](%/blocks.13/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_4967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_12\"](%/blocks.13/Cast_11_output_0, %onnx::Unsqueeze_4967), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4969 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_13\"](%/blocks.13/Add_output_0, %onnx::Unsqueeze_4969), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %onnx::Unsqueeze_4971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.13/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_14\"](%/blocks.13/Add_1_output_0, %onnx::Unsqueeze_4971), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.13/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13\n",
            "  %/blocks.13/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.13/Concat_6\"](%/blocks.13/Unsqueeze_12_output_0, %/blocks.13/Unsqueeze_13_output_0, %/blocks.13/Unsqueeze_14_output_0, %/blocks.13/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.13/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.13/Reshape_5\"](%/blocks.13/Transpose_2_output_0, %/blocks.13/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.13/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_15\"](%/blocks.13/Gather_output_0, %/blocks.13/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice_1\"](%/blocks.13/Reshape_5_output_0, %/blocks.13/Constant_41_output_0, %/blocks.13/Unsqueeze_15_output_0, %/blocks.13/Constant_40_output_0, %/blocks.13/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.13/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.13/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.13/Unsqueeze_16\"](%/blocks.13/Gather_1_output_0, %/blocks.13/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.13/Slice_2\"](%/blocks.13/Slice_1_output_0, %/blocks.13/Constant_45_output_0, %/blocks.13/Unsqueeze_16_output_0, %/blocks.13/Constant_44_output_0, %/blocks.13/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.13/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_2\"](%/blocks.12/Add_3_output_0, %/blocks.13/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.13/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.13/norm2/LayerNormalization\"](%/blocks.13/Add_2_output_0, %blocks.13.norm2.weight, %blocks.13.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.13/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/mlp/lin1/MatMul\"](%/blocks.13/norm2/LayerNormalization_output_0, %onnx::MatMul_6078), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/lin1/Add\"](%blocks.13.mlp.lin1.bias, %/blocks.13/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.13/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.13/mlp/act/Div\"](%/blocks.13/mlp/lin1/Add_output_0, %/blocks.13/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.13/mlp/act/Erf\"](%/blocks.13/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.13/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/act/Add\"](%/blocks.13/mlp/act/Erf_output_0, %/blocks.13/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/mlp/act/Mul\"](%/blocks.13/mlp/lin1/Add_output_0, %/blocks.13/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.13/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.13/mlp/act/Mul_1\"](%/blocks.13/mlp/act/Mul_output_0, %/blocks.13/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.13/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.13/mlp/lin2/MatMul\"](%/blocks.13/mlp/act/Mul_1_output_0, %onnx::MatMul_6079), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/mlp/lin2/Add\"](%blocks.13.mlp.lin2.bias, %/blocks.13/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.13/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.13/Add_3\"](%/blocks.13/Add_2_output_0, %/blocks.13/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.13 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.14/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.14/norm1/LayerNormalization\"](%/blocks.13/Add_3_output_0, %blocks.14.norm1.weight, %blocks.14.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.14/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather\"](%/blocks.14/Shape_output_0, %/blocks.14/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_1\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_1\"](%/blocks.14/Shape_1_output_0, %/blocks.14/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:171:0\n",
            "  %/blocks.14/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_2\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_2\"](%/blocks.14/Shape_2_output_0, %/blocks.14/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Shape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_3\"](%/blocks.14/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_3\"](%/blocks.14/Shape_3_output_0, %/blocks.14/Constant_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:254:0\n",
            "  %/blocks.14/Constant_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Mod_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod\"](%/blocks.14/Gather_output_0, %/blocks.14/Constant_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Constant_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub\"](%/blocks.14/Constant_5_output_0, %/blocks.14/Mod_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Mod_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_1\"](%/blocks.14/Sub_output_0, %/blocks.14/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:256:0\n",
            "  %/blocks.14/Constant_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Mod_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_2\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Constant_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub_1\"](%/blocks.14/Constant_8_output_0, %/blocks.14/Mod_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1073:0\n",
            "  %/blocks.14/Constant_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Mod_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mod[fmod=0, onnx_name=\"/blocks.14/Mod_3\"](%/blocks.14/Sub_1_output_0, %/blocks.14/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:257:0\n",
            "  %/blocks.14/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze\"](%/blocks.14/Mod_3_output_0, %onnx::Unsqueeze_5043), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5047 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_1\"](%/blocks.14/Mod_1_output_0, %onnx::Unsqueeze_5047), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat\"](%/blocks.14/Constant_10_output_0, %/blocks.14/Constant_11_output_0, %/blocks.14/Constant_12_output_0, %/blocks.14/Unsqueeze_output_0, %/blocks.14/Constant_13_output_0, %/blocks.14/Unsqueeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_2\"](%/blocks.14/Mod_3_output_0, %onnx::Unsqueeze_5056), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_3\"](%/blocks.14/Mod_1_output_0, %onnx::Unsqueeze_5060), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_1\"](%/blocks.14/Constant_14_output_0, %/blocks.14/Constant_15_output_0, %/blocks.14/Constant_16_output_0, %/blocks.14/Unsqueeze_2_output_0, %/blocks.14/Constant_17_output_0, %/blocks.14/Unsqueeze_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_4\"](%/blocks.14/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_4\"](%/blocks.14/Shape_4_output_0, %/blocks.14/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/blocks.14/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/Sub_2\"](%/blocks.14/Constant_19_output_0, %/blocks.14/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast\"](%/blocks.14/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/ConstantOfShape_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name=\"/blocks.14/ConstantOfShape\"](%/blocks.14/Sub_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Concat_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_2\"](%/blocks.14/Cast_output_0, %/blocks.14/ConstantOfShape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name=\"/blocks.14/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Reshape_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape\"](%/blocks.14/Concat_2_output_0, %/blocks.14/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name=\"/blocks.14/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Slice_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice\"](%/blocks.14/Reshape_output_0, %/blocks.14/Constant_22_output_0, %/blocks.14/Constant_23_output_0, %/blocks.14/Constant_21_output_0, %/blocks.14/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Transpose_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/blocks.14/Transpose\"](%/blocks.14/Slice_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Reshape_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_1\"](%/blocks.14/Transpose_output_0, %/blocks.14/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Cast_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_1\"](%/blocks.14/Reshape_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Pad_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Pad[mode=\"constant\", onnx_name=\"/blocks.14/Pad\"](%/blocks.14/norm1/LayerNormalization_output_0, %/blocks.14/Cast_1_output_0, %onnx::Pad_281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5209:0\n",
            "  %/blocks.14/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add\"](%/blocks.14/Gather_output_0, %/blocks.14/Mod_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.14/Add_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_1\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Mod_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:260:0\n",
            "  %/blocks.14/Constant_26_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div\"](%/blocks.14/Add_output_0, %/blocks.14/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_2_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_2\"](%/blocks.14/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_3\"](%/blocks.14/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_1_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_1\"](%/blocks.14/Add_1_output_0, %/blocks.14/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_4_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_4\"](%/blocks.14/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_5\"](%/blocks.14/Cast_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_5095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_4\"](%/blocks.14/Gather_2_output_0, %onnx::Unsqueeze_5095), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5097 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_5\"](%/blocks.14/Cast_3_output_0, %onnx::Unsqueeze_5097), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5101 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_6\"](%/blocks.14/Cast_5_output_0, %onnx::Unsqueeze_5101), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_7\"](%/blocks.14/Gather_3_output_0, %onnx::Unsqueeze_5105), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_3\"](%/blocks.14/Unsqueeze_4_output_0, %/blocks.14/Unsqueeze_5_output_0, %/blocks.14/Constant_28_output_0, %/blocks.14/Unsqueeze_6_output_0, %/blocks.14/Constant_29_output_0, %/blocks.14/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.14/Reshape_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_2\"](%/blocks.14/Pad_output_0, %/blocks.14/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:262:0\n",
            "  %/blocks.14/Transpose_1_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.14/Transpose_1\"](%/blocks.14/Reshape_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_31\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_32\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5116 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_8\"](%/blocks.14/Gather_3_output_0, %onnx::Unsqueeze_5116), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_4\"](%/blocks.14/Constant_30_output_0, %/blocks.14/Constant_31_output_0, %/blocks.14/Constant_32_output_0, %/blocks.14/Unsqueeze_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/Reshape_3_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_3\"](%/blocks.14/Transpose_1_output_0, %/blocks.14/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:263:0\n",
            "  %/blocks.14/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather\"](%/blocks.14/attn/Shape_output_0, %/blocks.14/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_1\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_1\"](%/blocks.14/attn/Shape_1_output_0, %/blocks.14/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_2\"](%/blocks.14/Reshape_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_2\"](%/blocks.14/attn/Shape_2_output_0, %/blocks.14/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.14/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/qkv/MatMul\"](%/blocks.14/Reshape_3_output_0, %onnx::MatMul_6094), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[752640, 53760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/qkv/Add\"](%blocks.14.attn.qkv.bias, %/blocks.14/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul\"](%/blocks.14/attn/Gather_1_output_0, %/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_5133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5133), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5135 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_1\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5135), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat\"](%/blocks.14/attn/Unsqueeze_output_0, %/blocks.14/attn/Unsqueeze_1_output_0, %/blocks.14/attn/Constant_3_output_0, %/blocks.14/attn/Constant_4_output_0, %/blocks.14/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[752640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape\"](%/blocks.14/attn/qkv/Add_output_0, %/blocks.14/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 752640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.14/attn/Transpose\"](%/blocks.14/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.14/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_1\"](%/blocks.14/attn/Gather_output_0, %/blocks.14/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_2\"](%/blocks.14/attn/Mul_1_output_0, %onnx::Unsqueeze_5150), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_3\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5152), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_1\"](%/blocks.14/attn/Constant_7_output_0, %/blocks.14/attn/Unsqueeze_2_output_0, %/blocks.14/attn/Unsqueeze_3_output_0, %/blocks.14/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[6272000, 15680, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_1\"](%/blocks.14/attn/Transpose_output_0, %/blocks.14/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.14/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.14/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.14/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.14/attn/Split\"](%/blocks.14/attn/Reshape_1_output_0, %/blocks.14/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze\"](%/blocks.14/attn/Split_output_0, %/blocks.14/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze_1\"](%/blocks.14/attn/Split_output_1, %/blocks.14/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.14/attn/Squeeze_2\"](%/blocks.14/attn/Split_output_2, %/blocks.14/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.14/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.14/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Mul_2_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_2\"](%/blocks.14/attn/Squeeze_output_0, %/blocks.14/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Transpose_1_output_0 : Float(*, *, *, strides=[15680, 1, 80], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.14/attn/Transpose_1\"](%/blocks.14/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/MatMul_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/MatMul\"](%/blocks.14/attn/Mul_2_output_0, %/blocks.14/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.14/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.14/attn/Range\"](%/blocks.14/attn/Constant_14_output_0, %/blocks.14/attn/Cast_output_0, %/blocks.14/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_4\"](%/blocks.14/attn/Range_output_0, %/blocks.14/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_1\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_2\"](%/blocks.14/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/attn/Div\"](%/blocks.14/attn/Cast_1_output_0, %/blocks.14/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_3\"](%/blocks.14/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_3\"](%/blocks.14/attn/Cast_3_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_5\"](%/blocks.14/attn/Range_output_0, %/blocks.14/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Cast_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_4\"](%/blocks.14/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Mul_4_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_4\"](%/blocks.14/attn/Cast_4_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Sub_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub\"](%/blocks.14/attn/Mul_3_output_0, %/blocks.14/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_1\"](%/blocks.14/attn/Gather_1_output_0, %/blocks.14/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_5\"](%/blocks.14/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_5\"](%/blocks.14/attn/Cast_5_output_0, %/blocks.14/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Add_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add\"](%/blocks.14/attn/Sub_output_0, %/blocks.14/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_6_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_6\"](%/blocks.14/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Gather_3_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_3\"](%blocks.14.attn.rel_pos_h, %/blocks.14/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_7\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.14/attn/Range_1\"](%/blocks.14/attn/Constant_19_output_0, %/blocks.14/attn/Cast_7_output_0, %/blocks.14/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_6\"](%/blocks.14/attn/Range_1_output_0, %/blocks.14/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_8\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_9\"](%/blocks.14/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/attn/Div_1\"](%/blocks.14/attn/Cast_8_output_0, %/blocks.14/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_10\"](%/blocks.14/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_6\"](%/blocks.14/attn/Cast_10_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.14/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_7\"](%/blocks.14/attn/Range_1_output_0, %/blocks.14/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Cast_11_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_11\"](%/blocks.14/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Mul_7_output_0 : Float(1, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_7\"](%/blocks.14/attn/Cast_11_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.14/attn/Sub_2_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_2\"](%/blocks.14/attn/Mul_6_output_0, %/blocks.14/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.14/attn/Sub_3\"](%/blocks.14/attn/Gather_2_output_0, %/blocks.14/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.14/attn/Cast_12\"](%/blocks.14/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/attn/Mul_8\"](%/blocks.14/attn/Cast_12_output_0, %/blocks.14/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Add_1_output_0 : Float(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_1\"](%/blocks.14/attn/Sub_2_output_0, %/blocks.14/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.14/attn/Cast_13_output_0 : Long(*, *, strides=[14, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/attn/Cast_13\"](%/blocks.14/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Gather_4_output_0 : Float(*, *, 80, strides=[1120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_4\"](%blocks.14.attn.rel_pos_w, %/blocks.14/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.14/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_3\"](%/blocks.14/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_5\"](%/blocks.14/attn/Shape_3_output_0, %/blocks.14/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/attn/Shape_4\"](%/blocks.14/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.14/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/attn/Gather_6\"](%/blocks.14/attn/Shape_4_output_0, %/blocks.14/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_5224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_8\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5224), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_9\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5226), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_10\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5228), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_11\"](%/blocks.14/attn/Gather_6_output_0, %onnx::Unsqueeze_5230), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_2\"](%/blocks.14/attn/Unsqueeze_8_output_0, %/blocks.14/attn/Unsqueeze_9_output_0, %/blocks.14/attn/Unsqueeze_10_output_0, %/blocks.14/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.14/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_2\"](%/blocks.14/attn/Squeeze_output_0, %/blocks.14/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.14/attn/Einsum_output_0 : Float(*, *, *, *, strides=[196, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.14/attn/Einsum\"](%/blocks.14/attn/Reshape_2_output_0, %/blocks.14/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.14/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[196, 14, 78400, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.14/attn/Einsum_1\"](%/blocks.14/attn/Reshape_2_output_0, %/blocks.14/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_5236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_12\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5236), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_13\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5238), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5240 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_14\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5240), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_15\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5242), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_16\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5244), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_3\"](%/blocks.14/attn/Unsqueeze_12_output_0, %/blocks.14/attn/Unsqueeze_13_output_0, %/blocks.14/attn/Unsqueeze_14_output_0, %/blocks.14/attn/Unsqueeze_15_output_0, %/blocks.14/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_3\"](%/blocks.14/attn/MatMul_output_0, %/blocks.14/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.14/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[196, 78400, 14, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_17\"](%/blocks.14/attn/Einsum_output_0, %/blocks.14/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_2\"](%/blocks.14/attn/Reshape_3_output_0, %/blocks.14/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.14/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[196, 14, 78400, 14, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_18\"](%/blocks.14/attn/Einsum_1_output_0, %/blocks.14/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.14/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[38416, 2744, 196, 14, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/Add_3\"](%/blocks.14/attn/Add_2_output_0, %/blocks.14/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_5254 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_19\"](%/blocks.14/attn/Gather_5_output_0, %onnx::Unsqueeze_5254), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_20\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5256), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5258 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_21\"](%/blocks.14/attn/Mul_output_0, %onnx::Unsqueeze_5258), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_4\"](%/blocks.14/attn/Unsqueeze_19_output_0, %/blocks.14/attn/Unsqueeze_20_output_0, %/blocks.14/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.14/attn/Reshape_4_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_4\"](%/blocks.14/attn/Add_3_output_0, %/blocks.14/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.14/attn/Softmax_output_0 : Float(*, *, *, strides=[38416, 196, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.14/attn/Softmax\"](%/blocks.14/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.14/attn/MatMul_1_output_0 : Float(*, *, *, strides=[15680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/MatMul_1\"](%/blocks.14/attn/Softmax_output_0, %/blocks.14/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5264 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_22\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5264), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.14/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5268 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_23\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5268), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5270 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_24\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5270), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_5\"](%/blocks.14/attn/Unsqueeze_22_output_0, %/blocks.14/attn/Constant_28_output_0, %/blocks.14/attn/Unsqueeze_23_output_0, %/blocks.14/attn/Unsqueeze_24_output_0, %/blocks.14/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[250880, 15680, 1120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_5\"](%/blocks.14/attn/MatMul_1_output_0, %/blocks.14/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[250880, 1120, 80, 15680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.14/attn/Transpose_2\"](%/blocks.14/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_25\"](%/blocks.14/attn/Gather_output_0, %onnx::Unsqueeze_5277), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5279 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_26\"](%/blocks.14/attn/Gather_1_output_0, %onnx::Unsqueeze_5279), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/attn/Unsqueeze_27\"](%/blocks.14/attn/Gather_2_output_0, %onnx::Unsqueeze_5281), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.14/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/attn/Concat_6\"](%/blocks.14/attn/Unsqueeze_25_output_0, %/blocks.14/attn/Unsqueeze_26_output_0, %/blocks.14/attn/Unsqueeze_27_output_0, %/blocks.14/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/attn/Reshape_6\"](%/blocks.14/attn/Transpose_2_output_0, %/blocks.14/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.14/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/attn/proj/MatMul\"](%/blocks.14/attn/Reshape_6_output_0, %onnx::MatMul_6103), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/attn/proj/Add\"](%blocks.14.attn.proj.bias, %/blocks.14/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.14/Shape_5\"](%/blocks.14/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Constant_33_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_33\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.14/Gather_5\"](%/blocks.14/Shape_5_output_0, %/blocks.14/Constant_33_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/Mul\"](%/blocks.14/Add_output_0, %/blocks.14/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:283:0\n",
            "  %/blocks.14/Constant_34_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_34\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_2_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_2\"](%/blocks.14/Mul_output_0, %/blocks.14/Constant_34_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_6_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_6\"](%/blocks.14/Div_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_7_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_7\"](%/blocks.14/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_35\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_3_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_3\"](%/blocks.14/Cast_7_output_0, %/blocks.14/Constant_35_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_8_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_8\"](%/blocks.14/Div_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_9_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_9\"](%/blocks.14/Cast_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Div_4_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/blocks.14/Div_4\"](%/blocks.14/Gather_5_output_0, %/blocks.14/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_10_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_10\"](%/blocks.14/Div_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %/blocks.14/Cast_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.14/Cast_11\"](%/blocks.14/Cast_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1106:0\n",
            "  %onnx::Unsqueeze_5305 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_9\"](%/blocks.14/Cast_11_output_0, %onnx::Unsqueeze_5305), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5307 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_10\"](%/blocks.14/Cast_3_output_0, %onnx::Unsqueeze_5307), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5309 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_11\"](%/blocks.14/Cast_5_output_0, %onnx::Unsqueeze_5309), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_36\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={14}, onnx_name=\"/blocks.14/Constant_37\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_38\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_5\"](%/blocks.14/Unsqueeze_9_output_0, %/blocks.14/Unsqueeze_10_output_0, %/blocks.14/Unsqueeze_11_output_0, %/blocks.14/Constant_36_output_0, %/blocks.14/Constant_37_output_0, %/blocks.14/Constant_38_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.14/Reshape_4_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 250880, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_4\"](%/blocks.14/attn/proj/Add_output_0, %/blocks.14/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:284:0\n",
            "  %/blocks.14/Transpose_2_output_0 : Float(*, *, *, *, *, *, strides=[6272000, 1254400, 89600, 17920, 1280, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2, 4, 5], onnx_name=\"/blocks.14/Transpose_2\"](%/blocks.14/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %onnx::Unsqueeze_5320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_12\"](%/blocks.14/Cast_11_output_0, %onnx::Unsqueeze_5320), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_13\"](%/blocks.14/Add_output_0, %onnx::Unsqueeze_5322), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %onnx::Unsqueeze_5324 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.14/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_14\"](%/blocks.14/Add_1_output_0, %onnx::Unsqueeze_5324), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.14/Constant_39\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14\n",
            "  %/blocks.14/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.14/Concat_6\"](%/blocks.14/Unsqueeze_12_output_0, %/blocks.14/Unsqueeze_13_output_0, %/blocks.14/Unsqueeze_14_output_0, %/blocks.14/Constant_39_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.14/Reshape_5_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.14/Reshape_5\"](%/blocks.14/Transpose_2_output_0, %/blocks.14/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:285:0\n",
            "  %/blocks.14/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_40\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_41\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_42\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_15\"](%/blocks.14/Gather_output_0, %/blocks.14/Constant_42_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_43\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Slice_1_output_0 : Float(*, *, *, *, strides=[6272000, 89600, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice_1\"](%/blocks.14/Reshape_5_output_0, %/blocks.14/Constant_41_output_0, %/blocks.14/Unsqueeze_15_output_0, %/blocks.14/Constant_40_output_0, %/blocks.14/Constant_43_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_44_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.14/Constant_44\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_45_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_45\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.14/Constant_46\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.14/Unsqueeze_16\"](%/blocks.14/Gather_1_output_0, %/blocks.14/Constant_46_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Constant_47_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/Constant_47\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Slice_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/blocks.14/Slice_2\"](%/blocks.14/Slice_1_output_0, %/blocks.14/Constant_45_output_0, %/blocks.14/Unsqueeze_16_output_0, %/blocks.14/Constant_44_output_0, %/blocks.14/Constant_47_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:288:0\n",
            "  %/blocks.14/Add_2_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_2\"](%/blocks.13/Add_3_output_0, %/blocks.14/Slice_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.14/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.14/norm2/LayerNormalization\"](%/blocks.14/Add_2_output_0, %blocks.14.norm2.weight, %blocks.14.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.14/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/mlp/lin1/MatMul\"](%/blocks.14/norm2/LayerNormalization_output_0, %onnx::MatMul_6114), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/lin1/Add\"](%blocks.14.mlp.lin1.bias, %/blocks.14/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.14/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.14/mlp/act/Div\"](%/blocks.14/mlp/lin1/Add_output_0, %/blocks.14/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.14/mlp/act/Erf\"](%/blocks.14/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.14/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/act/Add\"](%/blocks.14/mlp/act/Erf_output_0, %/blocks.14/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/mlp/act/Mul\"](%/blocks.14/mlp/lin1/Add_output_0, %/blocks.14/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.14/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.14/mlp/act/Mul_1\"](%/blocks.14/mlp/act/Mul_output_0, %/blocks.14/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.14/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.14/mlp/lin2/MatMul\"](%/blocks.14/mlp/act/Mul_1_output_0, %onnx::MatMul_6115), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/mlp/lin2/Add\"](%blocks.14.mlp.lin2.bias, %/blocks.14/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.14/Add_3_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.14/Add_3\"](%/blocks.14/Add_2_output_0, %/blocks.14/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.14 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/blocks.15/norm1/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.15/norm1/LayerNormalization\"](%/blocks.14/Add_3_output_0, %blocks.15.norm1.weight, %blocks.15.norm1.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/torch.nn.modules.normalization.LayerNorm::norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.15/attn/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather\"](%/blocks.15/attn/Shape_output_0, %/blocks.15/attn/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_1\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_1\"](%/blocks.15/attn/Shape_1_output_0, %/blocks.15/attn/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_2\"](%/blocks.15/norm1/LayerNormalization_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.15/attn/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_2\"](%/blocks.15/attn/Shape_2_output_0, %/blocks.15/attn/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:225:0\n",
            "  %/blocks.15/attn/qkv/MatMul_output_0 : Float(*, *, *, 3840, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/qkv/MatMul\"](%/blocks.15/norm1/LayerNormalization_output_0, %onnx::MatMul_6116), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/qkv/Add_output_0 : Float(*, *, *, 3840, strides=[15728640, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/qkv/Add\"](%blocks.15.attn.qkv.bias, %/blocks.15/attn/qkv/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::qkv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul\"](%/blocks.15/attn/Gather_1_output_0, %/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %onnx::Unsqueeze_5379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5379), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5381 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_1\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5381), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_3\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_4\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_5\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat\"](%/blocks.15/attn/Unsqueeze_output_0, %/blocks.15/attn/Unsqueeze_1_output_0, %/blocks.15/attn/Constant_3_output_0, %/blocks.15/attn/Constant_4_output_0, %/blocks.15/attn/Constant_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Reshape_output_0 : Float(*, *, *, *, *, strides=[15728640, 3840, 1280, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape\"](%/blocks.15/attn/qkv/Add_output_0, %/blocks.15/attn/Concat_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Transpose_output_0 : Float(*, *, *, *, *, strides=[1280, 15728640, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[2, 0, 3, 1, 4], onnx_name=\"/blocks.15/attn/Transpose\"](%/blocks.15/attn/Reshape_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:227:0\n",
            "  %/blocks.15/attn/Constant_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_6\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_1\"](%/blocks.15/attn/Gather_output_0, %/blocks.15/attn/Constant_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_7\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5396 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_2\"](%/blocks.15/attn/Mul_1_output_0, %onnx::Unsqueeze_5396), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5398 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_3\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5398), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_8\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_1\"](%/blocks.15/attn/Constant_7_output_0, %/blocks.15/attn/Unsqueeze_2_output_0, %/blocks.15/attn/Unsqueeze_3_output_0, %/blocks.15/attn/Constant_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Reshape_1_output_0 : Float(*, *, *, *, strides=[1280, 80, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_1\"](%/blocks.15/attn/Transpose_output_0, %/blocks.15/attn/Concat_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 1  1  1 [ CPULongType{3} ], onnx_name=\"/blocks.15/attn/Constant_9\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Split_output_0 : Float(*, *, *, *, device=cpu), %/blocks.15/attn/Split_output_1 : Float(*, *, *, *, device=cpu), %/blocks.15/attn/Split_output_2 : Float(*, *, *, *, device=cpu) = onnx::Split[axis=0, onnx_name=\"/blocks.15/attn/Split\"](%/blocks.15/attn/Reshape_1_output_0, %/blocks.15/attn/Constant_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_10\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze\"](%/blocks.15/attn/Split_output_0, %/blocks.15/attn/Constant_10_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_11\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_1_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze_1\"](%/blocks.15/attn/Split_output_1, %/blocks.15/attn/Constant_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_12\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Squeeze_2_output_0 : Float(*, *, *, strides=[80, 3840, 1], requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/blocks.15/attn/Squeeze_2\"](%/blocks.15/attn/Split_output_2, %/blocks.15/attn/Constant_12_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:229:0\n",
            "  %/blocks.15/attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.111803}, onnx_name=\"/blocks.15/attn/Constant_13\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Mul_2_output_0 : Float(*, *, *, strides=[80, 1280, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_2\"](%/blocks.15/attn/Squeeze_output_0, %/blocks.15/attn/Constant_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Transpose_1_output_0 : Float(*, *, *, strides=[80, 1, 3840], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name=\"/blocks.15/attn/Transpose_1\"](%/blocks.15/attn/Squeeze_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/MatMul_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/MatMul\"](%/blocks.15/attn/Mul_2_output_0, %/blocks.15/attn/Transpose_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:231:0\n",
            "  %/blocks.15/attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_14\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_15\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.15/attn/Range\"](%/blocks.15/attn/Constant_14_output_0, %/blocks.15/attn/Cast_output_0, %/blocks.15/attn/Constant_15_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_16\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Unsqueeze_4_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_4\"](%/blocks.15/attn/Range_output_0, %/blocks.15/attn/Constant_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_1\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_2\"](%/blocks.15/attn/Gather_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Div_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/attn/Div\"](%/blocks.15/attn/Cast_1_output_0, %/blocks.15/attn/Cast_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_3\"](%/blocks.15/attn/Unsqueeze_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Mul_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_3\"](%/blocks.15/attn/Cast_3_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_17\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Unsqueeze_5_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_5\"](%/blocks.15/attn/Range_output_0, %/blocks.15/attn/Constant_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Cast_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_4\"](%/blocks.15/attn/Unsqueeze_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Mul_4_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_4\"](%/blocks.15/attn/Cast_4_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Sub_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub\"](%/blocks.15/attn/Mul_3_output_0, %/blocks.15/attn/Mul_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_18\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_1\"](%/blocks.15/attn/Gather_1_output_0, %/blocks.15/attn/Constant_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_5\"](%/blocks.15/attn/Sub_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Mul_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_5\"](%/blocks.15/attn/Cast_5_output_0, %/blocks.15/attn/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Add_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add\"](%/blocks.15/attn/Sub_output_0, %/blocks.15/attn/Mul_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_6_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_6\"](%/blocks.15/attn/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Gather_3_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_3\"](%blocks.15.attn.rel_pos_h, %/blocks.15/attn/Cast_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Cast_7_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_7\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_19_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_19\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_20_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_20\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Range_1_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name=\"/blocks.15/attn/Range_1\"](%/blocks.15/attn/Constant_19_output_0, %/blocks.15/attn/Cast_7_output_0, %/blocks.15/attn/Constant_20_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_21\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Unsqueeze_6_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_6\"](%/blocks.15/attn/Range_1_output_0, %/blocks.15/attn/Constant_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_8_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_8\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_9_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_9\"](%/blocks.15/attn/Gather_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Div_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/attn/Div_1\"](%/blocks.15/attn/Cast_8_output_0, %/blocks.15/attn/Cast_9_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Cast_10_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_10\"](%/blocks.15/attn/Unsqueeze_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Mul_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_6\"](%/blocks.15/attn/Cast_10_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:318:0\n",
            "  %/blocks.15/attn/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_22\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Unsqueeze_7_output_0 : Long(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_7\"](%/blocks.15/attn/Range_1_output_0, %/blocks.15/attn/Constant_22_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Cast_11_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_11\"](%/blocks.15/attn/Unsqueeze_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Mul_7_output_0 : Float(1, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_7\"](%/blocks.15/attn/Cast_11_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:319:0\n",
            "  %/blocks.15/attn/Sub_2_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_2\"](%/blocks.15/attn/Mul_6_output_0, %/blocks.15/attn/Mul_7_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Constant_23_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/attn/Constant_23\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/blocks.15/attn/Sub_3\"](%/blocks.15/attn/Gather_2_output_0, %/blocks.15/attn/Constant_23_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/blocks.15/attn/Cast_12\"](%/blocks.15/attn/Sub_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Mul_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/attn/Mul_8\"](%/blocks.15/attn/Cast_12_output_0, %/blocks.15/attn/Div_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Add_1_output_0 : Float(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_1\"](%/blocks.15/attn/Sub_2_output_0, %/blocks.15/attn/Mul_8_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:320:0\n",
            "  %/blocks.15/attn/Cast_13_output_0 : Long(*, *, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/blocks.15/attn/Cast_13\"](%/blocks.15/attn/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Gather_4_output_0 : Float(*, *, 80, strides=[5120, 80, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_4\"](%blocks.15.attn.rel_pos_w, %/blocks.15/attn/Cast_13_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:322:0\n",
            "  %/blocks.15/attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_3\"](%/blocks.15/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Constant_24_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/blocks.15/attn/Constant_24\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_5\"](%/blocks.15/attn/Shape_3_output_0, %/blocks.15/attn/Constant_24_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/blocks.15/attn/Shape_4\"](%/blocks.15/attn/Squeeze_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Constant_25_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/blocks.15/attn/Constant_25\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %/blocks.15/attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/blocks.15/attn/Gather_6\"](%/blocks.15/attn/Shape_4_output_0, %/blocks.15/attn/Constant_25_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:352:0\n",
            "  %onnx::Unsqueeze_5470 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_8\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5470), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5472 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_9\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5472), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5474 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_10\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5474), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5476 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_11\"](%/blocks.15/attn/Gather_6_output_0, %onnx::Unsqueeze_5476), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_2\"](%/blocks.15/attn/Unsqueeze_8_output_0, %/blocks.15/attn/Unsqueeze_9_output_0, %/blocks.15/attn/Unsqueeze_10_output_0, %/blocks.15/attn/Unsqueeze_11_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.15/attn/Reshape_2_output_0 : Float(*, *, *, *, strides=[80, 245760, 3840, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_2\"](%/blocks.15/attn/Squeeze_output_0, %/blocks.15/attn/Concat_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:353:0\n",
            "  %/blocks.15/attn/Einsum_output_0 : Float(*, *, *, *, strides=[4096, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,hkc->bhwk\", onnx_name=\"/blocks.15/attn/Einsum\"](%/blocks.15/attn/Reshape_2_output_0, %/blocks.15/attn/Gather_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %/blocks.15/attn/Einsum_1_output_0 : Float(*, *, *, *, strides=[4096, 64, 65536, 1], requires_grad=0, device=cpu) = onnx::Einsum[equation=\"bhwc,wkc->bhwk\", onnx_name=\"/blocks.15/attn/Einsum_1\"](%/blocks.15/attn/Reshape_2_output_0, %/blocks.15/attn/Gather_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /usr/local/lib/python3.11/dist-packages/torch/functional.py:407:0\n",
            "  %onnx::Unsqueeze_5482 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_12\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5482), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5484 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_13\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5484), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_14\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5486), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_15\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5488), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_16\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5490), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_3_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_3\"](%/blocks.15/attn/Unsqueeze_12_output_0, %/blocks.15/attn/Unsqueeze_13_output_0, %/blocks.15/attn/Unsqueeze_14_output_0, %/blocks.15/attn/Unsqueeze_15_output_0, %/blocks.15/attn/Unsqueeze_16_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Reshape_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_3\"](%/blocks.15/attn/MatMul_output_0, %/blocks.15/attn/Concat_3_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name=\"/blocks.15/attn/Constant_26\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Unsqueeze_17_output_0 : Float(*, *, *, *, 1, strides=[4096, 65536, 64, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_17\"](%/blocks.15/attn/Einsum_output_0, %/blocks.15/attn/Constant_26_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Add_2_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_2\"](%/blocks.15/attn/Reshape_3_output_0, %/blocks.15/attn/Unsqueeze_17_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name=\"/blocks.15/attn/Constant_27\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Unsqueeze_18_output_0 : Float(*, *, *, 1, *, strides=[4096, 64, 65536, 64, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_18\"](%/blocks.15/attn/Einsum_1_output_0, %/blocks.15/attn/Constant_27_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %/blocks.15/attn/Add_3_output_0 : Float(*, *, *, *, *, strides=[16777216, 262144, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/Add_3\"](%/blocks.15/attn/Add_2_output_0, %/blocks.15/attn/Unsqueeze_18_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:358:0\n",
            "  %onnx::Unsqueeze_5500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_19\"](%/blocks.15/attn/Gather_5_output_0, %onnx::Unsqueeze_5500), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_20\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5502), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_21\"](%/blocks.15/attn/Mul_output_0, %onnx::Unsqueeze_5504), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_4\"](%/blocks.15/attn/Unsqueeze_19_output_0, %/blocks.15/attn/Unsqueeze_20_output_0, %/blocks.15/attn/Unsqueeze_21_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.15/attn/Reshape_4_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_4\"](%/blocks.15/attn/Add_3_output_0, %/blocks.15/attn/Concat_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:359:0\n",
            "  %/blocks.15/attn/Softmax_output_0 : Float(*, *, *, strides=[16777216, 4096, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/blocks.15/attn/Softmax\"](%/blocks.15/attn/Reshape_4_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:236:0\n",
            "  %/blocks.15/attn/MatMul_1_output_0 : Float(*, *, *, strides=[327680, 80, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/MatMul_1\"](%/blocks.15/attn/Softmax_output_0, %/blocks.15/attn/Squeeze_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5510 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_22\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5510), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/blocks.15/attn/Constant_28\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_23\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5514), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_24\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5516), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_29\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_5_output_0 : Long(5, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_5\"](%/blocks.15/attn/Unsqueeze_22_output_0, %/blocks.15/attn/Constant_28_output_0, %/blocks.15/attn/Unsqueeze_23_output_0, %/blocks.15/attn/Unsqueeze_24_output_0, %/blocks.15/attn/Constant_29_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Reshape_5_output_0 : Float(*, *, *, *, *, strides=[5242880, 327680, 5120, 80, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_5\"](%/blocks.15/attn/MatMul_1_output_0, %/blocks.15/attn/Concat_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Transpose_2_output_0 : Float(*, *, *, *, *, strides=[5242880, 5120, 80, 327680, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1, 4], onnx_name=\"/blocks.15/attn/Transpose_2\"](%/blocks.15/attn/Reshape_5_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %onnx::Unsqueeze_5523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_25\"](%/blocks.15/attn/Gather_output_0, %onnx::Unsqueeze_5523), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_26\"](%/blocks.15/attn/Gather_1_output_0, %onnx::Unsqueeze_5525), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %onnx::Unsqueeze_5527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
            "  %/blocks.15/attn/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/blocks.15/attn/Unsqueeze_27\"](%/blocks.15/attn/Gather_2_output_0, %onnx::Unsqueeze_5527), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/blocks.15/attn/Constant_30\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn\n",
            "  %/blocks.15/attn/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/blocks.15/attn/Concat_6\"](%/blocks.15/attn/Unsqueeze_25_output_0, %/blocks.15/attn/Unsqueeze_26_output_0, %/blocks.15/attn/Unsqueeze_27_output_0, %/blocks.15/attn/Constant_30_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/Reshape_6_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/blocks.15/attn/Reshape_6\"](%/blocks.15/attn/Transpose_2_output_0, %/blocks.15/attn/Concat_6_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn # /content/segment_anything/segment_anything/modeling/image_encoder.py:237:0\n",
            "  %/blocks.15/attn/proj/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/attn/proj/MatMul\"](%/blocks.15/attn/Reshape_6_output_0, %onnx::MatMul_6125), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/attn/proj/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/attn/proj/Add\"](%blocks.15.attn.proj.bias, %/blocks.15/attn/proj/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.image_encoder.Attention::attn/torch.nn.modules.linear.Linear::proj # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/Add_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add\"](%/blocks.14/Add_3_output_0, %/blocks.15/attn/proj/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:179:0\n",
            "  %/blocks.15/norm2/LayerNormalization_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=9.9999999999999995e-07, onnx_name=\"/blocks.15/norm2/LayerNormalization\"](%/blocks.15/Add_output_0, %blocks.15.norm2.weight, %blocks.15.norm2.bias), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/torch.nn.modules.normalization.LayerNorm::norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "  %/blocks.15/mlp/lin1/MatMul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin1/MatMul\"](%/blocks.15/norm2/LayerNormalization_output_0, %onnx::MatMul_6126), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin1/Add_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin1/Add\"](%blocks.15.mlp.lin1.bias, %/blocks.15/mlp/lin1/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/act/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/blocks.15/mlp/act/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Div_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Div[onnx_name=\"/blocks.15/mlp/act/Div\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Erf_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Erf[onnx_name=\"/blocks.15/mlp/act/Erf\"](%/blocks.15/mlp/act/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/blocks.15/mlp/act/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Add_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/act/Add\"](%/blocks.15/mlp/act/Erf_output_0, %/blocks.15/mlp/act/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_output_0 : Float(*, *, *, 5120, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul\"](%/blocks.15/mlp/lin1/Add_output_0, %/blocks.15/mlp/act/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/blocks.15/mlp/act/Constant_2\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/act/Mul_1_output_0 : Float(*, *, *, 5120, strides=[20971520, 327680, 5120, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/blocks.15/mlp/act/Mul_1\"](%/blocks.15/mlp/act/Mul_output_0, %/blocks.15/mlp/act/Constant_2_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.activation.GELU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:734:0\n",
            "  %/blocks.15/mlp/lin2/MatMul_output_0 : Float(*, *, *, 1280, device=cpu) = onnx::MatMul[onnx_name=\"/blocks.15/mlp/lin2/MatMul\"](%/blocks.15/mlp/act/Mul_1_output_0, %onnx::MatMul_6127), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/mlp/lin2/Add_output_0 : Float(*, *, *, 1280, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/mlp/lin2/Add\"](%blocks.15.mlp.lin2.bias, %/blocks.15/mlp/lin2/MatMul_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15/segment_anything.modeling.common.MLPBlock::mlp/torch.nn.modules.linear.Linear::lin2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "  %/blocks.15/Add_1_output_0 : Float(*, *, *, *, strides=[5242880, 81920, 1280, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/blocks.15/Add_1\"](%/blocks.15/Add_output_0, %/blocks.15/mlp/lin2/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/segment_anything.modeling.image_encoder.Block::blocks.15 # /content/segment_anything/segment_anything/modeling/image_encoder.py:180:0\n",
            "  %/Transpose_output_0 : Float(*, *, *, *, strides=[5242880, 1, 81920, 1280], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2], onnx_name=\"/Transpose\"](%/blocks.15/Add_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf:: # /content/SegmentAnything-TensorRT/sam_modification/ImageEncoderModels.py:208:0\n",
            "  %/neck/neck.0/Conv_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/neck.0/Conv\"](%/Transpose_output_0, %neck.0.weight), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/torch.nn.modules.conv.Conv2d::neck.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n",
            "  %/neck/neck.1/ReduceMean_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.1/ReduceMean\"](%/neck/neck.0/Conv_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:39:0\n",
            "  %/neck/neck.1/Sub_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/neck/neck.1/Sub\"](%/neck/neck.0/Conv_output_0, %/neck/neck.1/ReduceMean_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/neck/neck.1/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Pow_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Pow[onnx_name=\"/neck/neck.1/Pow\"](%/neck/neck.1/Sub_output_0, %/neck/neck.1/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/ReduceMean_1_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.1/ReduceMean_1\"](%/neck/neck.1/Pow_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/neck/neck.1/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Add_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.1/Add\"](%/neck/neck.1/ReduceMean_1_output_0, %/neck/neck.1/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Sqrt_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name=\"/neck/neck.1/Sqrt\"](%/neck/neck.1/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Div_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/neck/neck.1/Div\"](%/neck/neck.1/Sub_output_0, %/neck/neck.1/Sqrt_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.1/Mul_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/neck/neck.1/Mul\"](%onnx::Mul_6129, %/neck/neck.1/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %/neck/neck.1/Add_1_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.1/Add_1\"](%/neck/neck.1/Mul_output_0, %onnx::Add_6131), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.1 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %/neck/neck.2/Conv_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/neck.2/Conv\"](%/neck/neck.1/Add_1_output_0, %neck.2.weight), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/torch.nn.modules.conv.Conv2d::neck.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549:0\n",
            "  %/neck/neck.3/ReduceMean_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.3/ReduceMean\"](%/neck/neck.2/Conv_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:39:0\n",
            "  %/neck/neck.3/Sub_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/neck/neck.3/Sub\"](%/neck/neck.2/Conv_output_0, %/neck/neck.3/ReduceMean_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/neck/neck.3/Constant\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Pow_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Pow[onnx_name=\"/neck/neck.3/Pow\"](%/neck/neck.3/Sub_output_0, %/neck/neck.3/Constant_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/ReduceMean_1_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[1], keepdims=1, onnx_name=\"/neck/neck.3/ReduceMean_1\"](%/neck/neck.3/Pow_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:40:0\n",
            "  %/neck/neck.3/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name=\"/neck/neck.3/Constant_1\"](), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Add_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.3/Add\"](%/neck/neck.3/ReduceMean_1_output_0, %/neck/neck.3/Constant_1_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Sqrt_output_0 : Float(*, 1, *, *, strides=[4096, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name=\"/neck/neck.3/Sqrt\"](%/neck/neck.3/Add_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Div_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/neck/neck.3/Div\"](%/neck/neck.3/Sub_output_0, %/neck/neck.3/Sqrt_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:41:0\n",
            "  %/neck/neck.3/Mul_output_0 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/neck/neck.3/Mul\"](%onnx::Mul_6133, %/neck/neck.3/Div_output_0), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  %output_1 : Float(*, 256, *, *, strides=[1048576, 1, 16384, 256], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/neck/neck.3/Add_1\"](%/neck/neck.3/Mul_output_0, %onnx::Add_6135), scope: sam_modification.ImageEncoderModels.ImageEncoderViTSecondHalf::/torch.nn.modules.container.Sequential::neck/segment_anything.modeling.common.LayerNorm2d::neck.3 # /content/segment_anything/segment_anything/modeling/common.py:42:0\n",
            "  return (%output_1)\n",
            "\n",
            "sh: 1: trtexec: not found\n",
            "sh: 1: trtexec: not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversión de modelos ONNX a TensorRT (.engine)\n",
        "\n",
        "Ejecuta el script export_engine.py, que:\n",
        "\n",
        "Convierte modelos ONNX a modelos TensorRT (.engine) optimizados para GPUs NVIDIA.\n",
        "\n",
        "Cada comando exporta uno de los dos bloques de inferencia del modelo SAM:\n",
        "\n",
        "sam_vit_h_embedding_first.onnx → sam_vit_h_embedding_first.engine\n",
        "\n",
        "sam_vit_h_embedding_second.onnx → sam_vit_h_embedding_second.engine\n",
        "\n",
        "El flag --use_fp16 True indica que se use precisión FP16"
      ],
      "metadata": {
        "id": "dTNAjPkADxXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar primer modelo ONNX a ENGINE (.engine)\n",
        "!python export_engine.py \\\n",
        "  --onnx_model_path exported_models/vit_h/sam_vit_h_embedding_first.onnx \\\n",
        "  --engine_output_path checkpoints/sam_vit_h_embedding_first.engine \\\n",
        "  --use_fp16 True\n",
        "\n",
        "# Exportar segundo modelo ONNX a ENGINE (.engine)\n",
        "!python export_engine.py \\\n",
        "  --onnx_model_path exported_models/vit_h/sam_vit_h_embedding_second.onnx \\\n",
        "  --engine_output_path checkpoints/sam_vit_h_embedding_second.engine \\\n",
        "  --use_fp16 True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVJn2ypAr8p",
        "outputId": "706dbd62-92d8-4aba-cb49-ad176a3b524d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TensorRT engine successfully saved to checkpoints/sam_vit_h_embedding_first.engine\n",
            "[06/16/2025-10:36:00] [TRT] [W] Detected layernorm nodes in FP16.\n",
            "[06/16/2025-10:36:00] [TRT] [W] Running layernorm after self-attention with FP16 Reduce or Pow may cause overflow. Forcing Reduce or Pow Layers in FP32 precision, or exporting the model to use INormalizationLayer (available with ONNX opset >= 17) can help preserving accuracy.\n",
            "✅ TensorRT engine successfully saved to checkpoints/sam_vit_h_embedding_second.engine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# --- PASO 1: DEFINIR LA RUTA AL DIRECTORIO RAÍZ DEL PROYECTO ---\n",
        "# Esta es la carpeta que contiene el directorio 'src'.\n",
        "ruta_proyecto_tensorrt = '/content/SegmentAnything-TensorRT'\n",
        "\n",
        "# --- PASO 2: ASEGURARSE DE QUE LA RUTA ESTÉ EN EL PATH DE PYTHON ---\n",
        "# Este código se asegura de que no añadamos la ruta múltiples veces.\n",
        "if ruta_proyecto_tensorrt not in sys.path:\n",
        "    sys.path.append(ruta_proyecto_tensorrt)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto_tensorrt}\")\n",
        "else:\n",
        "    print(\"La ruta del proyecto ya está en el path.\")\n",
        "\n",
        "# --- PASO 3: IMPORTAR USANDO LA RUTA COMPLETA ---\n",
        "# Ahora que Python conoce la ruta al proyecto, podemos importar desde 'src.infer'.\n",
        "try:\n",
        "    # Como descubrimos, la clase InferenceEngine está dentro del archivo 'infer.py',\n",
        "    # que a su vez está dentro de la carpeta 'src'.\n",
        "    from src.infer import InferenceEngine\n",
        "\n",
        "    print(\"\\n✅ ¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\nError de importación: {e}\")\n",
        "    print(\"Verifica que el archivo '/content/SegmentAnything-TensorRT/src/infer.py' existe y contiene la clase 'InferenceEngine'.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAqMAKpIGiff",
        "outputId": "9a0b0db3-9242-4271-d96c-5897de52f3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta del proyecto ya está en el path.\n",
            "\n",
            "✅ ¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corrección e importación de módulos de SAM\n",
        "\n",
        "Asegura que Python puede encontrar el paquete segment_anything:\n",
        "\n",
        "Se añade manualmente la ruta al sistema (sys.path.append(...)).\n",
        "\n",
        "Corrige errores comunes de importación:\n",
        "\n",
        "Importa los módulos directamente desde sus archivos fuente:\n",
        "\n",
        "sam_model_registry: permite registrar y cargar variantes del modelo SAM (por ejemplo, ViT-B, ViT-H...).\n",
        "\n",
        "SamPredictor: clase que permite realizar inferencias (predict) con el modelo cargado.\n",
        "\n",
        "Manejo de errores:\n",
        "\n",
        "Si algo falla, muestra el mensaje correspondiente."
      ],
      "metadata": {
        "id": "HXirznc6EPtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Ruta al directorio que CONTIENE el paquete\n",
        "ruta_paquete = '/content/segment_anything'\n",
        "\n",
        "# Añadimos la ruta (si no está ya)\n",
        "if ruta_paquete not in sys.path:\n",
        "    sys.path.append(ruta_paquete)\n",
        "\n",
        "try:\n",
        "\n",
        "    # Importamos cada objeto desde su archivo correcto.\n",
        "    from segment_anything.build_sam import sam_model_registry\n",
        "    from segment_anything.predictor import SamPredictor\n",
        "\n",
        "    print(\"Los módulos se han importado correctamente.\")\n",
        "    print(\"SamPredictor y sam_model_registry están listos para ser usados.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\" Un último error de importación: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\" Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAEl1jlpak5x",
        "outputId": "bc794dcc-8c48-49d9-ebc1-48b2852d2d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los módulos se han importado correctamente.\n",
            "SamPredictor y sam_model_registry están listos para ser usados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# --- PASO 1: DEFINIR LA RUTA AL DIRECTORIO RAÍZ DEL PROYECTO ---\n",
        "# Esta es la carpeta que contiene el directorio 'src'.\n",
        "ruta_proyecto_tensorrt = '/content/SegmentAnything-TensorRT'\n",
        "\n",
        "# --- PASO 2: ASEGURARSE DE QUE LA RUTA ESTÉ EN EL PATH DE PYTHON ---\n",
        "# Este código se asegura de que no añadamos la ruta múltiples veces.\n",
        "if ruta_proyecto_tensorrt not in sys.path:\n",
        "    sys.path.append(ruta_proyecto_tensorrt)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto_tensorrt}\")\n",
        "else:\n",
        "    print(\"La ruta del proyecto ya está en el path.\")\n",
        "\n",
        "# --- PASO 3: IMPORTAR USANDO LA RUTA COMPLETA ---\n",
        "# Ahora que Python conoce la ruta al proyecto, podemos importar desde 'src.infer'.\n",
        "try:\n",
        "\n",
        "    from src.infer import InferenceEngine\n",
        "\n",
        "    print(\"\\n¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"\\nError de importación: {e}\")\n",
        "    print(\"Verifica que el archivo '/content/SegmentAnything-TensorRT/src/infer.py' existe y contiene la clase 'InferenceEngine'.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIc11ISggI0w",
        "outputId": "bf08a34a-0240-444d-e35c-b944dd62ecd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta del proyecto ya está en el path.\n",
            "\n",
            "¡Éxito! El módulo 'InferenceEngine' se ha importado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/SegmentAnything-TensorRT/src/__pycache__\n",
        "print(\"✅Caché de Python limpiada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1_Is-e2ifof",
        "outputId": "0256825c-a69f-4665-ca1e-490fb5a215cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Caché de Python limpiada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación del motor de inferencia (InferenceEngine)\n",
        "\n",
        "Este bloque prepara e inicializa todo lo necesario para que el motor SAM en TensorRT pueda funcionar con las imágenes, utilizando los modelos previamente exportados."
      ],
      "metadata": {
        "id": "xeKbVF_JFa6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import tensorrt as trt\n",
        "import os\n",
        "\n",
        "print(f\"Versión de TensorRT: {trt.__version__}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "ruta_proyecto = '/content/SegmentAnything-TensorRT'\n",
        "if ruta_proyecto not in sys.path:\n",
        "    sys.path.append(ruta_proyecto)\n",
        "    print(f\"Ruta del proyecto añadida: {ruta_proyecto}\")\n",
        "else:\n",
        "    print(\"La ruta del proyecto ya está en el path.\")\n",
        "\n",
        "# --- LÓGICA DEL PROGRAMA ---\n",
        "try:\n",
        "    # 1. Importamos el MÓDULO entero ('infer'), no solo la clase\n",
        "    import src.infer\n",
        "    print(\"✅ Módulo 'src.infer' importado.\")\n",
        "\n",
        "    # 2. \"Inyectamos\" la librería 'trt' en el módulo 'infer'\n",
        "    # Esto asegura que cualquier código dentro de 'infer.py' tenga acceso a 'trt'.\n",
        "    src.infer.trt = trt\n",
        "    print(\"✅ Dependencia 'trt' inyectada manualmente en 'src.infer'.\")\n",
        "\n",
        "    # 3. Definimos las rutas a los modelos\n",
        "    pth_path = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h.pth\"\n",
        "    trt_model_1 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_first.engine\"\n",
        "    trt_model_2 = \"/content/SegmentAnything-TensorRT/checkpoints/sam_vit_h_embedding_second.engine\"\n",
        "    print(\"Rutas a los modelos definidas.\")\n",
        "\n",
        "    # 4. Creamos la instancia usando la clase del módulo que hemos modificado\n",
        "    print(\"\\nCreando la instancia de InferenceEngine...\")\n",
        "    engine = src.infer.InferenceEngine(\n",
        "        pth_path=pth_path,\n",
        "        trt_model_1=trt_model_1,\n",
        "        trt_model_2=trt_model_2\n",
        "    )\n",
        "    print(\"\\n ✅Objeto 'engine' creado sin errores.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Ocurrió un error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQ4ZDSxh7V4",
        "outputId": "b6da1fe7-0c72-4d1b-f4c2-9ca8d5173e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorRT: 10.12.0.36\n",
            "----------------------------------------\n",
            "La ruta del proyecto ya está en el path.\n",
            "✅ Módulo 'src.infer' importado.\n",
            "✅ Dependencia 'trt' inyectada manualmente en 'src.infer'.\n",
            "Rutas a los modelos definidas.\n",
            "\n",
            "Creando la instancia de InferenceEngine...\n",
            "\n",
            " ✅Objeto 'engine' creado sin errores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Carga la imagen\n",
        "image_path = \"/content/SegmentAnything-TensorRT/images/original_image.jpg\"\n",
        "if not os.path.exists(image_path):\n",
        "    raise FileNotFoundError(f\"No se encontró la imagen en {image_path}\")\n",
        "\n",
        "image_bgr = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Define el punto y etiqueta para el prompt\n",
        "input_point = np.array([[182, 424]])\n",
        "input_label = np.array([1])  # 1 para foreground\n",
        "\n",
        "print(f\"Imagen cargada y punto definido en {input_point}.\")\n",
        "\n",
        "# Ejecuta la inferencia con el engine\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "\n",
        "# Visualización con matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image.astype(np.uint8))\n",
        "plt.title(\"Segmentación aplicada\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "xJJrsz92Xz-o",
        "outputId": "ec59535e-8687-4b78-dd5b-e53420dc23fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen cargada y punto definido en [[182 424]].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Carga la imagen\n",
        "image_path = \"/content/SegmentAnything-TensorRT/images/01_missing_hole_01.jpg\"\n",
        "if not os.path.exists(image_path):\n",
        "    raise FileNotFoundError(f\"No se encontró la imagen en {image_path}\")\n",
        "\n",
        "image_bgr = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Define el punto y etiqueta para el prompt\n",
        "input_point = np.array([[1759, 831],\n",
        "\n",
        "\n",
        "\n",
        "                        ])\n",
        "\n",
        "input_label = np.array([1])\n",
        "\n",
        "print(f\"Imagen cargada y punto definido en {input_point}.\")\n",
        "\n",
        "# Ejecuta la inferencia con el engine\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "\n",
        "# Visualización con matplotlib\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output_image.astype(np.uint8))\n",
        "plt.title(\"Segmentación aplicada\")\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "kN4D7AKv1tJL",
        "outputId": "9edc1597-e4e4-4ebe-f373-56279c9de4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen cargada y punto definido en [[1759  831]].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# Liberar caché de GPU antes de medir\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.synchronize()\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# Ejecutar inferencia con TensorRT\n",
        "output_image = engine(image_rgb, input_point, input_label)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "end_time = time.perf_counter()\n",
        "\n",
        "# Tiempo total de inferencia\n",
        "inference_time = end_time - start_time\n",
        "# Memoria máxima usada en GPU\n",
        "memory_used_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "\n",
        "print(f\"🕒 Tiempo de inferencia: {inference_time:.4f} segundos\")\n",
        "print(f\"💾 Memoria GPU usada: {memory_used_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmXvxHhc4bzc",
        "outputId": "d968f244-9488-4024-ba74-2c192b69e462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🕒 Tiempo de inferencia: 2.4001 segundos\n",
            "💾 Memoria GPU usada: 5737.77 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(engine.currentModel.context1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXBDy0VL05RU",
        "outputId": "e0366a1e-9cd2-47eb-9474-a8cd9302c8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorrt_bindings.tensorrt.IExecutionContext'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SegmentAnything-TensorRT/images/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CLjyuK0jdjf",
        "outputId": "ecc3293f-246a-4ecb-98bd-523d9f9bbe6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 332\n",
            "-rw-r--r-- 1 root root 99846 Jun 16 10:15 original_image.jpg\n",
            "-rw-r--r-- 1 root root 25039 Jun 16 10:15 vit_b_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 25957 Jun 16 10:15 vit_b_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 24976 Jun 16 10:15 vit_b_Mask_TensorRT.png\n",
            "-rw-r--r-- 1 root root 23657 Jun 16 10:15 vit_h_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 24672 Jun 16 10:15 vit_h_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 23573 Jun 16 10:15 vit_h_Mask_TensorRT.png\n",
            "-rw-r--r-- 1 root root 23551 Jun 16 10:15 vit_l_Mask_Original.png\n",
            "-rw-r--r-- 1 root root 24547 Jun 16 10:15 vit_l_Mask_TensorRT_FP16.png\n",
            "-rw-r--r-- 1 root root 23467 Jun 16 10:15 vit_l_Mask_TensorRT.png\n"
          ]
        }
      ]
    }
  ]
}