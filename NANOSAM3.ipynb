{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPS3ee4xbmcH9vddyI86d8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVR27XD/MobileSAM/blob/main/NANOSAM3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/nanosam"
      ],
      "metadata": {
        "id": "DLsaphnqBQqT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGO9r_qb6h_U",
        "outputId": "5b7abd73-1545-4dd4-e92f-41f4ef22e601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanosam'...\n",
            "remote: Enumerating objects: 1309, done.\u001b[K\n",
            "remote: Total 1309 (delta 0), reused 0 (delta 0), pack-reused 1309 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1309/1309), 97.56 MiB | 22.63 MiB/s, done.\n",
            "Resolving deltas: 100% (749/749), done.\n",
            "/content/nanosam\n"
          ]
        }
      ],
      "source": [
        "# Clonar el repositorio\n",
        "!git clone https://github.com/NVIDIA-AI-IOT/nanosam.git\n",
        "%cd /content/nanosam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚠️ Forzar numpy compatible\n",
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "\n",
        "# Instalar ONNX + ONNXRuntime GPU (CUDA 12 para T4)\n",
        "!pip install onnx==1.15.0 onnxruntime-gpu==1.17.1 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "\n",
        "# Instalar TensorRT 8.6 + PyCUDA\n",
        "!pip install nvidia-pyindex nvidia-tensorrt==8.6.1.6 pycuda --no-cache-dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "eLIz96Gy6q7b",
        "outputId": "5b2dfa47-630d-4aed-eca0-739888be1bee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "468130502f564ec2bce24df19a278b9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
            "Collecting onnx==1.15.0\n",
            "  Downloading onnx-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting onnxruntime-gpu==1.17.1\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/onnxruntime-gpu/1.17.1/onnxruntime_gpu-1.17.1-cp311-cp311-manylinux_2_28_x86_64.whl (192.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx==1.15.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx==1.15.0) (5.29.5)\n",
            "Collecting coloredlogs (from onnxruntime-gpu==1.17.1)\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/coloredlogs/15.0.1/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m850.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu==1.17.1)\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/humanfriendly/10/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m181.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.17.1) (1.3.0)\n",
            "Downloading onnx-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.15.0 onnxruntime-gpu-1.17.1\n",
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-tensorrt==8.6.1.6 (from versions: 0.0.1.dev4, 0.0.1.dev5, 99.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for nvidia-tensorrt==8.6.1.6\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Drive (para guardar el .engine)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Edd4MzX6uBl",
        "outputId": "b2e3dbdd-e25c-462d-a339-4796e4e300d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir carpeta nanosam al PYTHONPATH\n",
        "import sys\n",
        "sys.path.append(\"/content/nanosam\")\n"
      ],
      "metadata": {
        "id": "z7UUoem684a4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nanosam\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXtGwtQg9WRO",
        "outputId": "769e82f6-b25b-4423-e16c-5853b9cea3c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanosam\n",
            "Obtaining file:///content/nanosam\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: nanosam\n",
            "  Running setup.py develop for nanosam\n",
            "Successfully installed nanosam-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar modelo ONNX\n",
        "!python3 nanosam/tools/export_sam_mask_decoder_onnx.py \\\n",
        "    --model-type vit_t \\\n",
        "    --checkpoint \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam.pt\" \\\n",
        "    --output \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.onnx\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTC7cqUS6xAg",
        "outputId": "8ae8d3ac-291a-459c-d17c-e524fe7725e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "Loading model...\n",
            "Exporting onnx model to /content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.onnx...\n",
            "Model has successfully been run with ONNXRuntime.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U polygraphy --extra-index-url https://pypi.ngc.nvidia.com\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB9-RyGeHnMx",
        "outputId": "03f56bff-e1d1-42ee-9321-89f97e41f600"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting polygraphy\n",
            "  Downloading polygraphy-0.49.24-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading polygraphy-0.49.24-py2.py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polygraphy\n",
            "Successfully installed polygraphy-0.49.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/TensorRT-10.0.1.6.Linux.x86_64-gnu.cuda-12.4.tar.gz\" -C /usr/local/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4UwJzjiV71e",
        "outputId": "316a1841-8de8-48f0-858e-30954d757f08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorRT-10.0.1.6/\n",
            "TensorRT-10.0.1.6/lib\n",
            "TensorRT-10.0.1.6/bin\n",
            "TensorRT-10.0.1.6/data/\n",
            "TensorRT-10.0.1.6/data/int8_api/\n",
            "TensorRT-10.0.1.6/data/int8_api/reference_labels.txt\n",
            "TensorRT-10.0.1.6/data/int8_api/airliner.ppm\n",
            "TensorRT-10.0.1.6/data/int8_api/README.md\n",
            "TensorRT-10.0.1.6/data/int8_api/resnet50_per_tensor_dynamic_range.txt\n",
            "TensorRT-10.0.1.6/data/char-rnn/\n",
            "TensorRT-10.0.1.6/data/char-rnn/char-rnn.wts\n",
            "TensorRT-10.0.1.6/data/char-rnn/model/\n",
            "TensorRT-10.0.1.6/data/char-rnn/model/model-20080.meta\n",
            "TensorRT-10.0.1.6/data/char-rnn/model/model-20080.data-00000-of-00001\n",
            "TensorRT-10.0.1.6/data/char-rnn/model/model-20080.index\n",
            "TensorRT-10.0.1.6/data/char-rnn/model/checkpoint\n",
            "TensorRT-10.0.1.6/data/mnist/\n",
            "TensorRT-10.0.1.6/data/mnist/9.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/4.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/6.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/mnist.onnx\n",
            "TensorRT-10.0.1.6/data/mnist/3.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/5.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/2.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/README.md\n",
            "TensorRT-10.0.1.6/data/mnist/7.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/0.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/8.pgm\n",
            "TensorRT-10.0.1.6/data/mnist/1.pgm\n",
            "TensorRT-10.0.1.6/data/resnet50/\n",
            "TensorRT-10.0.1.6/data/resnet50/ResNet50.onnx\n",
            "TensorRT-10.0.1.6/data/resnet50/reflex_camera.jpeg\n",
            "TensorRT-10.0.1.6/data/resnet50/airliner.ppm\n",
            "TensorRT-10.0.1.6/data/resnet50/class_labels.txt\n",
            "TensorRT-10.0.1.6/data/resnet50/binoculars.jpeg\n",
            "TensorRT-10.0.1.6/data/resnet50/README.md\n",
            "TensorRT-10.0.1.6/data/resnet50/tabby_tiger_cat.jpg\n",
            "TensorRT-10.0.1.6/onnx_graphsurgeon/\n",
            "TensorRT-10.0.1.6/onnx_graphsurgeon/onnx_graphsurgeon-0.5.0-py2.py3-none-any.whl\n",
            "TensorRT-10.0.1.6/python/\n",
            "TensorRT-10.0.1.6/python/tensorrt_lean-10.0.1-cp39-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_lean-10.0.1-cp311-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt-10.0.1-cp311-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_dispatch-10.0.1-cp312-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_dispatch-10.0.1-cp38-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt-10.0.1-cp310-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_dispatch-10.0.1-cp311-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_lean-10.0.1-cp38-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_dispatch-10.0.1-cp39-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt-10.0.1-cp38-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt-10.0.1-cp312-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_lean-10.0.1-cp312-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_lean-10.0.1-cp310-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt-10.0.1-cp39-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/python/tensorrt_dispatch-10.0.1-cp310-none-linux_x86_64.whl\n",
            "TensorRT-10.0.1.6/doc/\n",
            "TensorRT-10.0.1.6/doc/Acknowledgements.txt\n",
            "TensorRT-10.0.1.6/doc/Readme.txt\n",
            "TensorRT-10.0.1.6/include/\n",
            "TensorRT-10.0.1.6/include/NvInferConsistency.h\n",
            "TensorRT-10.0.1.6/include/NvInferImpl.h\n",
            "TensorRT-10.0.1.6/include/NvInferPluginUtils.h\n",
            "TensorRT-10.0.1.6/include/NvInferRuntime.h\n",
            "TensorRT-10.0.1.6/include/NvInferSafeRuntime.h\n",
            "TensorRT-10.0.1.6/include/NvInferRuntimeCommon.h\n",
            "TensorRT-10.0.1.6/include/NvInferRuntimeBase.h\n",
            "TensorRT-10.0.1.6/include/NvInferConsistencyImpl.h\n",
            "TensorRT-10.0.1.6/include/NvOnnxConfig.h\n",
            "TensorRT-10.0.1.6/include/NvInferRuntimePlugin.h\n",
            "TensorRT-10.0.1.6/include/NvInfer.h\n",
            "TensorRT-10.0.1.6/include/NvInferVersion.h\n",
            "TensorRT-10.0.1.6/include/NvOnnxParser.h\n",
            "TensorRT-10.0.1.6/include/NvInferLegacyDims.h\n",
            "TensorRT-10.0.1.6/include/NvInferPlugin.h\n",
            "TensorRT-10.0.1.6/targets/\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_plugin_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_vc_plugin.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_vc_plugin.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libonnx_proto.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvonnxparser.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_vc_plugin_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvonnxparser_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_dispatch.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvinfer_plugin.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvinfer_vc_plugin.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvinfer_dispatch.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvinfer.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvonnxparser.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/stubs/libnvinfer_lean.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_lean.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_dispatch.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvonnxparser.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_lean.so\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_lean_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_lean.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_builder_resource.so.10.0.1\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_vc_plugin.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_dispatch.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvonnxparser.so.10\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/lib/libnvinfer_dispatch_static.a\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/bin/\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/bin/trtexec\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/include\n",
            "TensorRT-10.0.1.6/targets/x86_64-linux-gnu/samples\n",
            "TensorRT-10.0.1.6/samples/\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/sampleNonZeroPlugin.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/nonZeroKernel.h\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/nonZeroKernel.cu\n",
            "TensorRT-10.0.1.6/samples/sampleNonZeroPlugin/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleCharRNN/\n",
            "TensorRT-10.0.1.6/samples/sampleCharRNN/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleCharRNN/sampleCharRNN.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleCharRNN/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleAlgorithmSelector/\n",
            "TensorRT-10.0.1.6/samples/sampleAlgorithmSelector/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleAlgorithmSelector/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleAlgorithmSelector/sampleAlgorithmSelector.cpp\n",
            "TensorRT-10.0.1.6/samples/Makefile\n",
            "TensorRT-10.0.1.6/samples/common/\n",
            "TensorRT-10.0.1.6/samples/common/getoptWin.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleReporting.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleInference.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleInference.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleReporting.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleEngines.h\n",
            "TensorRT-10.0.1.6/samples/common/buffers.h\n",
            "TensorRT-10.0.1.6/samples/common/logger.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleDevice.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleDevice.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleOptions.h\n",
            "TensorRT-10.0.1.6/samples/common/getOptions.h\n",
            "TensorRT-10.0.1.6/samples/common/parserOnnxConfig.h\n",
            "TensorRT-10.0.1.6/samples/common/ErrorRecorder.h\n",
            "TensorRT-10.0.1.6/samples/common/common.h\n",
            "TensorRT-10.0.1.6/samples/common/dumpTFWts.py\n",
            "TensorRT-10.0.1.6/samples/common/sampleUtils.cpp\n",
            "TensorRT-10.0.1.6/samples/common/bfloat16.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleEngines.cpp\n",
            "TensorRT-10.0.1.6/samples/common/streamReader.h\n",
            "TensorRT-10.0.1.6/samples/common/safeCommon.h\n",
            "TensorRT-10.0.1.6/samples/common/logger.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleOptions.cpp\n",
            "TensorRT-10.0.1.6/samples/common/sampleEntrypoints.h\n",
            "TensorRT-10.0.1.6/samples/common/argsParser.h\n",
            "TensorRT-10.0.1.6/samples/common/EntropyCalibrator.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleConfig.h\n",
            "TensorRT-10.0.1.6/samples/common/BatchStream.h\n",
            "TensorRT-10.0.1.6/samples/common/getOptions.cpp\n",
            "TensorRT-10.0.1.6/samples/common/bfloat16.h\n",
            "TensorRT-10.0.1.6/samples/common/getopt.c\n",
            "TensorRT-10.0.1.6/samples/common/logging.h\n",
            "TensorRT-10.0.1.6/samples/common/sampleUtils.h\n",
            "TensorRT-10.0.1.6/samples/common/half.h\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/coord_conv.py\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/mnist_coord_conv_train.py\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/modify_onnx_ac.py\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMnistCoordConvAC/sampleOnnxMnistCoordConvAC.cpp\n",
            "TensorRT-10.0.1.6/samples/utils/\n",
            "TensorRT-10.0.1.6/samples/utils/timingCache.h\n",
            "TensorRT-10.0.1.6/samples/utils/timingCache.cpp\n",
            "TensorRT-10.0.1.6/samples/utils/fileLock.cpp\n",
            "TensorRT-10.0.1.6/samples/utils/fileLock.h\n",
            "TensorRT-10.0.1.6/samples/sampleNamedDimensions/\n",
            "TensorRT-10.0.1.6/samples/sampleNamedDimensions/create_model.py\n",
            "TensorRT-10.0.1.6/samples/sampleNamedDimensions/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleNamedDimensions/sampleNamedDimensions.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleNamedDimensions/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleDynamicReshape/\n",
            "TensorRT-10.0.1.6/samples/sampleDynamicReshape/sampleDynamicReshape.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleDynamicReshape/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleDynamicReshape/README.md\n",
            "TensorRT-10.0.1.6/samples/trtexec/\n",
            "TensorRT-10.0.1.6/samples/trtexec/profiler.py\n",
            "TensorRT-10.0.1.6/samples/trtexec/Makefile\n",
            "TensorRT-10.0.1.6/samples/trtexec/tracer.py\n",
            "TensorRT-10.0.1.6/samples/trtexec/README.md\n",
            "TensorRT-10.0.1.6/samples/trtexec/prn_utils.py\n",
            "TensorRT-10.0.1.6/samples/trtexec/trtexec.cpp\n",
            "TensorRT-10.0.1.6/samples/python/\n",
            "TensorRT-10.0.1.6/samples/python/introductory_parser_samples/\n",
            "TensorRT-10.0.1.6/samples/python/introductory_parser_samples/README.md\n",
            "TensorRT-10.0.1.6/samples/python/introductory_parser_samples/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/introductory_parser_samples/onnx_resnet50.py\n",
            "TensorRT-10.0.1.6/samples/python/network_api_pytorch_mnist/\n",
            "TensorRT-10.0.1.6/samples/python/network_api_pytorch_mnist/README.md\n",
            "TensorRT-10.0.1.6/samples/python/network_api_pytorch_mnist/sample.py\n",
            "TensorRT-10.0.1.6/samples/python/network_api_pytorch_mnist/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/network_api_pytorch_mnist/model.py\n",
            "TensorRT-10.0.1.6/samples/python/common_runtime.py\n",
            "TensorRT-10.0.1.6/samples/python/simple_progress_monitor/\n",
            "TensorRT-10.0.1.6/samples/python/simple_progress_monitor/simple_progress_monitor.py\n",
            "TensorRT-10.0.1.6/samples/python/simple_progress_monitor/README.md\n",
            "TensorRT-10.0.1.6/samples/python/simple_progress_monitor/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/load_plugin_lib.py\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/test_custom_hardmax_plugin.py\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/README.md\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/sample.py\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/CMakeLists.txt\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/plugin/\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/plugin/customHardmaxPlugin.h\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/plugin/customHardmaxPlugin.cpp\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/onnx_custom_plugin/model.py\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/data_processing.py\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/download.yml\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/yolov3_to_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/README.md\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/coco_labels.txt\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/onnx_to_tensorrt.py\n",
            "TensorRT-10.0.1.6/samples/python/yolov3_onnx/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/visualize.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/build_engine.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/image_batcher.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/onnx_utils.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/create_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/labels_coco.txt\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/README.md\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/eval_coco.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/infer.py\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/tensorflow_object_detection_api/compare_tf.py\n",
            "TensorRT-10.0.1.6/samples/python/common.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/visualize.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/build_engine.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/image_batcher.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/onnx_utils.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/create_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/README.md\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/eval_coco.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/infer.py\n",
            "TensorRT-10.0.1.6/samples/python/detectron2/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/eval_gt.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/build_engine.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/image_batcher.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/create_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/README.md\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/infer.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/efficientnet/compare_tf.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/utils.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_inetdef_cuda_python.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_triton.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_cpp.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_cupy.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_plugin_cpp/\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_plugin_cpp/circ_pad_plugin.cu\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_numba.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_example.png\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/README.md\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/CMakeLists.txt\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_multi_tactic.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_cuda_python.py\n",
            "TensorRT-10.0.1.6/samples/python/python_plugin/circ_pad_plugin_torch.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/visualize.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/build_engine.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/image_batcher.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/onnx_utils.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/create_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/infer_tf.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/labels_coco.txt\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/README.md\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/eval_coco.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/infer.py\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/efficientdet/compare_tf.py\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/data_processing.py\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/download.yml\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/prepare_model.py\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/README.md\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/build_and_refit_engine.py\n",
            "TensorRT-10.0.1.6/samples/python/engine_refit_onnx_bidaf/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/download.yml\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/post_processing.py\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/convert_to_onnx.py\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/README.md\n",
            "TensorRT-10.0.1.6/samples/python/onnx_packnet/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/README.md\n",
            "TensorRT-10.0.1.6/samples/python/downloader.py\n",
            "TensorRT-10.0.1.6/samples/python/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/sample_weight_stripping/\n",
            "TensorRT-10.0.1.6/samples/python/sample_weight_stripping/refit_engine_and_infer.py\n",
            "TensorRT-10.0.1.6/samples/python/sample_weight_stripping/README.md\n",
            "TensorRT-10.0.1.6/samples/python/sample_weight_stripping/requirements.txt\n",
            "TensorRT-10.0.1.6/samples/python/sample_weight_stripping/build_engines.py\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMNIST/\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMNIST/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMNIST/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleOnnxMNIST/sampleOnnxMNIST.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleINT8API/\n",
            "TensorRT-10.0.1.6/samples/sampleINT8API/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleINT8API/sampleINT8API.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleINT8API/README.md\n",
            "TensorRT-10.0.1.6/samples/Makefile.config\n",
            "TensorRT-10.0.1.6/samples/sampleProgressMonitor/\n",
            "TensorRT-10.0.1.6/samples/sampleProgressMonitor/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleProgressMonitor/README.md\n",
            "TensorRT-10.0.1.6/samples/sampleProgressMonitor/sampleProgressMonitor.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleIOFormats/\n",
            "TensorRT-10.0.1.6/samples/sampleIOFormats/sampleIOFormats.cpp\n",
            "TensorRT-10.0.1.6/samples/sampleIOFormats/Makefile\n",
            "TensorRT-10.0.1.6/samples/sampleIOFormats/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4 --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "22XeRVGuezik",
        "outputId": "da39b612-4f09-448f-dff9-de3619182b82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.4.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "05c0da81bf0c49b48bf26f727fd46f73"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/nanosam/export_clean_onnx.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTUSo0Fc3awZ",
        "outputId": "e85033a6-6352-4366-fdb1-8fc2331754f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/nanosam/nanosam/mobile_sam/modeling/tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with nanosam.mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanosam/export_clean_onnx.py\", line 4, in <module>\n",
            "    from nanosam.mobile_sam.predictor import MobileSAMPredictor\n",
            "ImportError: cannot import name 'MobileSAMPredictor' from 'nanosam.mobile_sam.predictor' (/content/nanosam/nanosam/mobile_sam/predictor.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nanosam.mobile_sam.build_sam import build_sam_vit_t\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam.pt\"\n",
        "sam = build_sam_vit_t(checkpoint_path).to(\"cuda\").eval()\n"
      ],
      "metadata": {
        "id": "VhRxdP-Z9fqx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Forzar que todos los submódulos de MaskDecoder estén en cuda\n",
        "mask_decoder = sam.mask_decoder\n",
        "mask_decoder = mask_decoder.to(\"cuda\")\n",
        "mask_decoder.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VObqR8Wh_dk1",
        "outputId": "10a04ef6-f18e-484d-e87a-3df19706afd8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskDecoder(\n",
              "  (transformer): TwoWayTransformer(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TwoWayAttentionBlock(\n",
              "        (self_attn): Attention(\n",
              "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (cross_attn_token_to_image): Attention(\n",
              "          (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (act): ReLU()\n",
              "        )\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (cross_attn_image_to_token): Attention(\n",
              "          (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_attn_token_to_image): Attention(\n",
              "      (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "    )\n",
              "    (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (iou_token): Embedding(1, 256)\n",
              "  (mask_tokens): Embedding(4, 256)\n",
              "  (output_upscaling): Sequential(\n",
              "    (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (1): LayerNorm2d()\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (4): GELU(approximate='none')\n",
              "  )\n",
              "  (output_hypernetworks_mlps): ModuleList(\n",
              "    (0-3): 4 x MLP(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "        (2): Linear(in_features=256, out_features=32, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (iou_prediction_head): MLP(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ✅ Cargar MaskDecoder y mover a GPU correctamente\n",
        "mask_decoder = sam.mask_decoder\n",
        "mask_decoder.eval()\n",
        "mask_decoder = mask_decoder.to(\"cuda\")  # MUY IMPORTANTE HACERLO ANTES DE CREAR EL WRAPPER\n",
        "\n",
        "# ✅ Crear wrapper en CUDA\n",
        "mask_decoder_export = MaskDecoderONNXWrapper(mask_decoder).to(\"cuda\")\n",
        "mask_decoder_export.eval()\n",
        "\n",
        "# ✅ Dummy inputs en CUDA\n",
        "image_embeddings = torch.randn(1, 256, 64, 64, device=\"cuda\", dtype=torch.float32)\n",
        "image_pe = torch.randn(1, 256, 64, 64, device=\"cuda\", dtype=torch.float32)\n",
        "sparse_prompt_embeddings = torch.randn(1, 2, 256, device=\"cuda\", dtype=torch.float32)\n",
        "dense_prompt_embeddings = torch.randn(1, 256, 64, 64, device=\"cuda\", dtype=torch.float32)\n",
        "multimask_output_flag = torch.tensor([1.0], device=\"cuda\", dtype=torch.float32)\n",
        "\n",
        "# ✅ Ruta exportación\n",
        "output_onnx_path = \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_mask_decoder_clean.onnx\"\n",
        "\n",
        "# ✅ Exportar ONNX\n",
        "torch.onnx.export(\n",
        "    mask_decoder_export,\n",
        "    (\n",
        "        image_embeddings,\n",
        "        image_pe,\n",
        "        sparse_prompt_embeddings,\n",
        "        dense_prompt_embeddings,\n",
        "        multimask_output_flag,\n",
        "    ),\n",
        "    output_onnx_path,\n",
        "    input_names=[\n",
        "        \"image_embeddings\", \"image_pe\", \"sparse_prompt_embeddings\", \"dense_prompt_embeddings\", \"multimask_output_flag\"\n",
        "    ],\n",
        "    output_names=[\"masks\", \"iou_predictions\"],\n",
        "    opset_version=14,\n",
        "    do_constant_folding=True\n",
        ")\n",
        "\n",
        "print(\"✅ Exportación OK:\", output_onnx_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "u4shMuz46MlF",
        "outputId": "e206eb61-0f33-4363-b795-117eece432ea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-41-3483267291.py:27: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  multimask_output = bool(multimask_output_flag.item())\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43-456449225.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# ✅ Exportar ONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m torch.onnx.export(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mmask_decoder_export\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    381\u001b[0m             )\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         export(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0m_validate_dynamic_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m             graph, params_dict, torch_out = _model_to_graph(\n\u001b[0m\u001b[1;32m   1429\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_trace_quant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mprev_autocast_cache_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m     trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m     outs = ONNXTracedModule(\n\u001b[0m\u001b[1;32m   1499\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     )(*args, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         graph, _out = torch._C._create_graph_by_tracing(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0min_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-41-3483267291.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output_flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmultimask_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultimask_output_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         masks, iou_pred = self.mask_decoder(\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mimage_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mimage_pe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_pe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nanosam/nanosam/mobile_sam/modeling/mask_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output)\u001b[0m\n\u001b[1;32m     92\u001b[0m     ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m\"\"\"Predicts masks. See 'forward' for more details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Concatenate output tokens (IOU token + mask tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         output_tokens = torch.cat([\n",
            "\u001b[0;32m/content/nanosam/nanosam/mobile_sam/modeling/mask_decoder.py\u001b[0m in \u001b[0;36mpredict_masks\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Predict masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mhyper_in_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_mask_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mhyper_in_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hypernetworks_mlps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_tokens_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nanosam.mobile_sam.build_sam import build_mobile_sam\n",
        "import torch\n",
        "\n",
        "# Ruta del checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam.pt\"\n",
        "\n",
        "# 1️⃣ Crear el modelo vacío\n",
        "model = build_mobile_sam(model_type=\"vit_t\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# 2️⃣ Cargar pesos\n",
        "state_dict = torch.load(checkpoint_path, map_location=\"cuda\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# 3️⃣ Extraer MaskDecoder\n",
        "mask_decoder = model.mask_decoder\n",
        "mask_decoder.eval()\n",
        "mask_decoder.to(\"cuda\")\n",
        "\n",
        "# Inputs dummy para la exportación\n",
        "image_embeddings = torch.randn(1, 256, 64, 64, device=\"cuda\", dtype=torch.float32)\n",
        "point_coords = torch.randn(1, 1, 2, device=\"cuda\", dtype=torch.float32)\n",
        "point_labels = torch.randint(0, 2, (1, 1), device=\"cuda\", dtype=torch.float32)\n",
        "mask_input = torch.randn(1, 1, 256, 256, device=\"cuda\", dtype=torch.float32)\n",
        "has_mask_input = torch.tensor([1.0], device=\"cuda\", dtype=torch.float32)\n",
        "orig_im_size = torch.tensor([[512, 512]], device=\"cuda\", dtype=torch.float32)\n",
        "\n",
        "# Ruta de exportación\n",
        "output_onnx_path = \"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_clean.onnx\"\n",
        "\n",
        "# Exportación ONNX\n",
        "torch.onnx.export(\n",
        "    mask_decoder,\n",
        "    (\n",
        "        image_embeddings,\n",
        "        point_coords,\n",
        "        point_labels,\n",
        "        mask_input,\n",
        "        has_mask_input,\n",
        "        orig_im_size\n",
        "    ),\n",
        "    output_onnx_path,\n",
        "    input_names=[\n",
        "        'image_embeddings', 'point_coords', 'point_labels',\n",
        "        'mask_input', 'has_mask_input', 'orig_im_size'\n",
        "    ],\n",
        "    output_names=['masks', 'iou_predictions', 'low_res_masks'],\n",
        "    opset_version=14,\n",
        "    do_constant_folding=True,\n",
        "    dynamic_axes={\n",
        "        'point_coords': {1: 'num_points'},\n",
        "        'point_labels': {1: 'num_points'}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"✅ Exportación terminada: {output_onnx_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "PH8jtTiJepyV",
        "outputId": "1abd22e4-5628-4860-f27b-65d8bebf312b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'build_mobile_sam' from 'nanosam.mobile_sam.build_sam' (/content/nanosam/nanosam/mobile_sam/build_sam.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1923846588.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnanosam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobile_sam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_sam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_mobile_sam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ruta del checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'build_mobile_sam' from 'nanosam.mobile_sam.build_sam' (/content/nanosam/nanosam/mobile_sam/build_sam.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/nanosam/export_clean_onnx.py \\\n",
        "  --checkpoint /content/drive/MyDrive/Colab\\ Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.pth \\\n",
        "  --output /content/drive/MyDrive/Colab\\ Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.onnx \\\n",
        "  --return-single-mask \\\n",
        "  --gelu-approximate \\\n",
        "  --use-stability-score \\\n",
        "  --opset 16\n"
      ],
      "metadata": {
        "id": "K8mJOU7CXWcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/nanosam/nanosam/mobile_sam/modeling/mask_decoder.py | grep class\n"
      ],
      "metadata": {
        "id": "Fd3tZbjiZ8E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export LD_LIBRARY_PATH=/usr/local/TensorRT-10.0.1.6/lib:$LD_LIBRARY_PATH && \\\n",
        "/usr/local/TensorRT-10.0.1.6/bin/trtexec \\\n",
        "    --onnx=\"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.onnx\" \\\n",
        "    --saveEngine=\"/content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/mobile_sam_mask_decoder.engine\" \\\n",
        "    --fp16 \\\n",
        "    --memPoolSize=workspace:4096\n"
      ],
      "metadata": {
        "id": "OVlqokKoWtIW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}